# Day01:
## 1. 天机学堂介绍:
### 项目亮点:
![[Pasted image 20240912131056.png]]

## 2. 项目环境搭建:
### 2.1 导入虚拟机
**部署常用开发组件:**
修改host,直接访问域名即可映射到对应ip地址.访问域名时**自动访问80端口**,**nginx监听了80端口**,并进行反向代理.
![[Pasted image 20240912132332.png]]

## 3.阅读源码:
![[Pasted image 20240915093116.png]]
### 删除订单失效BUG分析:
#### 错误分析:
查看前端发送请求为
![[Pasted image 20240915095341.png]]
查看nginx的配置文件,发现api.tianji.com会被反向代理到![[Pasted image 20240915095955.png]]
即http://192.168.150.101:10010/ts/orders/~.再查看gateway路由,发现以ts开头的请求都被路由到了trade-service服务中,即lb://trade-service/orders/~.
![[Pasted image 20240915100222.png]]
#### 代码开发:
##### **调试方法:**
**方法一(远程调试):**
1. 新建启动项"Remote JVM DEBUG",配置Configuration;同时Jenkins中配置部署脚本,并运行,此时虚拟机中的tj-trade应多出一个5005端口,即远程调试的端口!![[Pasted image 20240915153653.png]]
==**方法二(本地调试):**==
1. 在启动trade-service时配置`-active profile: local`,此时在nacos就会新增一个trade-service服务,并且ip地址为`192.168.150.1`. 此时我们在nacos中将虚拟机中的trade-service下线,当用户访问trade-service服务时,就会走本地的trade服务,而不是虚拟机中的!!![[Pasted image 20240915154402.png]]
##### **bug修复:**
1. 经debug分析,发现是在判断用户id是否相等时出现问题,id为Long型,在进行比较时,是比较其地址.包装类提前将-128~127之间的Long包装类提前创建出来,共享使用,故当Long值在-128~127时,可以使用`==/!=`进行判断;当在这之外,则需要使用equals来判断!!!

##### **分支管理:**
- 避免直接使用lesson-init提交bug代码,新建`hotfix-delete-order-error`分支,提交代码;随后进行测试,再切换到lesson-init分支,并将hotfix分支`merge into lesson-init`分支!

#### 熟悉项目:

# Day02:
**开发业务流程:**
![[Pasted image 20240915173012.png]]
## 我的课表:
需要强调的一点是，开发中最重要的环节其实是前两步：
- 原型分析、接口设计
- 数据库设计
那为什么要先设计接口呢？原因有两点：
- 第一：目前企业开发的模式往往是前后端分离，前后端并行开发。**前端开发需要调用后端接口**，**后端需要开发接口返回数据给前端**，要想并行开发，就必须有一套接口标准，前后端基于接口完成开发。
- 第二：设计接口的过程就是分析业务的过程，弄清楚了业务的细节，更有助于我们设计数据库结构，开发接口功能。
### 接口设计: 
#### 分析业务流程:
![[Pasted image 20240915191155.png]]

#### 接口统计:
根据业务流程,梳理可能需要开发的接口:
1) **加入课表:** 用户支付完成后,需要将已购买的课程加入课表. 支付完成后,交易服务会基于MQ通知(支付完成与加入课表无需同步进行)的方式,通知学习服务来执行加入课表的动作.
   ->**接口1:** 支付或报名课程后,监听到MQ通知,将课程加入课表.
2) **查询课表:** 课程加入课表后,用户可以在个人中心中查看课程.
   ->**接口2:** 分页查询我的课表.
3) **删除课程:** 课程学完后(或过期,退款等),用户可以选择将课程删除.
   ->**接口3:** 删除指定课程.
   ->**接口4:** 退款后,监听到MQ通知,删除指定课程.
4) **查询学习进度:** 用户可以查看最近的学习进度
   ->**接口5:** 查询最近正在学习的课程.
   ->**接口6:** 查询学习计划的进度.
   ![[Pasted image 20240915192307.png|600]]
5) **查询指定课程的学习状态:** 用户可以在课程中心查看指定课程的学习状态以及学习进度.
   ->**接口7:** 根据id查询指定课程的学习状态.![[Pasted image 20240915192558.png]]
6) **内部访问接口:** 除了页面原型中看到的接口以外,其它微服务也对`tj-learning`服务有数据需求,并且也定义了一些需要我们实现的Feign接口.在天机学堂的项目中,所有Feign接口都定义在了`tj-api`模块下，`learning`服务的接口定义在`com.tianji.api.client.learning`模块下:
   ->**接口8:** **统计某课程的报名人数**:后台管理的某些地方需要知道课程的报名人数
   ->**接口9:** **校验**当前用户是否报名了指定课程:用户学习课程的前提是报名了课程,某些业务中需要做校验![[Pasted image 20240915192742.png]]
**接口总结:**

| **编号** | **接口简述**                   | **请求方式** | **请求路径**                  |
| ------ | -------------------------- | -------- | ------------------------- |
| 1      | 支付或报名课程后，立刻加入课表            | MQ通知     |                           |
| 2      | 分页查询我的课表                   | GET      | /lessons/page             |
| 3      | 查询我最近正在学习的课程               | GET      | /lessons/now              |
| 4      | 根据id查询指定课程的学习状态            | GET      | /lessons/{courseId}       |
| 5      | 删除课表中的某课程                  | DELETE   | /lessons/{courseId}       |
| 6      | 退款后，立刻移除课表中的课程             | MQ通知     |                           |
| 7      | 校验指定课程是否是课表中的有效课程（Feign接口） | GET      | /lessons/{courseId}/valid |
| 8      | 统计课程学习人数（Feign接口）          | GET      | /lessons/{courseId}/count |
**MyBatisX插件使用方法:**
1. 配置数据源: `Tools-> Config Database`:
2. **设置代码生成:**![[Pasted image 20240915201844.png|800]]
3. 根据主键策略和枚举类调整相应属性:
```java
@ApiModelProperty(value = "主键")  
@TableId(value = "id", type = IdType.ASSIGN_ID)   // 根据数据库主键配置调整主键策略.  
private Long id;  
  
@ApiModelProperty(value = "课程状态，0-未学习，1-学习中，2-已学完，3-已失效")  
private LessonStatus status;    // 利用枚举类定义状态
  
@ApiModelProperty(value = "学习计划状态，0-没有计划，1-计划进行中")  
private PlanStatus planStatus;   
```
4. 根据接口设计调整Controller方法中的默认路径.

### 代码开发-添加课程到课表:
#### 接口设计:
![[Pasted image 20240915204756.png|600]]
#### 代码开发:
##### 1. **编写消息监听类:**
在`com.tianji.learning.mq`新建LessonChangeListener监听类. 
	1) 添加`@Component`注解,将监听类交由Spring容器管理;
	2) `@RequiredArgsConstructor`与`final`,实现构造器注入;
	3) `@RabbitListener`定义监听方法.
```java
@Component  
@Slf4j  
@RequiredArgsConstructor  
public class LessonChangeListener {  
  
    private final ILearningLessonService lessonService;  
  
    @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "learning.lesson.pay.queue",durable = "true"),  
    exchange = @Exchange(value = MqConstants.Exchange.ORDER_EXCHANGE,type = ExchangeTypes.TOPIC),  
    key = MqConstants.Key.ORDER_PAY_KEY))  
    public void onMsg(OrderBasicDTO orderBasicDTO){  
        log.info("接收到消息！！");  
//        TODO 校验参数(健壮性处理)
        if (orderBasicDTO == null || orderBasicDTO.getUserId() == null  
                || CollUtils.isEmpty(orderBasicDTO.getCourseIds())){  
            log.info("订单数据为空！");  
		// 处理异常时,不可抛出,否则Mq会持续尝试,直到达到上限!  
            return;  
        }  

//        TODO 调用service,保存课程到课表  
        lessonService.addUserLesson(orderBasicDTO.getUserId(), orderBasicDTO.getCourseIds());  
    }  
}
```
##### 2. Service层:
- 监听类传递了userId与courseId给Serivce层,实现将课程保存到课表,需要PO类,故需要实现DTO->PO,故观察课表中的字段. 发现很多字段都有默认值,故只需设置`user_id,course_id,expire_time`三个字段即可.
![[Pasted image 20240916092854.png]]
- user_id,course_id已由Listener传递,故只需查询过期时间,即通过"加入课程时间+有效期"获得,由此通过**调用courseClient来查询课程信息,获得每个课程的有效期!**
```java
    @Override  
    public void addUserLesson(Long userId, List<Long> courseIds) {  
//        TODO 通过feign远程调用服务,得到课程信息  
        List<CourseSimpleInfoDTO> cinfos = courseClient.getSimpleInfoList(courseIds);  
  
        List<LearningLesson> list = new ArrayList<>();  
//        TODO 封装PO实体类，填充过期时间  
        for (CourseSimpleInfoDTO info : cinfos){  
            LearningLesson learningLesson = new LearningLesson();  
  
            learningLesson.setUserId(userId);  
            learningLesson.setCourseId(info.getId());  
            Integer validDuration = info.getValidDuration();  
            if (validDuration != null) {  
                LocalDateTime now = LocalDateTime.now();  
                learningLesson.setCreateTime(now);  
                learningLesson.setExpireTime(now.plusMonths(validDuration));  
            }  
  
            list.add(learningLesson);  
        }  
//        TODO 批量保存(MyBatisPlus的方法)
        saveBatch(list);  
    }
```
##### 3. Bug修复:
- 在这里出现了一个问题,添加课程时发现LeanringApplication无响应!?查看前端发送的请求,发现是先请求`/freecourse/{courseId}`,并且返回数据为`msg="课程已过期"`! 查询后发现是`OrderController`中的`enrolledFreeCourse()`,**追踪业务逻辑**,发现是在service层调用了`getOnShelfCourse`判断课程是否过期导致! 故将该判断逻辑注释,重新编译运行,发现请求可正确到达LearningApplication! 自此,成功修复该Bug!!
![[Pasted image 20240916095301.png]]

### 代码开发-分页查询我的课表:
#### **接口设计:**
![[Pasted image 20240915193407.png]]
#### 代码开发:
##### Controller层:
- 使用构造器注入: 1)利用final定义成员变量; 2)添加@RequiredArgsConstructors注解.
```java
private final ILearningLessonService lessonService;

@GetMapping("page")  
@ApiOperation("分页查询我的课表")  
public PageDTO<LearningLessonVO> queryMyLessons(PageQuery pageQuery){  
    return lessonService.queryMyLessons(pageQuery);  
}
```
##### Service层:
>[!实现分页查询的几种方法]
>1)利用MyBatis分页插件的`PageHelper.startPage(PageNum,PageSize)`方法;
>2)利用MyBatis中的Page方法


### 接口开发-查询正在学习的课程

# Day03:学习计划和进度
## 提交学习记录:
### 需求分析和接口设计:

#### 需求:
在课程学习页面播放视频时或考试后,需要提交学习记录信息到服务端保存.
![[Pasted image 20240917104006.png|300]]
#### 接口:
- 小节类型包含课程or考试.若考试,则直接记录未完成;若为课程,则需判断视频播放进度超过50%.
![[Pasted image 20240917104134.png]]![[Pasted image 20240917144410.png]]

## 课程过期定时任务
- 利用SpringTask实现定时任务: 1)启动类上开启@EnableScheduling注解; 2)编写定时任务类,如下
```java
@Component
public class LessonStatusCheckJob(){
	@Scheduled(cron = "0 * * * * ?") // 代表每分钟的第0秒执行一次
	public void lessonStatusCheck(){
		// 1. 查询所有未过期的课程 
		List<LearningLesson> list = lessonService.list(Wrappers.<LearningLesson>lambdaQuery()
										.ne(LearningLesson::getStatus, LessonStatus.EXPIRED);
					
		// 2. 判断是否过期
		for (LearningLesson lesson : list){
			if(now.isAfter(lesson.getExpireTime())){
				lesson.setStatus(LessonStatus.Expired);
			}
		}
		// 3. 批量更新
		lessonSerivce.updateBatchById(list);
	}
}
```

## 方案思考
### 思考题：思考一下目前提交学习记录功能可能存在哪些问题？有哪些可以改进的方向？
- 更新学习记录时,因为是每15秒查询一次,所以在用户量大时,对数据库的访问量很大! 所以在"更新最近学习小节"与"更新最近学习时间"时,需要进行优化!


# Day04:高并发优化
## 1. 高并发优化方案:
解决高并发问题从宏观角度来说有3个方向:
其中，水平扩展和服务保护侧重的是运维层面的处理。而**提高单机并发能力侧重**的则是业务层面的处理，也就是我们程序员在开发时可以做到的。
![[Pasted image 20240917191422.png]]
### 1.1 提高单机并发能力:
- 在机器性能一定的情况下,提高单机并发能力就是要尽可能**缩短业务的响应时间**（**R**esponse**T**ime）,而对响应时间影响最大的往往是对数据库的操作。
![[Pasted image 20240917191849.png]]
### 1.2 变同步写为异步写
![[Pasted image 20240917193108.png]]
利用MQ可以把同步业务变成异步，从而提高效率。
- 当我们接收到用户请求后,可以先不处理业务,而是**发送MQ消息并返回给用户结果**。
- 而后通过**消息监听器**监听MQ消息,处理后续业务。

#### **优点**:
- 无需等待复杂业务处理，大大减少响应时间
- 利用MQ暂存消息，起到流量削峰整形作用
- 降低写数据库频率，减轻数据库并发压力
#### 缺点：
- 依赖于MQ的可靠性
- 降低了写频率,但是没有减少数据库写次数
#### 应用场景：
- 比较适合应用于业务复杂,业务链较长,有多次数据库写操作的业务.

### 1.3 合并写请求:
- 合并写请求就是指当写数据库并发较高时，不再直接写到数据库。而是**先将数据缓存到Redis**，然后**定期**将缓存中的数据批量写入数据库。
![[Pasted image 20240917193640.png]]
- 由于Redis是内存操作，写的效率也非常高，这样每次**请求的处理速度大大提高,响应时间大大缩短**，并发能力肯定有很大的提升。
- 而且由于数据都缓存到Redis了，积累一些数据后再**批量写入**数据库，这样数据库的写频率、写次数都大大减少，对数据库压力小了非常多！
#### 优点:
- 写缓存速度快，响应时间大大减少
- 降低数据库的写频率和写次数，大大减轻数据库压力
#### 缺点:
- 实现相对复杂
- 依赖Redis可靠性
-  不支持事务和复杂业务
#### 场景:
- 写频率较高、写业务相对简单的场景

## 2. 播放进度记录方案改进
- 播放进度统计包含大量的数据库读,写操作, 尤其是写操作, 所以通过高并发优化方案2来实现,即合并写请求.
### 2.1 优化方案选择:
前端**每隔15秒**就提交一次请求。在一个视频播放的过程中，可能有数十次请求，但**完播（进度超50%）的请求只会有一次**。因此多数情况下都是更新一下播放进度即可。也就是说，**95%的请求都是在更新`learning_record`表中的`moment`字段，以及`learning_lesson`表中的正在学习的小节id和时间。** 并且我们只需记录最后一次的播放进度即可,故**==采用合并写的方案==**来降低数据库写的次数和频率.

### 2.2 Redis数据结构设计:
因为需要更新某个用户的某个小节的播放进度,所以Key为sectionId和userid,Value为播放进度(moment)和用户id. 因为sectionId和userId即为lessonId,故选择lessonId作为Key值即可. 
![[Pasted image 20240917194756.png#pic_center|300]]
这样设计有一个问题.课程有很多,每个课程的小节也非常多.每个小节都是一个独立的KEY，需要创建的KEY也会非常多,浪费大量内存.

而且，用户学习视频的过程中，可能会在多个视频之间来回跳转，这就会导致**频繁的创建缓存、缓存过期，影响到最终的业务性能**。该如何解决呢? 
	可以把一个课程的多个小节作为一个KEY来缓存:
![[Pasted image 20240917200513.png|400]]
这样做有两个好处：
- 可以大大**减少需要创建的KEY的数量**，减少内存占用。
- 一个课程创建一个缓存，当用户在**多个视频间跳转时，整个缓存的有效期都会被延续**，**不会频繁的创建和销毁缓存数据**
### 2.3 业务流程更新:
添加缓存以后，学习记录提交的业务流程就需要发生一些变化:
![[Pasted image 20240917200815.png]]
变化最大的有几点：
- 查询记录是否存在时,先查询Redis,再查询数据库.若Redis无而DB有,则将DB中的数据存入Redis,并继续走左侧分支.
- 提交播放进度后,如果是**更新播放进度则不写数据库,而是写缓存,即更新Redis中的moment**
- 需要一个定时任务，**定期将缓存数据写入数据库**
### 2.4 持久化思路 
对于合并写请求方案，一定有一个步骤就是持久化缓存数据到数据库。一般采用的是定时任务持久化. 但是又会有两个问题: 1)定时任务频率太高,则会造成数据库压力过大; 2)定时任务频率太低,则不满足续播的误差需求.

> 那么问题来了，有什么办法能够在**不增加数据库压力的情况下,保证时间误差较低**吗？

我们再次打开该视频续播的时候，肯定是从最后一次提交的播放进度来续播。也就是说**续播进度之前的N次播放进度都是没有意义的**，都会被覆盖。

既然如此，我们完全没有必要定期把这些播放进度写到数据库，只需要将用户最后一次提交的播放进度写入数据库即可。所以我们完全没有必要定期把这些播放进度写到数据库，只需要将用户**最后一次提交的播放进度写入数据库**即可。

> 但问题来了，我们怎么知道哪一次提交是最后一次提交呢？

只要用户一直在提交记录，Redis中的播放进度就会一直变化。**如果Redis中的播放进度不变，肯定是停止了播放，是最后一次提交。**

>因此，我们只要能判断Redis中的播放进度是否变化即可。怎么判断呢？

每当前端提交播放记录时，我们可以**设置一个延迟任务并保存这次提交的进度**。等待20秒后（因为前端每15秒提交一次，**20秒就是等待下一次提交**），检查Redis中的缓存的进度与任务中的进度是否一致。
- 不一致：说明持续在提交，无需处理
- 一致：说明是最后一次提交，更新学习记录、更新课表最近学习小节和时间到数据库中.

流程如下:![[Pasted image 20240917204209.png]]

## 3. 延迟任务
### 3.1 延迟任务方案
![[Pasted image 20240917204644.png]] 
### DelayQueue的用法:
- `Delayed`类型元素,即实现了Delayed接口的延迟任务类:
  - 实现getDelay()和compareTo()方法,功能为获取剩余延迟时间、比较执行顺序.
```Java
@Data
public class DelayTask<D> implements Delayed {
    private D data;
    private long deadlineNanos;

    public DelayTask(D data, Duration delayTime) {
        this.data = data;
        this.deadlineNanos = System.nanoTime() + delayTime.toNanos();
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return unit.convert(Math.max(0, deadlineNanos - System.nanoTime()), TimeUnit.NANOSECONDS);
    }

    @Override
    public int compareTo(Delayed o) {
        long l = getDelay(TimeUnit.NANOSECONDS) - o.getDelay(TimeUnit.NANOSECONDS);
        if(l > 0){
            return 1;
        }else if(l < 0){
            return -1;
        }else {
            return 0;
        }
    }
}
```

- `queue.add(new DelayTask<>(Object,Times))`:往延迟队列中添加`Delayed`类型元素;
- `queue.poll()`: 非阻塞式出队方法,即为空时也会执行并输出;
- `queue.take()`: 阻塞式出队方法,只有当非空时才会出队. 无元素时,线程会一直等待!

## 4. 代码改造
将业务流程封装成工具类,需要时直接调用工具类即可.
1. 添加播放记录到Redis，并添加一个延迟检测任务到DelayQueue
2. 查询Redis缓存中的指定小节的播放记录
3. 删除Redis缓存中的指定小节的播放记录
4. 异步执行DelayQueue中的延迟检测任务，检测播放进度是否变化，如果无变化则写入数据库
### 4.1 定义延迟任务工具类: 
定义延迟任务类,实现Delayed接口,实现其中的`getDelay()`与`compareTo()`方法.
```java
@Data  
public class DelayTask<D> implements Delayed {  
    private D data;  
    private long deadlineNanos;  
  
    public DelayTask(D data, Duration delayTime) {  
        this.data = data;  
        this.deadlineNanos = System.nanoTime() + delayTime.toNanos();  
    }  
  
    @Override  
    public long getDelay(TimeUnit unit) {  
        return unit.convert(Math.max(0, deadlineNanos - System.nanoTime()), TimeUnit.NANOSECONDS);  
    }  
  
    @Override  
    public int compareTo(Delayed o) {  
        long l = getDelay(TimeUnit.NANOSECONDS) - o.getDelay(TimeUnit.NANOSECONDS);  
        if(l > 0){  
            return 1;  
        }else if(l < 0){  
            return -1;  
        }else {  
            return 0;  
        }  
    }  
}
```

### 4.2 添加学习记录到Redis与添加延迟任务到DelayQueue

```java
public void addLearningRecordTask(LearningRecord record){  
    // 1.添加数据到Redis缓存  
    writeRecordCache(record);  
    // 2.提交延迟任务到延迟队列 DelayQueue    
    queue.add(new DelayTask<>(new RecordTaskData(record), Duration.ofSeconds(20)));  
}  
  
public void writeRecordCache(LearningRecord record) {  
    log.debug("更新学习记录的缓存数据");  
    try {  
        // 1.数据转换:转换为Json字符串存储到Redis中.
        String json = JsonUtils.toJsonStr(new RecordCacheData(record));  
        // 2.写入Redis,定义Key为learning:record:LessonId
        String key = StringUtils.format(RECORD_KEY_TEMPLATE, record.getLessonId());  
        redisTemplate.opsForHash().put(key, record.getSectionId().toString(), json);  
        // 3.添加缓存过期时间. 缓存过期时间为1mins,而Redis中数据每20秒不更新就会写入DB中,故无影响.
        redisTemplate.expire(key, Duration.ofMinutes(1));  
    } catch (Exception e) {  
        log.error("更新学习记录缓存异常", e);  
    }  
}
```
其中,RecordCacheData类如下,即对应了Redis中的HashValue中的属性.
![[Pasted image 20240917200513.png|400]]
```java
@Data  
@NoArgsConstructor  
private static class RecordCacheData{  
    private Long id;  
    private Integer moment;  
    private Boolean finished;  
  
    public RecordCacheData(LearningRecord record) {  
        this.id = record.getId();  
        this.moment = record.getMoment();  
        this.finished = record.getFinished();  
    }  
}
```

RecordTaskData类:
- 对应Redis中的属性.
```java
@Data  
@NoArgsConstructor  
private static class RecordTaskData{  
    private Long lessonId;  
    private Long sectionId;  
    private Integer moment;  
  
    public RecordTaskData(LearningRecord record) {  
        this.lessonId = record.getLessonId();  
        this.sectionId = record.getSectionId();  
        this.moment = record.getMoment();  
    }  
}
```

### 4.3 查询小节播放记录
从Redis中读取播放记录.
```java
public LearningRecord readRecordCache(Long lessonId, Long sectionId){  
    try {  
        // 1.读取Redis数据:拼接Key并查询!
        String key = StringUtils.format(RECORD_KEY_TEMPLATE, lessonId);  
        Object cacheData = redisTemplate.opsForHash().get(key, sectionId.toString());  
        if (cacheData == null) {  
            return null;  
        }  
        // 2.数据检查和转换  
        return JsonUtils.toBean(cacheData.toString(), LearningRecord.class);  
    } catch (Exception e) {  
        log.error("缓存读取异常", e);  
        return null;  
    }  
}
```

### 4.4 删除小节播放记录
```java
public void cleanRecordCache(Long lessonId, Long sectionId){  
    // 删除数据:拼接Key,查询然后删除.
    String key = StringUtils.format(RECORD_KEY_TEMPLATE, lessonId);  
    redisTemplate.opsForHash().delete(key, sectionId.toString());  
}
```

### 4.5 异步延迟任务
- @PostConstructor:当前**类实例化后且属性注入后执行**,常用来做初始化!
- `CompletableFuture.runAsync(this::handleDelayTask)`:会**开启一个新线程**来执行任务handleDelayTask任务.
- @PreDestory:当前**类实例销毁前执行**.
```java
@PostConstruct  
public void init(){  
    CompletableFuture.runAsync(this::handleDelayTask);  
}  
@PreDestroy  
public void destroy(){  
    log.debug("关闭学习记录处理的延迟任务");  
    begin = false;  
}  
private void handleDelayTask(){  
    while (begin){  
        try {  
            // 1.尝试获取任务: 阻塞式拉取任务
            DelayTask<RecordTaskData> task = queue.take();  
            log.debug("获取到要处理的播放记录任务");  
            RecordTaskData data = task.getData();  
            // 2.读取Redis缓存  
            LearningRecord record = readRecordCache(data.getLessonId(), data.getSectionId());  
            if (record == null) {  
                continue;  
            }  
            // 3.比较数据:拿Redis中的播放记录与任务中的播放记录进行比较!
            if(!Objects.equals(data.getMoment(), record.getMoment())){  
                // 4.如果不一致，播放进度在变化，无需持久化  
                continue;  
            }  
            // 5.如果一致，证明用户离开了视频，需要持久化: 更新数据库
            // 5.1.更新学习记录  
            record.setFinished(null);  
            recordMapper.updateById(record);  
            // 5.2.更新课表  
            LearningLesson lesson = new LearningLesson();  
            lesson.setId(data.getLessonId());  
            lesson.setLatestSectionId(data.getSectionId());  
            lesson.setLatestLearnTime(LocalDateTime.now());  
            lessonService.updateById(lesson);  
  
            log.debug("准备持久化学习记录信息");  
        } catch (Exception e) {  
            log.error("处理播放记录任务发生异常", e);  
        }  
    }  
}
```

### 4.6 源代码改造
需要改造的部分一共有以下几个:
![[Pasted image 20240919234412.png|450]]
#### 4.6.1 改造"查询学习记录":
![[Pasted image 20240919234236.png]]
原思路:直接查询数据库,判断记录是否存在. 
改造后思路:
1. 先查询缓存;
2. 若命中,则直接返回缓存数据;
2. 若未命中,则再查询数据库,并将数据库中的数据写入缓存!

```java
private LearningRecord queryOldRecord(Long lessonId, Long sectionId) {
	// 1.查询缓存
	LearningRecord cache = taskHandler.readRecordCache(lessonId, sectionId);
	// 2.如果命中，直接返回
	if (record != null) {
		return cache;
	}
	// 3.未命中，查询数据库
	LearningRecord dbRecord = lambdaQuery()
			.eq(LearningRecord::getLessonId, lessonId)
			.eq(LearningRecord::getSectionId, sectionId)
			.one();
	// 若数据库中的数据也为空,则返回null以便后面判断通过,以新增学习逻辑.
	if (record == null){
		return null;
	}
	// 4.写入缓存
	taskHandler.writeRecordCache(record);
	return record;
}
```
#### 4.6.2 改造"是否是第一次学完":
![[Pasted image 20240920000538.png]]
改造后思路:
- 若非第一次学完,则缓存学习记录到Redis;(调用4.2中的addLearningRecordTask方法)'
	- 封装LearningRecord对象;
- 若为第一次学完,则更新学习记录,并清楚缓存(即播放记录)
- 并提交延迟任务;
```java hl:5-13,26
        // 4.存在，则更新
        // 4.1.判断是否是第一次完成
        boolean finished = !old.getFinished() && recordDTO.getMoment() * 2 >= recordDTO.getDuration();
        if (!finished) {
            LearningRecord record = new LearningRecord();
            record.setLessonId(recordDTO.getLessonId());
            record.setSectionId(recordDTO.getSectionId());
            record.setMoment(recordDTO.getMoment());
            record.setId(old.getId());
            record.setFinished(old.getFinished());
            // 提交延迟任务
            taskHandler.addLearningRecordTask(record);
            return false;
        }
        // 4.2.更新数据
        boolean success = lambdaUpdate()
                .set(LearningRecord::getMoment, recordDTO.getMoment())
                .set(LearningRecord::getFinished, true)
                .set(LearningRecord::getFinishTime, recordDTO.getCommitTime())
                .eq(LearningRecord::getId, old.getId())
                .update();
        if (!success) {
            throw new DbException("更新学习记录失败！");
        }
        // 4.3.清理缓存
        taskHandler.cleanRecordCache(recordDTO.getLessonId(), recordDTO.getSectionId());
        return true;
```

## 5.1.线程池的使用

目前我们的延迟任务执行还是单线程模式,大家将其改造为线程池模式,核心线程数与CPU核数一致即可.
### 创建线程池的方式
不建议,会出现OutOfMemory异常!
(因为**无法指定内部BlockQueue的容量**,故可能因为任务量太大而导致内存溢出!)
`Executors.newFixedThreadPool()`:创建固定线程的线程池
`Executors.newSingleThreadPool()`:创建单线程的线程池
`Executors.newCachedThreadPool()`:创建缓存线程池
`Executors.newScheduledThreadPool()`:创建可执行延迟任务的线程池

上述四个创建方式的**底层**都是:
`new ThreadPoolExecutor(corePoolSize, maximumPoolSize, KeepAliveTime, TimeUnit, BlockQueue)`
**参数设置建议:**
1. 如果任务属于CPU运算型任务,推荐核心线程为CPU的核数.
2. 如果任务属于IO型(读写型) ,推荐核心线程为CPU核数的两倍.

### 线程池的使用:
- 调用线程池的submit方法,传入Runnable类的对象,并实现其run方法.
```
poolExecutor.submit(new Runnable(){
	@Override
	public void run(){
		// 需要执行任务
	}
})
```
### 线程池的执行流程:
![[Pasted image 20240920200013.png|450]]
1. 若有空闲核心线程,则调用线程执行任务;
2. 若核心线程已满,则进入阻塞队列排队,等待核心线程执行;
3. 若队列也已满,则会创建临时线程执行;
4. 若临时线程也已满,则会走拒绝策略!


# Day06:
## 1. 业务流程:
![[Pasted image 20240920221310.png|450]]

我们说过点赞服务必须独立，因此必须抽取为一个**独立服务**。多个其它微服务业务的点赞数据都有点赞系统来维护。
	如果业务方需要根据点赞数排序，就必须在数据库中维护点赞数字段。但是**点赞系统无法修改其它业务服务的数据库，否则就出现了业务耦合**。该怎么办呢？
**解决方法:**
![[Pasted image 20240920221823.png]]
## 2. 表设计:
点赞记录本质就是记录**谁给什么内容点了赞**，所以核心属性包括：
- 点赞目标id
- 点赞人id
不过点赞的内容多种多样，为了加以区分，我们还需要把**点赞的内容类型**记录下来：
- 点赞对象类型（为了通用性）
![[Pasted image 20240920222127.png]]

其中,user_id和biz_id为联合唯一索引,保证用户只能点赞该业务一次!
![[Pasted image 20240920222502.png]]

## 3. 实现点赞功能:
前端需要根据**是否点赞过**来相应的渲染点赞按钮,即灰色和点亮,所以需要实现**查询用户点赞状态**的接口,用于判断该用户是否点赞过该业务.因此需要实现两个接口:
1) 点赞/取消点赞
2) 根据多个业务id批量查询用户是否点赞多个业务
### 3.1.点赞或取消点赞
### 3.1.1.接口信息
点赞就是新增一条点赞记录，取消就是删除这条记录,可合并为同一个接口,便于前端交互. 所以**请求参数**首先要包含点赞相关的数据:
1) 用户id(ThreadLocal中,由jwt令牌(token)传递);
2) 业务类型(是问答还是评论)->**用于确保点赞功能的通用性!**
3) 业务id;
4) 是否点赞

返回值有两种设计：
- 方案一：无返回值，200就是成功，页面直接把点赞数+1展示给用户即可
- 方案二：返回点赞数量，页面渲染
这里推荐使用方案一，因为每次**统计点赞数量也有很大的性能消耗**。

综上,接口信息如下:
![[Pasted image 20240921093338.png]]
### 3.1.2 业务流程
点赞业务的几点需求：
- 点赞就新增一条点赞记录，取消点赞就删除记录
- 用户不能重复点赞
- **点赞数由具体的业务方保存，需要通知业务方更新点赞数**
	- 通过MQ实现,减少了每次点赞都需要统计点赞数量造成的大性能消耗.
![[Pasted image 20240921092926.png]]

业务方有两个:回答或者评论. 根据MQ通知业务方时,由于**每次点赞的业务类型不同，所以没有必要通知到所有业务方，而是仅仅通知与当前点赞业务关联的业务方即可**。

在RabbitMQ中，利用**TOPIC类型的交换机**，结合**不同的RoutingKey**，可以实现通知对象的变化。我们需要让**不同的业务方监听不同的RoutingKey**，然后发送通知时根据点赞类型不同，发送不同RoutingKey:
![[Pasted image 20240921093721.png]]

### 3.1.3 完整业务代码实现:
梳理业务逻辑:
1) 是点赞还是取消点赞;
2.1) 走点赞逻辑 -> 代码中为`like(recordDTO)`方法
	 新增点赞记录
2.2) 取消赞逻辑 -> 代码中为`unlike(recordDTO)`方法
	 删除点赞记录;
3) 统计该业务id下的总点赞数量 -> 根据业务id来统计
4) 发送消息到MQ ->参数为交换机,RoutingKey和消息内容.
	```java
	mqHelper.send(
	LIKE_RECORD_EXCHANGE,
	StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, recordDTO.getBizType()),
	LikedTimesDTO.of(recordDTO.getBizId(), likedTimes));
	```

```java
/**
 * <p>
 * 点赞记录表 服务实现类
 * </p>
 */
@Service
@RequiredArgsConstructor
public class LikedRecordServiceImpl extends ServiceImpl<LikedRecordMapper, LikedRecord> implements ILikedRecordService {

    private final RabbitMqHelper mqHelper;

    @Override
    public void addLikeRecord(LikeRecordFormDTO recordDTO) {
        // 1.基于前端的参数，判断是执行点赞还是取消点赞
        boolean success = recordDTO.getLiked() ? like(recordDTO) : unlike(recordDTO);
        // 2.判断是否执行成功，如果失败，则直接结束
        if (!success) {
            return;
        }
        // 3.如果执行成功，统计点赞总数
        Integer likedTimes = lambdaQuery()
                .eq(LikedRecord::getBizId, recordDTO.getBizId())
                .count();
        // 4.发送MQ通知
        mqHelper.send(
                LIKE_RECORD_EXCHANGE,
                StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, recordDTO.getBizType()),
                LikedTimesDTO.of(recordDTO.getBizId(), likedTimes));
    }

    private boolean unlike(LikeRecordFormDTO recordDTO) {
        return remove(new QueryWrapper<LikedRecord>().lambda()
                .eq(LikedRecord::getUserId, UserContext.getUser())
                .eq(LikedRecord::getBizId, recordDTO.getBizId()));
    }

    private boolean like(LikeRecordFormDTO recordDTO) {
        Long userId = UserContext.getUser();
        // 1.查询点赞记录
        Integer count = lambdaQuery()
                .eq(LikedRecord::getUserId, userId)
                .eq(LikedRecord::getBizId, recordDTO.getBizId())
                .count();
        // 2.判断是否存在，如果已经存在，直接结束
        if (count > 0) {
            return false;
        }
        // 3.如果不存在，直接新增
        LikedRecord r = new LikedRecord();
        r.setUserId(userId);
        r.setBizId(recordDTO.getBizId());
        r.setBizType(recordDTO.getBizType());
        save(r);
        return true;
    }
}
```

## 4. 批量查询点赞状态
### 4.0 Feign拦截器
Feign拦截器会在微服务间通过Feign实现远程调用时,校验ThreadLoca中是否包含userId,如果有则放入Feign请求的请求头中!
	Feign是一个声明式的HTTP客户端,主要作用是**简化服务间的HTTP调用**.通过Feign,开发者可以像调用本地方法一样调用远程服务,无需编写复杂的HTTP请求处理逻辑.
![[Pasted image 20240922112321.png]]
**具体代码实现如下:** 
- `UserContext.getUser()`即是将从ThreadLocal中获取userId封装起来了.
- `template.header`就是重新放入Feign请求头中!
```java
public class FeignRelayUserInterceptor implements RequestInterceptor {  
    @Override  
    public void apply(RequestTemplate template) {  
        Long userId = UserContext.getUser();  
        if (userId == null) {  
            return;  
        }  
        template.header(JwtConstants.USER_HEADER, userId.toString());  
    }  
}
```

### 4.1 暴露Feign接口
为了其他微服务能调用该接口,必须**暴露Feign客户端**,并定义好**fallback降级处理**.

#### 4.1.1 为接口创建client客户端:
1. 在`tj-api.com.tianji.api.client.remark`中创建RemarkClient,拷贝Controller中的isBizLiked方法,即查询点赞状态的服务.
	**`@FeignClient` 注解:**
		`value="remark-service"`,即被调用的服务名(注册在nacos中的名字)
		fallbackFactory="RemarkClientFallback.class"
	**`@fallbackFactory`注解**: 指定降级处理类!
```Java
@FeignClient(value = "remark-service", fallbackFactory = RemarkClientFallback.class)
public interface RemarkClient {
    @GetMapping("/likes/list")
    Set<Long> isBizLiked(@RequestParam("bizIds") Iterable<Long> bizIds);
}
```

#### 4.1.2 Feign降级处理:
![[Pasted image 20240921192054.png|450]]
因为微服务之间的长调用链路,当C挂掉时,B无法调用C就会一直等待,此时B中存在大量阻塞线程,直到超时,并导致B也挂掉,同理也会导致A,D也挂掉! 即**雪崩(级联失败)现象**!
此时引入**降级处理**,当C挂掉时,B不会一直等待,而是在等待一定时间后,走C的降级处理类,并返回假数据,此时B就不会阻塞,避免了雪崩出现.

**实现:**
1. 引入open-feign与sentinel依赖!
2. 在`~.client.remark`中创建子包fallback,并创建降级处理类`RemarkClientFallback`,**实现`FallbackBackFactory<T>`接口,重写create(Throwable cause)方法,返回Feign客户端!**
```java
@Slf4j
public class RemarkClientFallback implements FallbackFactory<RemarkClient> {

    @Override
    public RemarkClient create(Throwable cause) {
        log.error("查询remark-service服务异常", cause);
        return new RemarkClient() {

            @Override
            public Set<Long> isBizLiked(Iterable<Long> bizIds) {
                return CollUtils.emptySet();
            }
        };
    }
}
```
3. 编写FallbackConfig配置类与nacos中的shared-feign配置类(开启sentinel)
```Java 
@Configuration
public class FallbackConfig {
    @Bean
    public RemarkClientFallback remarkClientFallback(){
        return new RemarkClientFallback();
    }
}
```

```yaml
feign:
	sentinel:
		enabled: true
```

### 4.1.3 监听点赞变更的消息
当用户点赞后,会发送MQ消息到相应的业务方!以互动问答为例,需要**定义MQ监听器,自动监听消息队列中的消息并进行消费!

在learning模块中创建mq包,创建`LikeTimesChangeListener监听器`,并加上`@Component`注解交由Spring容器管理.注入`replyService`,以实现对数据库的更新操作!
**加上@RabbitListener注解:**
	`value = @Queue(name = "qa.liked.times.queue", durable = "true")`: **定义一个名称为`qa.liked.times.queue`的持久化队列!**
	`exchange = @Exchange(name = "likeRecordExchange", type = ExchangeTypes.TOPIC), key = "qa.liked.times`: 将队列绑定到`likeRecordExchange`交换机上,使用路由键`QA_LIKED_TIMES_KEY`来路由消息.
		**exchange的属性都在其他地方定义!** 
	
```java
@Slf4j
@Component
@RequiredArgsConstructor
public class LikeTimesChangeListener {

    private final IInteractionReplyService replyService;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "qa.liked.times.queue", durable = "true"),
            exchange = @Exchange(name = LIKE_RECORD_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = QA_LIKED_TIMES_KEY
    ))
    public void listenReplyLikedTimesChange(LikedTimesDTO dto){
        log.debug("监听到回答或评论{}的点赞数变更:{}", dto.getBizId(), dto.getLikedTimes());
        InteractionReply r = new InteractionReply();
        r.setId(dto.getBizId());
        r.setLikedTimes(dto.getLikedTimes());
        replyService.updateById(r);
    }
}
```
## 5. 点赞功能改进
点赞业务包含多次数据库读写操作,当点赞的用户,次数过多时,会造成数据库压力过大!当有人非常频繁的点赞、取消点赞.这样就会给数据库带来非常大的压力。
![[Pasted image 20240921201954.png]]

### 5.1 改进思路分析:
在前面改进"更新学习记录"功能时,就是利用了合并写请求的优化方案,使用Redis作缓存,以及MQ异步写来实现减少写操作.
然而,**此处虽然用了MQ异步写,此处更重要的是利用MQ来解耦(通过MQ来通知其他业务执行更新操作)**,数据库写的次数并没有减少,压力依旧很大!!!

此处,我们依然采用合并写请求的方案,并且保留异步处理,做到兼顾**异步写**、**合并写**的优势.但是,合并写请求必须是对中间的N次写操作不敏感!

>**无论用户中间执行点赞、取消、再点赞、再取消多少次，点赞次数发生了多少次变化，业务方只关注最终的点赞结果即可：**
- 用户是否点赞了
- 业务的总点赞次数
因此,点赞功能可以使用合并写方案!业务流程如下:
![[Pasted image 20240921224725.png]]
![[Pasted image 20240921225638.png]]
合并写请求有两个关键点要考虑：
- 数据如何缓存
- 缓存何时写入数据库

#### 5.1.1 点赞数据缓存
使用Redis记录缓存,需要决定: 
1)存储什么信息?
2)使用哪种结构存储;
3)KEY和VALUE是什么?

点赞中最重要的两条信息: **1)用户是否点赞; 2)某业务的点赞总次数**
##### 5.1.1.1 用户是否点赞
记录某个用户是否点赞了某个业务,参考数据库的表字段,可以知道需要 1)业务id; 2)给该业务点赞的所有用户的id. 并且业务可被多用户点赞, 所以需要集合来存储: List,Set,SortedSet,Hash.

而要判断用户是否点赞，就是判**断存在且唯一**。显然，Set集合是最合适的。我们可以用**业务id为Key，创建Set集合，将点赞的所有用户保存其中**，格式如下：
![[Pasted image 20240921230543.png]]

由于**Redis本身具备持久化机制**，**AOF提供的数据可靠性已经能够满足点赞业务的安全需求**，因此我们完全可以用Redis存储来代替数据库的点赞记录。

也就是说，用户的一切点赞行为，以及将来查询点赞状态我们可以都走Redis，**不再使用数据库查询.**

>[!Redis与数据库结合的思路]
>-  先利用Redis来记录点赞状态,并且**定期的**将Redis中的点赞状态持久化到数据库.
> 	 | 使用定时任务实现!(例如SpringTask)
>- 对于历史点赞记录，比如下架的课程、或者超过2年以上的访问量较低的数据都可以从redis移除，只保留在数据库中.
>- 当某个记录点赞时，优先去Redis查询并判断，如果Redis中不存在，再去查询数据库数据并缓存到Redis.

##### 5.1.1.2 点赞次数
对于点赞次数,需要持久化存储到业务方,故仍需使用数据库存储,**Redis只起缓存作用**即可!
点赞次数需要记录以下几个数据:①业务类型,②业务id,③点赞次数.
>(此处业务类型与业务id是区分开的,即对应数据库中的两个字段,感觉变成同一个字段也可以!类似于lesson_id为user_id与course_id)

根据需要存储的数据,可以使用2种结构进行存储:
- Hash:传统键值对集合，无序
- SortedSet：基于Hash结构，并且增加了跳表。因此**可排序**，但更占用内存.

如果是从节省内存角度来考虑，Hash结构无疑是最佳的选择；但是考虑到将来我们要**从Redis读取点赞数，然后移除（避免重复处理）**。为了**保证线程安全，查询、移除操作必须具备原子性**。而==**SortedSet则提供了几个移除并获取的功能，天生具备原子性**==。并且我们每隔一段时间就会将数据从Redis移除，并不会占用太多内存。因此，这里我们计划使用SortedSet结构:
![[Pasted image 20240921232539.png]]

#### 5.1.2 点赞数据入库
点赞数据写入缓存了，但是这里有一个新的问题：
**何时把缓存的点赞数，通过MQ通知到业务方，持久化到业务方的数据库呢？**

>前面的播放记录是每隔15秒发送一次请求,频率固定,故可以采用接收到播放记录后20秒检测数据变更来确定是否有新数据到达.

点赞任务具有随机性,无法判断用户何时点赞,点赞频率如何,故无法采用延迟手段!!!
	**这也是大多数合并写请求业务所面临的问题!**
我们在这采用定时任务,**定时将缓存的数据持久化到数据库**中!

#### 5.1.3 流程图
改造后的流程图如下:
![[Pasted image 20240921232928.png]]

### 5.2 改造点赞逻辑
需要改造的内容包括：
- `tj-remark`中所有点赞有关接口
    - 点赞接口(like,unlike方法)
    - 查询单个点赞状态
    - 批量查询点赞状态
- `tj-remark`处理点赞数据持久化的定时任务
- `tj-learning`监听点赞数变更消息的业务

#### 5.2.1 点赞接口

```java hl:22-23,16,27-31
/**
 * <p>
 * 点赞记录表 服务实现类
 * </p>
 */
@Service
@RequiredArgsConstructor
public class LikedRecordServiceRedisImpl extends ServiceImpl<LikedRecordMapper, LikedRecord> implements ILikedRecordService {

    private final RabbitMqHelper mqHelper;
    private final StringRedisTemplate redisTemplate;

    @Override
    public void addLikeRecord(LikeRecordFormDTO recordDTO) {
        // 1.基于前端的参数，判断是执行点赞还是取消点赞
        boolean success = recordDTO.getLiked() ? like(recordDTO) : unlike(recordDTO);
        // 2.判断是否执行成功，如果失败，则直接结束
        if (!success) {
            return;
        }
        // 3.如果执行成功，统计点赞总数
        Long likedTimes = redisTemplate.opsForSet()
                .size(RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId());
        if (likedTimes == null) {
            return;
        }
        // 4.使用ZSET缓存某业务点赞总数到Redis
        redisTemplate.opsForZSet().add(
                RedisConstants.LIKES_TIMES_KEY_PREFIX + recordDTO.getBizType(),
                recordDTO.getBizId().toString(),
                likedTimes
        );
    }

    private boolean unlike(LikeRecordFormDTO recordDTO) {
        // 1.获取用户id
        Long userId = UserContext.getUser();
        // 2.获取Key
        String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId();
        // 3.执行SREM命令
        Long result = redisTemplate.opsForSet().remove(key, userId.toString());
        return result != null && result > 0;
    }

    private boolean like(LikeRecordFormDTO recordDTO) {
        // 1.获取用户id
        Long userId = UserContext.getUser();
        // 2.获取Key
        String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId();
        // 3.执行SADD命令
        Long result = redisTemplate.opsForSet().add(key, userId.toString());
        return result != null && result >  0;
    }
}
```

#### 5.2.2 批量查询点赞状态统计
该接口是根据用户id查询对多个业务的点赞状态,而根据前面的点赞表结构(Set),只能使用`SISMEMBER bizId userId`来查询单个业务中该用户是否点赞.
![[Pasted image 20240921234029.png|400]]
所以为了实现该接口功能,一个方法就是多次执行ISMEMBER命令,也就**需要向Redis多次发起网络请求,给网络带宽带来非常大的压力**,影响业务性能。
	并且只有这种办法...!!!

并且,Redis提供了Pipeline功能,可用于在**一次请求中执行多个命令**,减小对网络带宽的压力.
>**不要在一次批处理中传输太多命令，否则单次命令占用带宽过多，会导致网络阻塞**

使用Pipeline功能改造获得的批量查询点赞状态的功能代码如下:
```Java hl:5-10,15-18
@Override
public Set<Long> isBizLiked(List<Long> bizIds) {
    // 1.获取登录用户id
    Long userId = UserContext.getUser();
    // 2.查询点赞状态
    List<Object> objects = redisTemplate.executePipelined((RedisCallback<Object>) connection -> {
        StringRedisConnection src = (StringRedisConnection) connection;
        for (Long bizId : bizIds) {
            String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + bizId;
            src.sIsMember(key, userId.toString());
        }
        return null;
    });
    // 3.返回结果
    return IntStream.range(0, objects.size()) // 创建从0到集合size的流
            .filter(i -> (boolean) objects.get(i)) // 遍历每个元素，保留结果为true的角标i
            .mapToObj(bizIds::get)// 用角标i取bizIds中的对应数据，就是点赞过的id
            .collect(Collectors.toSet());// 收集
}
```

#### 5.2.3 定时任务
需要**定时读取这些点赞总数的变更数据**,通过MQ发送给业务方.
![[Pasted image 20240922001508.png|]]

1. 启动类上添加@EnableScheduling注解,开启定时任务功能!
2. 编写定时任务类`LikedTimesCheckTask`:
	`@Scheduled(fixedDelay = 20000)`:每隔20秒执行一次!
	`@Scheduled(cron = "0/20 * * * * ?)`:也是每隔20秒执行一次!
```Java
@Component
@RequiredArgsConstructor
public class LikedTimesCheckTask {

    private static final List<String> BIZ_TYPES = List.of("QA", "NOTE");
    private static final int MAX_BIZ_SIZE = 30;

    private final ILikedRecordService recordService;

    @Scheduled(fixedDelay = 20000)
    public void checkLikedTimes(){
        for (String bizType : BIZ_TYPES) {
            recordService.readLikedTimesAndSendMessage(bizType, MAX_BIZ_SIZE);
        }
    }
}
```

1. service层中实现具体逻辑:
   - `popMin(KEY,SIZE)`:返回SIZE条分数较小的数据的集合.(集合为VALUE-SCORE)
      - tuple为`<bizeId,likedTimes>集合`,从中获取单个业务id和点赞次数,然后封装到`LikedTimesDTO`中,并添加到集合中!
   - 发送MQ消息: 将多组数据通过MQ一次性发送到业务方.list中存储了maxBizSize个业务id及其点赞次数!
```Java hl:11-17
@Override
public void readLikedTimesAndSendMessage(String bizType, int maxBizSize) {
    // 1.读取并移除Redis中缓存的点赞总数
    String key = RedisConstants.LIKES_TIMES_KEY_PREFIX + bizType;
    Set<ZSetOperations.TypedTuple<String>> tuples = redisTemplate.opsForZSet().popMin(key, maxBizSize);
    if (CollUtils.isEmpty(tuples)) {
        return;
    }
    // 2.数据转换
    List<LikedTimesDTO> list = new ArrayList<>(tuples.size());
    for (ZSetOperations.TypedTuple<String> tuple : tuples) {
        String bizId = tuple.getValue();
        Double likedTimes = tuple.getScore();
        if (bizId == null || likedTimes == null) {
            continue;
        }
        list.add(LikedTimesDTO.of(Long.valueOf(bizId), likedTimes.intValue()));
    }
    // 3.发送MQ消息
    mqHelper.send(
            LIKE_RECORD_EXCHANGE,
            StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, bizType),
            list);
}
```

>注意:这里MQHelper的`send()`方法的参数为泛型,所以既可以传递likedTimesDTO,也可以传递list集合! 前者单次更新一个业务的点赞次数,后者批量更新多个业务![[Pasted image 20240922004406.png]]

#### 5.2.4 监听点赞数变更
对MQ消息队列中的`list<LikedTimesDTO>`中的每个LikedTimesDTO对象,将其封装成`InteractionReply对象`,然后添加到list中,**批量更新**数据库中的`interaction_reply`表.
	执行批量更新,避免利用循环每次执行单条更新语句,这样效率低且对数据库压力大.
```Java hl:16-23
@Slf4j
@Component
@RequiredArgsConstructor
public class LikeTimesChangeListener {

    private final IInteractionReplyService replyService;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "qa.liked.times.queue", durable = "true"),
            exchange = @Exchange(name = LIKE_RECORD_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = QA_LIKED_TIMES_KEY
    ))
    public void listenReplyLikedTimesChange(List<LikedTimesDTO> likedTimesDTOs){
        log.debug("监听到回答或评论的点赞数变更");

        List<InteractionReply> list = new ArrayList<>(likedTimesDTOs.size());
        for (LikedTimesDTO dto : likedTimesDTOs) {
            InteractionReply r = new InteractionReply();
            r.setId(dto.getBizId());
            r.setLikedTimes(dto.getLikedTimes());
            list.add(r);
        }
        replyService.updateBatchById(list);
    }
}
```

# Day07-积分系统
## 1. 签到功能
### 1.1 思路分析
签到功能组合新的两个要素:**1)谁签到:用户id; 2)什么时候签到的:签到日期**. 再补充一些功能要素: 补签功能,按照年月统计签到.
综上可得ER图:
![[Pasted image 20240922140709.png|450]]
若签到功能使用int(4字节)或者boolean进行存储,则在用户量增大的情况下可能会导致占用存储空间过大! 而签到功能只有两种状态:签到/未签到, 则可使**用BitMap进行存储, 用一行二进制数字来表示该用户一个月的签到记录.**(一个月最多31位,大大节省空间!)
### 1.2 BitMap用法
BitMap数据结构是基于String数据结构实现的.**Redis的String类型底层是SDS**，也会**存在一个字节数组用来保存数据**。而Redis就提供了几个按位操作这个数组中数据的命令，实现了BitMap效果。
#### Redis命令
>注意,偏移量OFFSET均从0开始.(偏移量为0就代表第一位)
- `SETBIT KEY OFFSET VALUE`: 修改某位上的数据. value为1或0.
	- **返回值为该位上原来的值!**
- `BITFIELD KEY GET ENCODING OFFSET`:
	- encoding：返回结果的编码方式，BitMap中是二进制保存，而返回结果会转为10进制，但需要一个转换规则，也就是这里的编码方式
    - u:无符号整数,例如 u2，代表读2个bit位，转为无符号整数返回
    - i:又符号整数,例如 i2，代表读2个bit位，转为有符号整数返回
	- `BITFIELD bm GET u3 0`:假设bm为11100111,则返回结果为7. 即从第1位开始,读取3个二进制数字,转换为无符号整数返回.
		- 若为`BITFIELD bm GET i3 0`,则仍是取111,但此时其补码为除符号位外,原码取反+1,即补码为101,十进制值为-1.
#### RedisTemplate操作BitMap命令:
- `redisTemplate.opsForValue.setBit(KEY,OFFSET,VALUE)`:设置某位的值,返回值为该位原来的值(布尔类型).
- `redisTemplate.opsForValue.bitField(KEY,BitFieldSubCommands subCommands)`
	- 偏移量为0,取前3位,转换为有符号整数. 返回值为list,利用get(0)取第一个就是结果.
```java
redisTemplate.opsForValue.bitField(KEY,
			   BitFieldSubCommands
			   .create()
			   .getCommands(BitFieldSubCommands.BitFieldType.signed(3))
			   .valueAt(0));
```

### 1.3 签到接口
在个人中心的积分页面，用户**每天都可以签到一次**，**连续签到则有积分奖励**，请实现签到接口，**记录用户每天签到信息**，方便做签到统计。

#### 1.3.1 接口设计和分析
签到记录用BitMap进行存储,为**每个用户每个月的签到记录都生成一个KEY**.KEY值需要包含用户id与年月,故为`sign:uid:xxx:202401`,

更新签到记录,需要知道是**哪个用户在什么时间签到(可通过ThreadLocal和LocalDateTime**获得,并且因为连续签到有积分奖励,所以这里需要返回**连续签到天数**以及**今日签到获得的积分值**.
![[Pasted image 20240922220610.png]]

#### 1.3.2 实体
使用VO封装返回参数:
额外多了一个签到得分,因为签到默认获得一分.
```java
@Data
@ApiModel(description = "签到结果")
public class SignResultVO {
    @ApiModelProperty("连续签到天数")
    private Integer signDays;
    @ApiModelProperty("签到得分")
    private Integer signPoints = 1;
    @ApiModelProperty("连续签到奖励积分，连续签到超过7天以上才有奖励")
    private Integer rewardPoints;

    @JsonIgnore
    public int totalPoints(){
        return signPoints + rewardPoints;
    }
}

```

#### 1.3.3 连续签到统计
>从最后一次签到开始,向前统计,直到遇到第一次未签到为止,计算总的签到次数,就是连续签到天数.![[Pasted image 20240922222807.png]]

存在两个问题:
1) 如何获得本月到今天截止的所有签到数据?
	`BITFIELD KEY GET u[dayOfMonth] 0`,实现获取到今天为止的所有位数,并转换为无符号整数返回.
2) ==**如何从后向前遍历每个bit位?**==
	 1. 将当月签到数据**与1做与运算**,即可获得最后一个bit位,即当天的签到记录;
	$$
	\begin{aligned}
	10011\\
	\frac{00001}{00001} \\
	\end{aligned}
	$$
	 2. 将签到数据右移一位,重复执行步骤1,即可获得前一天的签到记录.以此类推..
#### 1.3.4 实现接口
```Java hl:49-66
@Service
@RequiredArgsConstructor
public class SignRecordServiceImpl implements ISignRecordService {

    private final StringRedisTemplate redisTemplate;

    @Override
    public SignResultVO addSignRecords() {
        // 1.签到
        // 1.1.获取登录用户
        Long userId = UserContext.getUser();
        // 1.2.获取日期
        LocalDate now = LocalDate.now();
        // 1.3.拼接key
        String key = RedisConstants.SIGN_RECORD_KEY_PREFIX
                + userId
                + now.format(DateUtils.SIGN_DATE_SUFFIX_FORMATTER);
        // 1.4.计算offset
        int offset = now.getDayOfMonth() - 1;
        // 1.5.保存签到信息
        Boolean exists = redisTemplate.opsForValue().setBit(key, offset, true);
        if (BooleanUtils.isTrue(exists)) {
            throw new BizIllegalException("不允许重复签到！");
        }
        // 2.计算连续签到天数
        int signDays = countSignDays(key, now.getDayOfMonth());
        // 3.计算签到得分
        int rewardPoints = 0;
        switch (signDays) {
            case 7:
                rewardPoints = 10;
                break;
            case 14:
                rewardPoints = 20;
                break;
            case 28:
                rewardPoints = 40;
                break;
        }
        // TODO 4.保存积分明细记录 
        
        // 5.封装返回
        SignResultVO vo = new SignResultVO();
        vo.setSignDays(signDays);
        vo.setRewardPoints(rewardPoints);
        return vo;
    }
							\\ len为截止到当天的天数
    private int countSignDays(String key, int len) {
        // 1.获取本月从第一天开始，到今天为止的所有签到记录
        List<Long> result = redisTemplate.opsForValue()
                .bitField(key, BitFieldSubCommands.create().get(
                        BitFieldSubCommands.BitFieldType.unsigned(len)).valueAt(0));
        if (CollUtils.isEmpty(result)) {
            return 0;
        }
        int num = result.get(0).intValue();
        // 2.定义一个计数器
        int count = 0;
        // 3.循环获取最后一个bit位,直到为0(即未签到)
        while ((num & 1) == 1) {
            // 4.计数器+1
            count++;
            // 5.把数字右移一位，最后一位被舍弃，倒数第二位成了最后一位
	        // >>> 为无符号右移.
			num >>>= 1; // -> num = num >>> 1
        }
        return count;
    }
}
```

## 2. 积分功能
用户签到、学习、参与互动问答、提交学习笔记等行为都可以产生积分，并基于积分形成排行榜。积分当月有效，月底清零。
### 2.1 新增积分
签到,写评价,写问答,写笔记都可以增加积分,所以为了避免耦合,采用异步的方式,将原有业务与业务解耦.

#### 2.1.1 思路分析
异步解耦的方式有很多，比如：
- 利用Spring的`@EventListener`功能:往往在同一个服务内使用
- 利用MQ:往往用在跨服务业务中使用

不同业务都有新增积分的功能,因此可以定义不同的RoutingKey用来传递不同的MQ消息.
![[Pasted image 20240922235610.png]]
**积分记录表结构:**
![[Pasted image 20240923000109.png|450]]

考虑到积分记录需要记录新增积分,所以需要以下参数:
1)用户id;
2)积分值: 通过MQ消息传递;
3)积分类型: 可以根据不同的RoutingKey进行判断 
4)新增积分时间: 即当前时间.
#### 2.1.2 发送MQ消息
改造签到接口,添加"新增积分"功能.
- 签到完成后,使用mqHelper发送mq消息到`tj-learning`(积分记录表在`tj-learning`中)
	- 消息接收方通过交换机`MqConstants.Exchange.LEARNING_EXCHANGE`定义;
	- 消息类型通过`RoutingKey:MqConstants.Key.SIGN_IN`来定义;
	- 消息内容封装为`SignInMessage`.
```java
        // 4.保存积分明细记录
        mqHelper.send(
                MqConstants.Exchange.LEARNING_EXCHANGE,
                MqConstants.Key.SIGN_IN,
                SignInMessage.of(userId, rewardPoints + 1));// 签到积分是基本得分+奖励积分
```

#### 2.1.3 编写消息监听器
```Java 
@Component
@RequiredArgsConstructor
public class LearningPointsListener {

    // 监听签到的新增积分
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "sign.points.queue", durable = "true"),
            exchange = @Exchange(name = MqConstants.Exchange.LEARNING_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = MqConstants.Key.SIGN_IN
    ))
    public void listenSignInMessage(SignInMessage message){
    // 在service中具体实现保存积分记录操作.
        recordService.addPointsRecord(message.getUserId(), message.getPoints(), PointsRecordType.SIGN);
    }
}
```

#### 2.1.4 保存积分记录
因为有些业务具有新增积分上限,所以在新增积分前还得**查询今天的新增积分是否达到上限**!
![[Pasted image 20240923000225.png|300]]

```Java
@Override
public void addPointsRecord(Long userId, int points, PointsRecordType type) {
    LocalDateTime now = LocalDateTime.now();
    int maxPoints = type.getMaxPoints();
    // 1.判断当前方式有没有积分上限
    int realPoints = points;
    if(maxPoints > 0) {
        // 2.有，则需要判断是否超过上限
        LocalDateTime begin = DateUtils.getDayStartTime(now);
        LocalDateTime end = DateUtils.getDayEndTime(now);
        // 2.1.查询今日已得积分
        int currentPoints = queryUserPointsByTypeAndDate(userId, type, begin, end);
        // 2.2.判断是否超过上限
        if(currentPoints >= maxPoints) {
            // 2.3.超过，直接结束
            return;
        }
        // 2.4.没超过，保存积分记录
        if(currentPoints + points > maxPoints){
            realPoints = maxPoints - currentPoints;
        }
    }
    // 3.没有，直接保存积分记录
    PointsRecord p = new PointsRecord();
    p.setPoints(realPoints);
    p.setUserId(userId);
    p.setType(type);
    save(p);
}

private int queryUserPointsByTypeAndDate(
        Long userId, PointsRecordType type, LocalDateTime begin, LocalDateTime end) {
  
        // 1.查询条件  
//        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
//        wrapper.lambda()  
//                .eq(PointsRecord::getUserId, userId)  
//                .eq(type != null, PointsRecord::getType, type)  
//                .between(begin != null && end != null, PointsRecord::getCreateTime, begin, end);  
//        // 2.调用mapper，查询结果  
//        Integer points = getBaseMapper().queryUserPointsByTypeAndDate(wrapper);  
//        // 3.判断并返回  
//        return points == null ? 0 : points;  
        // 1. 构建查询语句  
        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
        wrapper.select("sum(points) as totalPoints");  
        wrapper.eq("user_id", userId)  
                .eq("type", type)  
                .between("create_time",begin,end);  
        // 2. 获得查询结果  
        // sum()的返回值为BigDecimal类型.
        Map<String, Object> map = pointsRecordService.getMap(wrapper);  
  
        // 3. 返回查询结果  
        if (map != null){  
            BigDecimal points = (BigDecimal) map.get("totalPoints");  
            return points.intValue();  
        }  
        // 返回值为-1,代表失败.  
        return -1;
}
```
也可以使用MyBatisPlus中的SQL进行查询,即**调用了service层的getMap()方法,并且构建wrapper条件时带上`wrapper.select()`.** 

具体Mapper层中的查询语句:
因为需要调用sum函数,所以**在Mapper层中自定义SQL语句**
```Java
public interface PointsRecordMapper extends BaseMapper<PointsRecord> {

    @Select("SELECT SUM(points) FROM points_record ${ew.customSqlSegment}")
    Integer queryUserPointsByTypeAndDate(@Param(Constants.WRAPPER) QueryWrapper<PointsRecord> wrapper);
}
```
### 2.2 查询今日积分情况
#### 2.2.1 接口分析
在个人中心，用户可以查看**当天**各种**不同类型**的**已获得的积分**和**积分上限**:
![[Pasted image 20240923080225.png|350]]
所以,查询接口如下:
1) 不同类型: 返回类型参数;
2) 已获得积分: 返回该类型对应已获得的积分;
3) 积分上限: 根据类型返回该类型的积分上限.
因为有多种类型,所以返回值应该为`List<PointsStatisticsVO>`,内部包含多个Json字符串.
![[Pasted image 20240923080430.png]]
#### 2.2.2 实现接口
SQL语句如下: 按照类型分组.
```SQL
SELECT type,SUM(points)
FROM points_record
WHERE user_id = ? 
AND create_time 
BETWEEN 'begin' AND end 
GROUP BY type;
```

```Java
    @Override  
    public List<PointsStatisticsVO> queryMyPointsToday() {  
//        1. 用户id  
        Long userId = UserContext.getUser();  
//        2. 构建查询语句: 签到,课程学习,课程评论...  
        LocalDateTime now = LocalDateTime.now();  
        LocalDateTime begin = DateUtils.getDayStartTime(now);  
        LocalDateTime end = DateUtils.getDayEndTime(now) ;  
  
        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
//        利用PointsRecord中的points属性暂存"当日已获得积分"  
        wrapper.select("type,sum(points) as points");  
        wrapper.eq("user_id", userId);  
        wrapper.between("create_time",begin,end);  
        wrapper.groupBy("type");  
        List<PointsRecord> list = pointsRecordService.list(wrapper);  
        if (CollUtils.isEmpty(list)){  
            return CollUtils.emptyList();  
        }  
//        3. 封装结果并返回  
        List<PointsStatisticsVO> res = new ArrayList<>();  
        for (PointsRecord r : list){  
            PointsStatisticsVO vo = new PointsStatisticsVO();  
            vo.setMaxPoints(r.getType().getMaxPoints());  
            vo.setPoints(r.getPoints());  
            vo.setType(r.getType().getDesc()); //getDesc()获取枚举类的String类型  
            res.add(vo);  
        }  
        return res;  
    }
```

# Day08-排行榜系统
 
## 1. 实时排行榜 
### 1.1 思路分析
计算每个用户获得的总积分,可以通过查询积分记录表,对用户进行分组,然后累加已获得积) 分,对应SQL语句为:
`SELECT user_id, sum(points) FROM points_record GROUP BY user_id ORDER BY SUM(points);`

但是这样调用SQL语句进行查询,会对数据库造成很大压力,不太靠谱,因此使用Redis实现.
要**存储赛季**,**用户id**以及**用户对应的积分**三项数据,可以采用SortedSet来实现!
![[Pasted image 20240923220336.png|400]]

### 1.2 生成实时榜单
在原有的新增积分记录的流程上添加"累加积分到Redis"的流程. SortedSet可以实现对Score进行累加(`ZINCRBY key increment member`),而不是替换!
![[Pasted image 20240923220531.png|300]]

#### 1.2.1 更新积分到Redis
- KEY前缀为:`boards:yyyyMM`,对应某一个赛季.
- `incrementScore(key,member,value)`:代表对KEY下的member累加value.
```Java
        // 4.更新总积分到Redis
        String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + now.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);
        redisTemplate.opsForZSet().incrementScore(key, userId.toString(), realPoints);
```

### 1.3 查询积分榜
### 1.3.1 分析和设计接口
在个人中心，学生可以查看**指定赛季积分排行榜(只显示前100)**,还可以查看**自己总积分和排名**。而且**排行榜分为本赛季榜单和历史赛季榜单**. 本赛季排行榜存在于Redis中,而历史赛季排行榜存在于MySQL数据库中.
	本赛季和历史赛季榜单可以视为同一个接口,无非就是传入的赛季id不同!
![[Pasted image 20240923222108.png]]

首先我们分析一下**请求参数**:
- 榜单数据非常多，不可能一次性查询出来，因此这里一定是**分页查询**（滚动分页），需要分页参数。
- 由于要**查询历史榜单需要知道赛季**，因此参数中需要指定赛季id。当赛季id为空，我们认定是查询当前赛季。这样就可以把两个接口合二为一。

然后是返回值，无论是历史榜单还是当前榜单，结构都一样。分为两部分:
- 当前用户的积分和排名。**当前用户不一定上榜，因此需要单独查询**
- 榜单数据。就是**N个用户的积分、排名形成的集合**。

**接口如下:**
![[Pasted image 20240923222506.png]]

#### 1.3.2 实现接口
##### Controller层
- 传入查询条件,分页查询;
- 根据返回参数,使用PointsBoardVO进行封装.
	```Java
	@Data  
	@ApiModel(description = "积分榜单汇总信息")  
		public class PointsBoardVO {  
			@ApiModelProperty("我的榜单排名")  
			private Integer rank;  
			@ApiModelProperty("我的积分值")  
			private Integer points;  
			@ApiModelProperty("前100名上榜人信息")  
			private List<PointsBoardItemVO> boardList;  
		}
	```

```Java
@GetMapping
@ApiOperation("分页查询指定赛季的积分排行榜")
public PointsBoardVO queryPointsBoardBySeason(PointsBoardQuery query){
	return pointsBoardService.queryPointsBoardBySeason(query);
}
```

##### Service层:
- 因为当前赛季的积分排行榜存储在Redis中,而历史赛季存储在MySQL中,所以**根据赛季不同,对应的查询方法也不同**.
- 
```Java hl:9-16,32
@Override  
public PointsBoardVO queryPointsBoardBySeason(PointsBoardQuery query) {  
    // 1.判断是否是查询当前赛季  
    Long season = query.getSeason();  
    boolean isCurrent = season == null || season == 0;  
    // 2.获取Redis的Key  
    LocalDateTime now = LocalDateTime.now();  
    String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + now.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);  
    // 2.查询我的积分和排名  
    PointsBoard myBoard = isCurrent ?  
            queryMyCurrentBoard(key) : // 查询当前榜单（Redis）  
            queryMyHistoryBoard(season); // 查询历史榜单（MySQL）  
    // 3.查询榜单列表  
    List<PointsBoard> list = isCurrent ?  
            queryCurrentBoardList(key, query.getPageNo(), query.getPageSize()) :   
            queryHistoryBoardList(query);  
    // 4.封装VO  
    PointsBoardVO vo = new PointsBoardVO();  
    // 4.1.处理我的信息  
    if (myBoard != null) {  
        vo.setPoints(myBoard.getPoints());  
        vo.setRank(myBoard.getRank());  
    }  
    if (CollUtils.isEmpty(list)) {  
        return vo;  
    }  
    // 4.2.查询用户信息: 1. 获取id表; 2.根据id查询name
    Set<Long> uIds = list.stream().map(PointsBoard::getUserId).collect(Collectors.toSet());  
    List<UserDTO> users = userClient.queryUserByIds(uIds);  
    Map<Long, String> userMap = new HashMap<>(uIds.size());  
    if(CollUtils.isNotEmpty(users)) {  
        userMap = users.stream().collect(Collectors.toMap(UserDTO::getId, UserDTO::getName)); // 返回map,其中key为userId,value为userName 
    }  
    // 4.3.转换VO,用于返回赛季记录.
    List<PointsBoardItemVO> items = new ArrayList<>(list.size());  
    for (PointsBoard p : list) {  
        PointsBoardItemVO v = new PointsBoardItemVO();  
        v.setPoints(p.getPoints());  
        v.setRank(p.getRank());  
        v.setName(userMap.get(p.getUserId()));  
        items.add(v);  
    }  
    vo.setBoardList(items);  
    return vo;  
}
```

- `ZREVRANK key member`:查询key中成员member的排名(由大到小,从0开始);
- `ZSCORE key member`:查询key中成员member的分数.
- `ZREVRANGE key start stop`:查询第start到第stop条数据,起始索引为0.
	- 返回结果为`Set<ZSetOperations.TypedTuple<String>>`.每一个tuple中对应一个`member-score`;
- 通过`rank++`实现对用户排名,因为ZREVRANGE查询本身就是已排序的.
```Java hl:10-23
    public List<PointsBoard> queryCurrentBoardList(String key, Integer pageNo, Integer pageSize) {
        // 1.计算分页
        int from = (pageNo - 1) * pageSize;
        // 2.分页查询: 利用from计算每次查询的起始索引.
        Set<ZSetOperations.TypedTuple<String>> tuples = redisTemplate.opsForZSet()
                .reverseRangeWithScores(key, from, from + pageSize - 1);
        if (CollUtils.isEmpty(tuples)) {
            return CollUtils.emptyList();
        }
        // 3.封装
        int rank = from + 1;
        List<PointsBoard> list = new ArrayList<>(tuples.size());
        for (ZSetOperations.TypedTuple<String> tuple : tuples) {
            String userId = tuple.getValue(); // 获取member
            Double points = tuple.getScore(); // 获取score
            if (userId == null || points == null) {
                continue;
            }
            PointsBoard p = new PointsBoard();
            p.setUserId(Long.valueOf(userId));
            p.setPoints(points.intValue());
            p.setRank(rank++);
            list.add(p);
        }
        return list;
    }
    
// 需要查询当前用户的排名以及积分.
    private PointsBoard queryMyCurrentBoard(String key) {
        // 1.绑定key
        BoundZSetOperations<String, String> ops = redisTemplate.boundZSetOps(key);
        // 2.获取当前用户信息
        String userId = UserContext.getUser().toString();
        // 3.查询积分
        Double points = ops.score(userId);
        // 4.查询排名
        Long rank = ops.reverseRank(userId);
        // 5.封装返回(健壮性保证!)
        PointsBoard p = new PointsBoard();
        p.setPoints(points == null ? 0 : points.intValue());
        p.setRank(rank == null ? 0 : rank.intValue() + 1);
        return p;
    }
}
```

## 2. 历史排行榜
### 2.1 海量数据存储策略
![[Pasted image 20240924084505.png]]

#### 2.1.1 分区
##### 介绍:
**表分区（Partition)** 是一种数据存储方案，可以解决单表数据较多的问题。MySQL5.1开始支持表分区功能。

简单来说，就是按照某种规则，**把表数据对应的ibd文件拆分成多个文件来存储**。从物理上来看，一张表的数据被拆到多个表文件存储了；从逻辑上来看，他们对外表现是一张表。

表分区的本质是对数据的**水平拆分**，而拆分的方式也有多种，常见的有：
- **Range分区:**按照指定字段的取值范围分区
- List分区：按照指定字段的枚举值分区，必须**提前指定好所有的分区值**，如果数据找不到分区会报错;
- Hash分区：基于字段做hash运算后分区，一般做hash运算的字段都是数值类型
- Key分区：根据指定字段的值做运算的结果分区，与hash分区类似，但不限定字段类型

对表进行分区拆分,例如list拆分,需要在**一开始就列举除所有的分区值**,所以对于赛季榜单这种会持续更新的表可能不太适用!
##### **优缺点分析:**
**优点:**
1. 可以让**单表存储更多的数据**。
2. 分区表的数据更容易维护，可以通**过清除整个分区来批量删除大量数据**，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作。
3. 部分查询能够从查询条件确定**只落在少数分区**上，速度会很快（查询条件尽量扫描少的分区）。
4. 分区表的数据还可以**分布在不同的物理设备**上，从而高效利用多个硬件设备。
5. 可以**使用分区表来避免某些特殊瓶颈**，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争。
6. 可以备份和恢复单个分区。

**分区的限制和缺点**：
- 在mysql5.6.7之前的版本，一个表最多有1024个分区；从5.6.7开始，一个表最多可以有8192个分区。
- MYSQL的**分区字段，必须包含在主键字段内**。如果一个表有主键，那么分区字段必须包含在主键内，也就是分区字段必须是主键的一部分或者全部，不能以非主键的字段作为分区字段。当然，也可以为没有主键的表建立分区。
- 分区表无法使用外键约束。
- NULL值会使分区过滤无效。
- 所有分区必须使用相同的存储引擎。

#### 2.1.2 分表
##### 介绍:
**分表**是一种表设计方案，由开发者在创建表时按照自己的业务需求拆分表。也就是说这是开发者自己对表的处理，与数据库无关。分表从逻辑上和物理上都是一张表,所以在处理数据时需要考虑到哪张表进行处理!
##### 优缺点:
**优点:**
- 拆分方式更加灵活
- 而且可以**解决单表字段过多**的问题
**缺点:**
- 增删改查时，**需要自己判断访问哪张表**
- 垂直拆分还会导致**事务问题及数据关联问题**:原本一张表的操作，变为多张表操作。

#### 2.1.3 分库和集群
无论是分区，还是分表，我们刚才的分析都是**建立在单个数据库的基础**上。但是单个数据库也存在一些问题：
- 单点故障问题：数据库发生故障，整个系统就会瘫痪
- 单库的性能瓶颈问题：单库受服务器限制，其网络带宽、CPU、连接数都有瓶颈
- 单库的存储瓶颈问题：单库的磁盘空间有上限，如果磁盘过大，数据检索的速度又会变慢

综上，在大型系统中，我们除了要做分表、还需要**对数据做分库，建立综合集群。**

首先，在微服务项目中，我们会按照项目模块，**每个微服务使用独立的数据库**，**因此每个库的表是不同的**，这种分库模式成为**垂直分库**。

而为了保证**单节点的高可用性**，我们会给数据库建立**主从集群**，主节点向从节点同步数据。两者结构一样，可以看做是**水平扩展**。主节点宕机时,从节点可以充当主节点,保证了稳定性.
![[Pasted image 20240925134851.png]]

##### 优缺点:
**优点:**
- 解决了海量数据存储问题，突破了单机存储瓶颈
- 提高了并发能力，突破了单机性能瓶颈
- 避免了单点故障

**缺点:**
- 成本非常高
- 数据聚合统计比较麻烦
- 主从同步的一致性问题
- 分布式事务问题

#### **2.1.4 总结
![[Pasted image 20240924003713.png|400]]

### 2.2 历史榜单
综合考虑:1)用户数据规模不会太高; 2)解决单表数据量过大问题.所以无需采用分库和集群,这样会造成不必要的麻烦. 并且使用list分区需要在分区时列举出所有可能的赛季,而赛季是持续更新的,所以不太现实. 故**采用水平分表方案**.

将历史榜单根据赛季拆分,单个赛季对应一个独立的表. 故可以简化表字段,将赛季id略去用不同表进行区分;将id作为排名,故可以省略排名字段.
![[Pasted image 20240925135323.png]]
### 2.3 定时任务生成榜单表
积分榜先存于Redis,需要定时任务将其持久化于MySQL数据库中,所以在这里创建定时任务,通过SpringTask定时任务来生成历史榜单.

#### 2.3.1 定时任务
- 定义定时任务类,`@Scheduled(cron='')`注解用于执行定时任务.
- 调用service层执行具体业务逻辑: 创建历史赛季榜单表.
```Java
@Component
@RequiredArgsConstructor
public class PointsBoardPersistentHandler {

    private final IPointsBoardSeasonService seasonService;

    private final IPointsBoardService pointsBoardService;

    @Scheduled(cron = "0 0 3 1 * ?") // 每月1号，凌晨3点执行
    public void createPointsBoardTableOfLastSeason(){
        // 1.获取上月时间
        LocalDateTime time = LocalDateTime.now().minusMonths(1);
        // 2.查询赛季id
        Integer season = seasonService.querySeasonByTime(time);
        if (season == null) {
            // 赛季不存在
            return;
        }
        // 3.创建表
        pointsBoardService.createPointsBoardTableBySeason(season);
    }
}
```


### 2.4 分布式任务调度
SpringTask存在一些问题：
- 当微服务**多实例部署时，定时任务会被执行多**次。而事实上我们只需要这个任务被执行一次即可。**(SpringTask作为单机任务,不适用于分布式任务)**
- 我们除了要定时创建表，还要定时持久化Redis数据到数据库，我们希望这多个定时任务能够按照顺序依次执行，**SpringTask无法控制任务顺序**

不仅仅是SpringTask，其它**单机使用的定时任务工具，都无法实现像这种任务执行者的调度、任务执行顺序的编排、任务监控**等功能。这些功能必须要用到**分布式任务调度组件**。

#### 2.4.1 分布式任务调度原理
定时任务需要两个组件:1)任务(待执行的代码); 2)**任务触发器:基于定义好的规则触发任务**. 因此在多实例部署时, 每个实例都有任务触发器,可能会导致任务多次执行! 

因此,需要把任务触发器提取到各个实例之外,做统一触发,调度.
**任务的执行交由任务调度服务控制统一处理**,并且执行结果还可通过回调接口返回给各个实例,方便查看执行状态,任务等.
![[Pasted image 20240925142056.png]]

### 2.4.3 XXL-JOB介绍
XXL-JOB的运行原理与架构:
![[Pasted image 20240925142217.png]]

XXL-JOB分为两部分：
- **执行器:** 通过配置创建一个执行器,**负责与XXL-JOB调度中心交互，执行本地任务**。
- **调度中心:** 一个独立服务，负责**管理执行器、管理任务、任务执行的调度、任务结果和日志收集。**

### 2.4.4 XXL-JOB定时创建榜单表
#### 2.4.4.1 部署调度中心
**自定义部署调度中心:**
1. 执行官方SQL语句`XXL-JOB.sql`,创建数据库表;
2. 配置`application.properties`,配置端口,数据库地址,数据库账户密码;
3. 部署启动!
![[Pasted image 20240925143328.png]]

#### 2.4.4.2 微服务集成执行器
1. 引入XXL-JOB依赖;
2. ==**配置执行器:**==
	- adminAddress：调度中心地址，天机学堂中就是填虚拟机地址
	- appname：微服务名称
	- ip和port：当前执行器的ip和端口，无需配置，自动获取
	- accessToken：访问令牌，在调度中心中配置令牌，所有执行器访问时都必须携带该令牌，否则无法访问。
	- logPath：任务运行日志的保存目录
	- logRetentionDays：日志最长保留时长
```Java
@Configuration
@ConditionalOnClass(XxlJobSpringExecutor.class)
@EnableConfigurationProperties(XxlJobProperties.class)
public class XxlJobConfig {

    @Bean
    public XxlJobSpringExecutor xxlJobExecutor(XxlJobProperties prop) {
        log.info(">>>>>>>>>>> xxl-job config init.");
        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();
        XxlJobProperties.Admin admin = prop.getAdmin();
        if (admin != null && StringUtils.isNotEmpty(admin.getAddress())) {
            xxlJobSpringExecutor.setAdminAddresses(admin.getAddress());
        }
        XxlJobProperties.Executor executor = prop.getExecutor();
        if (executor != null) {
            if (executor.getAppName() != null)
                xxlJobSpringExecutor.setAppname(executor.getAppName());
            if (executor.getIp() != null)
                xxlJobSpringExecutor.setIp(executor.getIp());
            if (executor.getPort() != null)
                xxlJobSpringExecutor.setPort(executor.getPort());
            if (executor.getLogPath() != null)
                xxlJobSpringExecutor.setLogPath(executor.getLogPath());
            if (executor.getLogRetentionDays() != null)
                xxlJobSpringExecutor.setLogRetentionDays(executor.getLogRetentionDays());
        }
        if (prop.getAccessToken() != null)
            xxlJobSpringExecutor.setAccessToken(prop.getAccessToken());
        log.info(">>>>>>>>>>> xxl-job config end.");
        return xxlJobSpringExecutor;
    }
}
```
3. 配置执行器属性:
	**1)创建配置类:`XxlJob.properties`;**
```Java
@Data
@ConfigurationProperties(prefix = "tj.xxl-job")
public class XxlJobProperties {

    private String accessToken;
    private Admin admin;
    private Executor executor;

    @Data
    public static class Admin {
        private String address;
    }

    @Data
    public static class Executor {
        private String appName;
        private String address;
        private String ip;
        private Integer port;
        private String logPath;
        private Integer logRetentionDays;

    }
}
```

**2)nacos中配置了Shared-xxljob.yaml,会读取其中配置.**
```Java
tj:
  xxl-job:
    access-token: tianji
    admin:
      address: http://192.168.150.101:8880/xxl-job-admin
    executor:
    // 从bootstrap.yaml启动类配置文件中读取
      appname: ${spring.application.name} 
      log-retention-days: 10
      logPath: job/${spring.application.name}
```

#### 2.4.4.3 定义任务
同样还是Handler,将其中的`@Scheduled()`的SpringTask定时任务类用`@XXLJob(任务名称)`替代
![[Pasted image 20240925150017.png]]

#### 2.4.4.4 注册执行器
登录XXL-Job控制台,注册执行器,注意AppName与微服务名称保持相同.![[Pasted image 20240925152150.png|450]]

#### 2.4.4.5 配置任务调度
配置任务调度:1)分配任务何时执行; 2)任务由哪个执行器执行.
	- JobHandler: 填写@XXlJOB注解中自定义的任务名称.
![[Pasted image 20240925152302.png]]

### 2.5 榜单持久化
#### 2.5.1 动态表名
![[Pasted image 20240925165745.png]]
**利用MyBatisPlus的插件实现动态表名插入.**
1. 定义DynamicTableNameInnerInterceptor拦截器:
	- `map.put(tableName,TableNameHandler)`:当对tableName这个表进行CRUD操作时,会被拦截器动态替换成handler处理后的结果.
	- 使用三目运算符进行了健壮性处理,避免操作空表!
```Java hl:7,8
@Configuration  
public class MybatisConfiguration {  
  
    @Bean  
    public DynamicTableNameInnerInterceptor dynamicTableNameInnerInterceptor() {  
        Map<String, TableNameHandler> map = new HashMap<>(1);  
        map.put("points_board", (sql, tableName) -> TableInfoContext.getInfo()==null ? "points_board":TableInfoContext.getInfo());  
        return new DynamicTableNameInnerInterceptor(map);  
    }  
}
```
2. 修改MyBatisPlus的配置:
	- 该方法定义了一个MP拦截器链,往里面添加了很多拦截器,如动态表名,分页,自动填充..
	- `@Autowired(required = false)`:代表该拦截器为非必须.因为拦截器链定义在common方法中,故其他模块也会调用,但可能不会使用动态表名插件.所以定义为"非必须",避免导致其他服务无法启动.
	- **拦截器的添加是有顺序的:表名 > 多租户 > 分页 > 乐观锁 > 字段填充!!!**
```Java
    @Bean
    @ConditionalOnMissingBean
    public MybatisPlusInterceptor mybatisPlusInterceptor(@Autowired(required = false) DynamicTableNameInnerInterceptor innerInterceptor) {
        // 1.定义插件主体，注意顺序：表名 > 多租户 > 分页 > 乐观锁 > 字段填充
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        // 2.表名插件
        if (innerInterceptor != null) {
            interceptor.addInnerInterceptor(innerInterceptor);
        }
        // 3.分页插件
        PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(DbType.MYSQL);
        paginationInnerInterceptor.setMaxLimit(200L);
        interceptor.addInnerInterceptor(paginationInnerInterceptor);
        // 4.字段填充插件
        interceptor.addInnerInterceptor(new MyBatisAutoFillInterceptor());
        return interceptor;
    }
}
```
#### 2.5.2 定时持久化任务
持久化时需要从Redis中查询数据,若单赛季数据量过大,则可能导致压力过大,所以这里采用分页查询,降低单次查询的数据量.
这里也带来一个问题,因为查询分页了,所以插入数据时也会分页,难道要重复计算动态表名吗?
**解决办法:**
使用ThreadLocal存放计算的动态表名.
**拦截器:** 使用TableInfoContext.getInfo()方法,具体操作就是从TL中获取表名.
```Java
        map.put("points_board", (sql, tableName) -> TableInfoContext.getInfo() == null ? tableName : TableInfoContext.getInfo());
```
**定时任务:**
下面的`TableInfoContext.setInfo()`就是计算表名,并存入TL中.
```Java hl:10,30,35
@XxlJob("savePointsBoard2DB")
public void savePointsBoard2DB(){
    // 1.获取上月时间
    LocalDateTime time = LocalDateTime.now().minusMonths(1);

    // 2.计算动态表名
    // 2.1.查询赛季信息
    Integer season = seasonService.querySeasonByTime(time);
    // 2.2.将表名存入ThreadLocal
    TableInfoContext.setInfo(POINTS_BOARD_TABLE_PREFIX + season);

    // 3.查询榜单数据
    // 3.1.拼接KEY
    String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + time.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);
    // 3.2.查询数据
    int pageNo = 1;
    int pageSize = 1000;
    while (true) {
        List<PointsBoard> boardList = pointsBoardService.queryCurrentBoardList(key, pageNo, pageSize);
        if (CollUtils.isEmpty(boardList)) {
            break;
        }
        // 4.持久化到数据库
        // 4.1.把排名信息写入id (并清空多余字段.)
        boardList.forEach(b -> {
            b.setId(b.getRank().longValue());
            b.setRank(null);
        });
        // 4.2.持久化(这其中会调用动态表名拦截器.)
        pointsBoardService.saveBatch(boardList);
        // 5.翻页
        pageNo++;
    }
    // 任务结束，移除动态表名
    TableInfoContext.remove();
}
```

#### 2.5.3 XXL-JOB任务分片
##### **解决的问题:**
1) 数据量过大,单个任务执行器处理会耗费过多时间;
2) 多个任务执行器执行,可能会导致重复处理任务.

##### **任务分片(Shard)方案原理:**
将每页数据轮询给各个处理器,并重复该过程.
![[Pasted image 20240925212916.png]]
每个执行器处理的任务数据页情况:
1) 执行器编号与起始页码编号相同;
2) 单个执行器页码间隔与执行器数量相同.

综上,关键参数即为**执行器编号**与**执行器数量**.可通过以下命令获得:
```Java
XxlJobHelper.getShardIndex(); ->获取当前执行器编号,从0开始(+1即为页码编号)
XxlJobHelper.getShardTotal(); ->获取执行器总数量.
```
所以,改造代码如下: (注意,任务的路由策略需要更改为"**分片广播**" !)
	**根据当前执行器编号动态获取要处理的页码!**
```Java
    // 3.2.查询数据
    int index = XxlJobHelper.getShardIndex();
    int total = XxlJobHelper.getShardTotal();
    int pageNo = index + 1; // 起始页，就是分片序号+1
    int pageSize = 10;
	...
	...
	// 5.翻页，跳过N个页，N就是分片数量
	pageNo+=total;
```

#### 2.5.4 清理Redis缓存任务
既然已经将Redis中的数据持久化到数据库中了,那么Redis的数据就已经无用,可以清除了!这里同样调用XxlJob定时任务进行处理(**与持久化方法在同一个类中**)
	`@XxlJob(~)`注解,将该方法定义为XXL-Job定时任务.
	**`unlink()`方法**:与Delete方法不同.更适合操作大数据.
		1. `unlink()`为**异步删除**命令,不会阻塞客户端;
		2. `unlink()`会释放已经分配的内存,减少内存使用量.
		3. `unlink()`不会返回已操作的键的数量;
		4. 
```Java
@Component
@RequiredArgsConstructor
public class PointsBoardPersistentHandler {
	// 需要与任务调度中心的JobHandler的名称相同.
    @XxlJob("clearPointsBoardFromRedis") 
    public void clearPointsBoardFromRedis(){
        // 1.获取上月时间
        LocalDateTime time = LocalDateTime.now().minusMonths(1);
        // 2.计算key
        String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + time.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);
        // 3.删除
        redisTemplate.unlink(key);
    }
}
```
#### 2.4.5 任务链
##### 解决的问题:
1. 前面已经定义了多个任务:1)创建历史赛季榜单表;2)持久化到数据库; 3)清除Redis的缓存. 该如何保证三个任务按顺序执行呢?
2. 若通过Cron表达式定时执行,则无法确定在某个时间点,前一个任务已经完成!

##### 解决方案:
**使用XxlJob的子任务功能**!
若想让B在A之后执行,就需要配置**任务B作为任务A的子任务**. 
具体操作为:将三个任务均添加到调度中心,将B的id添加到A的子任务id中.
![[Pasted image 20240925214505.png]]

##### 存在的问题:
- 因为持久化Redis到上赛季榜单是分片执行的,而任务链中的子任务会在单个分片执行完成后就执行.
这个问题无法通过任务链解决.有几个idea是:
1. **将清理Redis任务与持久化任务合并,即持久化结束后,清除当前页的Redis缓存.**
2. 因为清理Redis缓存的时间没什么要求,所以可以预估任务2结束的时间,然后再执行任务3(不加入到任务链中).

# Day09:优惠券管理
## **1. 需求分析:**
### 1.1 表设计
#### 1.1.1优惠券表设计:
![[Pasted image 20240925223049.png]]
### 1.1.2 兑换码表设计
![[Pasted image 20240925223633.png]]
 
## 2. 优惠券管理
### 2.1 分页查询优惠券
#### 2.1.1 接口设计
![[Pasted image 20240925225856.png]]

请求参数,`pageNo+pageSize+...`,包含多个属性,可以使用`CouponQuery`进行封装.
	**父类PageQuery**中包含静态属性
```Java
@EqualsAndHashCode(callSuper = true)
@Data
@ApiModel(description = "优惠券查询参数")
@Accessors(chain = true)
public class CouponQuery extends PageQuery {

    @ApiModelProperty("优惠券折扣类型：1：每满减，2：折扣，3：无门槛，4：满减")
    private Integer type;

    @ApiModelProperty("优惠券状态，1：待发放，2：发放中，3：已结束, 4：取消/终止")
    private Integer status;

    @ApiModelProperty("优惠券名称")
    private String name;
}
```


**返回值**,熟悉的`list集合+pages+total`,对于这种返回类型,一般使用`PageDTO<XxPageVO>`进行封装.
可见`PageDTO`包含三个属性: 1)页码; 2)单页总条数; 3)当前页展示的数据.
```Java'
@Data  
@NoArgsConstructor  
@AllArgsConstructor  
@ApiModel(description = "分页结果")  
public class PageDTO<T> {  
    @ApiModelProperty("总条数")  
    protected Long total;  
    @ApiModelProperty("总页码数")  
    protected Long pages;  
    @ApiModelProperty("当前页数据")  
    protected List<T> list;
```
#### 2.1.2 接口实现
使用MP的lambdaQuery实现分页查询:
	`type != null`为查询条件,即只有当type!=null时,才添加该条件.
	`isNotBlank()`:即使有空格,也认为是空; 而`isNotEmpty()`有空格认为是非空.\
```Java
@Override
public PageDTO<CouponPageVO> queryCouponByPage(CouponQuery query) {
    Integer status = query.getStatus();
    String name = query.getName();
    Integer type = query.getType();
    // 1.分页查询
    Page<Coupon> page = lambdaQuery()
            .eq(type != null, Coupon::getDiscountType, type)
            .eq(status != null, Coupon::getStatus, status)
            .like(StringUtils.isNotBlank(name), Coupon::getName, name)
            .page(query.toMpPageDefaultSortByCreateTimeDesc());
    // 2.处理VO: 
    // 1)获取list<Coupon>; 2)list<Coupon> -> list<CouponPageVO>; 3)封装到PageDTO中..
    List<Coupon> records = page.getRecords();
    if (CollUtils.isEmpty(records)) {
        return PageDTO.empty(page);
    }
    List<CouponPageVO> list = BeanUtils.copyList(records, CouponPageVO.class);
    // 3.返回
    return PageDTO.of(page, list);
}
```

此处的分页查询看似未用到pageNo和pageSize,但实际上`toMpPage()`方法中隐式使用了这两个参数!(**也就是说,`lambdaQuery()`内部实质上还是通过创建Page对象来实现分页查询!**)
```Java
public class PageQuery {
    public <T> Page<T> toMpPage(String defaultSortBy, boolean isAsc) {
        if (StringUtils.isBlank(sortBy)){
            sortBy = defaultSortBy;
            this.isAsc = isAsc;
        }
        Page<T> page = new Page<>(pageNo, pageSize);
        OrderItem orderItem = new OrderItem();
        orderItem.setAsc(this.isAsc);
        orderItem.setColumn(sortBy);
        page.addOrder(orderItem);
        return page;
    }
    public <T> Page<T> toMpPageDefaultSortByCreateTimeDesc() {
        return toMpPage(Constant.DATA_FIELD_NAME_CREATE_TIME, false);
    }
}
```

### 2.2 发放优惠券
#### 2.2.1 接口设计
前端页面如下:
![[Pasted image 20240926170023.png]]

所以可知,需要传入以下参数: 
- 发放（领用）开始时间：如果为空说明是立刻发放，开始时间就是当前时间
- 发放（领用）结束时间
- 有效期天数：如果为空说明是固定有效期
- 使用期限开始时间：如果为空说明是固定天数有效期
- 使用期限结束时间：如果为空说明是固定天数有效期

接口如下:
![[Pasted image 20240926170118.png]]

#### 2.2.2 接口实现
- 只有状态为"待发放"的优惠券才能执行发放操作 -> **验证优惠券状态**
- 判断是立即发放还是定时发放:
	- 立即发送,前端只发送"结束时间";
	- 定时发放,前端发送"开始+结束时间";
		- **据此判断,若开始时间为null或开始时间在当前时间之前,则为立即发放.**
- 根据前端传参设置优惠券使用期限;
- 将优惠券status设置为"进行中".

```Java hl:16-18
@Transactional
@Override
public void beginIssue(CouponIssueFormDTO dto) {
    // 1.查询优惠券
    Coupon coupon = getById(dto.getId());
    if (coupon == null) {
        throw new BadRequestException("优惠券不存在！");
    }
    // 2.判断优惠券状态，是否是暂停或待发放
    if(coupon.getStatus() != CouponStatus.DRAFT && coupon.getStatus() != PAUSE){
        throw new BizIllegalException("优惠券状态错误！");
    }
    // 3.判断是否是立刻发放
    LocalDateTime issueBeginTime = dto.getIssueBeginTime();
    LocalDateTime now = LocalDateTime.now();
    // 开始时间为null,或开始时间在当前时间之前,说明为立即发放.
    // 使用isAfter而不是isBefore,是为了保证当前时间和开始时间相同时,也为true.
	boolean isBegin = issueBeginTime == null ||!issueBeginTime.isAfter(now);
    // 4.更新优惠券
    // 4.1.拷贝属性到PO
    Coupon c = BeanUtils.copyBean(dto, Coupon.class);
    // 4.2.更新状态:
    // 4.2.1 立即发放的更新状态
    if (isBegin) {
        c.setStatus(ISSUING);
        c.setIssueBeginTime(now);
    }else{  // 定时发放的更新状态
        c.setStatus(UN_ISSUE);
    }
    // 4.3.写入数据库
    updateById(c);

    // TODO 兑换码生成
}
```

### 2.3 兑换码生成
#### 2.3.1 需求分析与接口设计
**需求:** 若为定时发放,则会生成兑换码用来兑换优惠券! 兑换码必须保证以下需求:
![[Pasted image 20240926183743.png]]
要求如下：
- 可读性好：兑换码是要给用户使用的，用户需要输入兑换码，因此可读性必须好。我们的要求：
  - **长度不超过10个字符**
  - 只能是**24个大写字母和8个数字**：ABCDEFGHJKLMNPQRSTUVWXYZ23456789
- 数据量大：优惠活动比较频繁，必须有充足的兑换码，最好有**10亿以上的量**
- 唯一性：10亿兑换码都**必须唯一**，不能重复，否则会出现兑换混乱的情况
- 不可重兑：兑换码必须便于**校验兑换状态,避免重复**兑换
- 防止爆刷：兑换码的规律性不能很明显，**不能轻易被人猜测**到其它兑换码
- 高效：兑换码生成、验证的算法必须**保证效率**，避免对数据库带来较大的压力

#### 2.3.2 算法分析


### 2.4 异步生成兑换码
#### 2.4.1 需求分析
**需求:** 当优惠券的发放方式为兑换码,则需要生成兑换码.
判断是否需要生成兑换码，要同时满足两个要求：
- 领取方式必须是兑换码方式
- 之前的状态必须是待发放，不能是暂停.
并且生成的兑换码较多,采用异步方式进行.
![[Pasted image 20240926212732.png]]


#### 2.4.2 代码实现
##### Service层: 生成兑换码
具体逻辑为:
- 前端传入兑换码数量totalNum,对Redis中该key的值一次性自增totalNum,这样可以保证频繁的操作Redis! 然后循环取出,并设置兑换码.
```Java 
@Service
public class ExchangeCodeServiceImpl extends ServiceImpl<ExchangeCodeMapper, ExchangeCode> implements IExchangeCodeService {

    private final StringRedisTemplate redisTemplate;
    private final BoundValueOperations<String, String> serialOps;

    @Override
    @Async("generateExchangeCodeExecutor")
    public void asyncGenerateCode(Coupon coupon) {
        // 发放数量
        Integer totalNum = coupon.getTotalNum();
        // 1.获取Redis自增序列号 
        Long result = redisTemplate
			        .opsForValue
			        .increment(COUPON_CODE_SERIAL_KEY,totalNum);
        if (result == null) {
            return;
        }
        // 获取自增后的值
        int maxSerialNum = result.intValue();
        List<ExchangeCode> list = new ArrayList<>(totalNum);
        // 获取起始值
        int serialNum = maxSerialNum - totalNum + 1;
        // 循环遍历
        for (serialNum; serialNum <= maxSerialNum; serialNum++) {
            // 2.生成兑换码
            // 调用generateCode方法,对每个id都生成兑换码.
            String code = CodeUtil.generateCode(serialNum, coupon.getId());
            // 封装兑换码信息.
            ExchangeCode e = new ExchangeCode();
            e.setCode(code);
            e.setId(serialNum);
            e.setExchangeTargetId(coupon.getId());
            e.setExpiredTime(coupon.getIssueEndTime());
            list.add(e);
        }
        // 3.保存数据库
        saveBatch(list);
    }
}
```

##### 异步生成方法:
1. **定义线程池**,用于异步生成兑换码.
```Java
@Configuration
public class PromotionConfig {

    @Bean
    public Executor generateExchangeCodeExecutor(){
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        // 1.核心线程池大小
        executor.setCorePoolSize(2);
        // 2.最大线程池大小
        executor.setMaxPoolSize(5);
        // 3.队列大小
        executor.setQueueCapacity(200);
        // 4.线程名称
        executor.setThreadNamePrefix("exchange-code-handler-");
        // 5.拒绝策略
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.initialize();
        return executor;
    }
}
```
2. 启动类上添加`@EnableAsync`注解,开启异步功能;
3. 需要异步执行的方法上加上`@Async("线程池名称")`方法. 
	- 线程池名称默认为Bean注册在容器中的名称.


# Day10-领取优惠券
## 1. 需求分析和接口设计
### 1.1 原型分析
根据页面不同,需要分别显示"**优惠券列表**"和"**我的优惠券**",并且点击"立即兑换"后可以输入兑换码**兑换优惠券**,或者对"优惠券列表"中的优惠券点击"立即领取",可以**领取优惠券**

所以,一共四个接口:
1)查询优惠券列表; 2)查询我的优惠券; 3)兑换优惠券; 4)领取优惠券.

### 1.2 数据库设计
领取优惠券,需要记录哪个用户领取了哪张优惠券.并且,还需要记录用户领券后的使用情况.

**用户券表如下:**
![[Pasted image 20240927223434.png]]
## 2. 领取优惠券
### ==2.1 查询发放中的优惠券==
#### 2.1.1 接口分析
**页面原型:**![[Pasted image 20240927230708.png]]
1. 查看时,必定是能查看多个优惠券,所以这里应该是一个批量查询接口,返回值是list!
2. 返回的字段需要包括以下信息: (信息较多,使用VO封装.)
	- 1)优惠券名称; 2)折扣类型; 3)适用范围; 4)有效期 等等. 
![[Pasted image 20240927230547.png]]

#### 2.1.2 VO实体
![[Pasted image 20240927231135.png]]

#### 2.1.3 接口实现
- 难点在于查询"**是否可领取**"和"**是否已经领取**"这两个属性.
![[Pasted image 20240927232847.png]]
**优惠券还有剩余并且用户已领取未超过限领数量:**
	1) 用户券表中该优惠券id对应的数量>优惠券发放数量;
	2) 当前userId,优惠券id对应的id数量<限领数量.
**已经领取,尚未使用:**
	1) 对应某个券,userId,存在该数据,并且状态为"待使用".

**实际开发流程:**
1) 查询用户券表user_coupon,条件为:**当前用户**,**状态为发放中**,获取优惠券id;
2) 统计当前用户,针对每一个优惠券的已领数量;
3) 统计当前用户,针对每一个券的已领且未使用数量.
```Java hl:21-24
@Override
public List<CouponVO> queryIssuingCoupons() {
    // 1.查询发放中的优惠券列表: 1)状态为发放中;2)方式为手动领取
    // 查询的是coupon表
    List<Coupon> coupons = lambdaQuery()
            .eq(Coupon::getStatus, ISSUING)
            .eq(Coupon::getObtainWay, ObtainType.PUBLIC)
            .list();
    if (CollUtils.isEmpty(coupons)) {
        return CollUtils.emptyList();
    }
    // 2.统计当前用户已经领取的优惠券的信息
    // 查询用户券表,获取发放中的优惠券id集合.
    List<Long> couponIds = coupons.stream().map(Coupon::getId).collect(Collectors.toList());
    // 2.1.查询当前用户已经领取的优惠券的数据(对应'1)')
    // 条件为当前用户,且状态为发放中.
    List<UserCoupon> userCoupons = userCouponService.lambdaQuery()
            .eq(UserCoupon::getUserId, UserContext.getUser())
            .in(UserCoupon::getCouponId, couponIds)
            .list();
    // 2.2.统计当前用户对优惠券的已经领取数量
    // 按照优惠券id分组,并统计其数量.
    Map<Long, Long> issuedMap = userCoupons.stream()
        .collect(Collectors.groupingBy(UserCoupon::getCouponId, Collectors.counting()));
    // 2.3.统计当前用户对优惠券的已经领取并且未使用的数量
    // 依旧是查询当前用户已经领取的优惠券集合,条件为未使用.
    Map<Long, Long> unusedMap = userCoupons.stream()
		.filter(uc -> uc.getStatus() == UserCouponStatus.UNUSED)
        .collect(Collectors.groupingBy(UserCoupon::getCouponId, Collectors.counting()));
    // 3.封装VO结果
    List<CouponVO> list = new ArrayList<>(coupons.size());
    for (Coupon c : coupons) {
        // 3.1.拷贝PO属性到VO
        CouponVO vo = BeanUtils.copyBean(c, CouponVO.class);
        list.add(vo);
        // 3.2.是否可以领取：已经被领取的数量 < 优惠券总数量 && 当前用户已经领取的数量 < 每人限领数量 
        vo.setAvailable(
                c.getIssueNum() < c.getTotalNum()
                && issuedMap.getOrDefault(c.getId(), 0L) < c.getUserLimit()
        );
        // 3.3.是否可以使用：当前用户已经领取并且未使用的优惠券数量 > 0
        vo.setReceived(unusedMap.getOrDefault(c.getId(),  0L) > 0);
    }
    return list;
}
```

#### 2.1.4 登录拦截放行问题
发放中的优惠券,不管登录还是未登录都应该可以查看.但目前，未登录情况下访问优惠券页面就会报错:
![[Pasted image 20240928001823.png]]

这是由于`tj-auth-resource-sdk`模块起作用:1)获取登录用户信息; 2)校验登录状态,未登录则报错. (基于SpringMVC中的拦截器实现)
![[Pasted image 20240928001945.png|400]]

##### 2.1.4.1 UserInfoInterceptor


### 2.2 兑换码兑换优惠券
#### 2.2.1 接口分析
用户输入"兑换码",若兑换码未被兑换,且在有效期内,即可获得对应优惠券.
所以,前端传参为: **兑换码id**

由兑换码id->优惠券id,就需要解析兑换码,获取对应优惠券id!由于兑换码id是自增的,所以解析出兑换码id再去查询BitMap,即可判断是否被兑换.

流程如下:
![[Pasted image 20240928084444.png]]

 接口如下:
![[Pasted image 20240928084634.png]]

#### 2.2.2 接口实现
- 使用SETBIT命令判断某位是否为1,但是这样无论兑换码是否有效,该位都会被置为1. 所以这里采用try-catch,当兑换失败后,将该位重置为0.
```Java
    @Override
    @Transactional // 操作多个表,添加事务注解.
    public void exchangeCoupon(String code) {
        // 1.校验并解析兑换码
        long serialNum = CodeUtil.parseCode(code);
        // 2.校验是否已经兑换 SETBIT KEY 4 1 ，这里直接执行setbit，通过返回值来判断是否兑换过
        boolean exchanged = codeService.updateExchangeMark(serialNum, true);
        if (exchanged) {
            throw new BizIllegalException("兑换码已经被兑换过了");
        }
        try {
            // 3.查询兑换码对应的优惠券id
            ExchangeCode exchangeCode = codeService.getById(serialNum);
            if (exchangeCode == null) {
                throw new BizIllegalException("兑换码不存在！");
            }
            // 4.是否过期
            LocalDateTime now = LocalDateTime.now();
            if (now.isAfter(exchangeCode.getExpireTime()) {
                throw new BizIllegalException("兑换码已经过期");
            }
            // 5.校验并生成用户券
            // 5.1.查询优惠券
             Coupon coupon = couponMapper.selectById(exchangeCode.getCouponId());
            // 5.2.查询用户
            Long userId = UserContext.getUser();
            // 5.3.校验并生成用户券，更新兑换码状态
            checkAndCreateUserCoupon(coupon, userId, serialNum);
        } catch (Exception e) {
            // 重置兑换的标记 0 
            codeService.updateExchangeMark(serialNum, false);
            throw e;
        }
    }
```

## ==3. 并发安全问题==

### 3.1 超卖问题
#### 3.1.1.分析原因
现在我们对于优惠券库存的处理逻辑是这样的：
- 查询优惠券
- 判断库存是否充足（领取数量<总数量）
- 如果充足，更新优惠券领取数量
这里采用的是**先查询，再判断，再更新**的方案，而以上三步操作并**不具备原子性**。如果是多线程并发运行，如果**N个线程同时去查询**（N大于剩余库存），此时大概率查询到的库存是充足的，然后判断库存自然没问题。最后一起更新库存，自然就会超卖。
![[Pasted image 20240928104804.png]]

#### 3.1.2 解决方案
并发安全问题，最广为人知的解决方案就是**加锁**.不过，加锁的方式多种多样，大家熟悉的Synchronized、ReentrantLock只是其中最基础的锁。

从实现思想上来说，锁可以分为两大类: 
- **悲观锁**
	- 悲观锁是一种独占和排他的锁机制，**保守地认为数据会被其他事务修改**，所以在整个数据处理过程中将数据处于锁定状态。
	- 悲观锁认为安全问题一定会发生，所以直接独占资源。结果就是**多个线程会串行执行**被保护的代码。
	- 优点:安全性非常高
	- 缺点:性能较差

- **乐观锁**
	- 乐观锁是一种较为**乐观的并发控制方法**，**假设多用户并发的不会产生安全问题**，因此无需独占和锁定资源。但在**更新数据前**，会先检查是否有其他线程修改了该数据，如果有，则认为可能有风险，会放弃修改操作
	- 乐观锁则认为安全问题不一定发生，所以不独占资源.结果就是**允许多线程并行执行**。但如果真的发生并发修改怎么办？？**乐观锁采用CAS（Compare And Set）思想**，在**更新数据前先判断数据与我之前查询到的是否一致**，不一致则证明有其它线程也在更新。为了避免出现安全问题，放弃本次更新或者重新尝试一次。
	- 优点: 性能好、安全性也好
	- 缺点: 并发较高时，可能出现更新成功率较低的问题（并行的N个线程只会有1个成功）
**乐观锁工作原理:**
**添加库存的判断条件,确保查询时和更新时库存没变化.**
![[Pasted image 20240928105815.png]]
#### 3.1.3 解决超卖问题
将领取优惠券,更新数据库的更新SQL语句修改为:
`UPDATE coupon SET issue_num = issue_num + 1 WHERE id = #{id} AND issue_num < total_num`
这样就可以保证更新时券的剩余数量小于总数量.

### ==3.2 锁失效问题==
添加乐观锁,可以保证优惠券已领数量不会超过优惠券总数量,解决了超卖问题. 但是无法解决单个用户领取数量超过限领数量!
用户领取优惠券的操作,也是查询,判断,更新分步执行,无法保证原子性!
![[Pasted image 20240928111026.png]]

 因为乐观锁常用在更新，而且这里用户和优惠券的关系并不具备唯一性，因此**新增时无法基于乐观锁做判断**。这里的用户领取优惠券是**插入(INSERT)操作**.

#### 3.2.1 锁对象问题
用户限领数量判断是**针对单个用户**的，因此**锁的范围不需要是整个方法**，只要**锁定某个用户**即可。所以这里建议采用Synchronized的代码块，而不是同步方法。并且**同步代码块的锁指定为用户id，那么同一个用户并发操作时会被锁定**，不同用户互相没有影响，整体效率也是可以接受的。
![[Pasted image 20240928111933.png]]
**加锁时,避免锁Long对象,因为Long类型内部的LongCache类缓存了-128~127.**
但是,由于`toString()`操作的底层是new了新的String对象的,所以这里无法保证同一个用户进来时,`userId.toString()`是相同的值.

#### 3.2.2 解决方案
采用String的`intern()`方法,intern方法保证了只要两个字符串的字面量相同,就会返回字符串常量池中已存在的引用; 若不存在相同的字面量,就会将新的添加到字符串常量池中.
![[Pasted image 20240928111814.png]]

### ==3.3 事务边界问题==
#### 3.3.1 分析原因
原因如下:先开启事务,再获取锁,业务执行完毕后,先释放锁,再提交事务.
![[Pasted image 20240928201648.png|500]]

总结:由于锁过早释放，导致了事务尚未提交，**判断出现错误**，最终导致并发安全问题发生。

#### 3.3.2 解决方案
解决方案很简单，就是调整边界,将锁放事务前:
- 业务开始前:先获取锁,再开启事务
- 业务结束后:先提交事务,再释放锁
**具体实现:**
- 将事务加在方法上,而锁加在方法外;
- 事务方法必须用public修饰.
- 事务方法需要**被spring管理**.因此要把事务方法向上抽取到service接口中:
```Java
	synchronized(userId.toString().intern()){ // 这里加锁，这样锁在事务之外
		checkAndCreateUserCoupon(coupon, userId, null);
	}

	@Transactional // 这里进事务，同时，事务方法一定要public修饰
    public void checkAndCreateUserCoupon(Coupon coupon, Long userId, Integer serialNum){

public interface IUserCouponService extends IService<UserCoupon> {

    void checkAndCreateUserCoupon(Coupon coupon, Long userId, Integer serialNum);
```
#### 3.3.3.总结
在事务和锁并行存在时，**一定要考虑事务和锁的边界问题**。由于事务的隔离级别问题，可能会导致不同事务之间数据不可见，往往会产生一些不可预期的现象。
### ==3.4 事务失效问题==
#### 3.4.1 分析原因
##### 3.4.1.1 事务方法非public修饰
由于Spring的事务是**基于AOP的方式结合动态代理来**实现的。因此事务方法一定要是public的，这样才能便于被Spring做事务的代理和增强。

##### 3.4.1.2 非事务方法调用本类事务方法
```Java
@Service
public class OrderService {
    // 非事务方法
    public void createOrder(){
        // ... 准备订单数据
        
        // 生成订单并扣减库存
        insertOrderAndReduceStock();
    }
    // 本类中事务方法
    @Transactional
    public void insertOrderAndReduceStock(){
        // 生成订单
        insertOrder();
        // 扣减库存
        reduceStock();
    }
}
```
`insertOrderAndReduceStock`方法是一个事务方法,会被Spring事务管理.Spring会给`OrderService`类生成一个**动态代理对象**,对`insertOrderAndReduceStock`方法做增加,实现事务效果. 但是由于createOrder是非事务方法,其中调用了`insertOrderAndReduceStock`方法,这个调用其实**隐含了一个`this.`的前缀**。也就是说,这里相当于是**直接调用原始的OrderService中的普通方法，而非被Spring代理对象的代理方法**。

##### 3.4.1.3 事务方法的异常被捕获了
```Java
 @Service
 public class OrderService {

    @Transactional
    public void createOrder(){
        // ... 准备订单数据
        // 生成订单
        insertOrder();
        // 扣减库存
        reduceStock();
    }

    private void reduceStock() {
        try {
            // ...扣库存
        } catch (Exception e) {
            // 处理异常
        }
    }

 }
```
`reduceStock`方法内部直接捕获了Exception类型的异常，也就是说方法执行过程中即便出现了异常也不会向外抛出。
而Spring的事务管理就是要**感知业务方法的异常,当捕获到异常后才会回滚事务**.现在事务被捕获,就会**导致Spring无法感知事务异常**，自然不会回滚，事务就失效了。

##### 3.4.1.4 事务异常类型不对
Spring的事务管理默认感知的异常类型是`RuntimeException`,当事务方法内部抛出了一个`IOException`时，不会被Spring捕获，因此就不会触发事务回滚，事务就失效了。

当我们的业务中会抛出`RuntimeException`以外的异常时，应该通过`@Transactional`注解中的`rollbackFor`属性来指定异常类型.

##### 3.4.1.5 事务传播行为不对
- 当方法内部存在`REQUIRES_NEW`的事务方法,会创建新事物,成为子事务.但子事务内部报错回滚时,只会回滚当前子事务,而不会回滚外部事物(`createOrder`); 而当`createOrder`方法抛出异常时,只有`insertOrder`方法会回滚,而reduceStock方法不会回滚.
- 默认的事务传播行为为合并,即内部事务与外部事物共用一个事务.
```Java
 
@Service
 public class OrderService {
    @Transactional
    public void createOrder(){
        // 生成订单
        insertOrder();
        // 扣减库存
        reduceStock();
        throw new RuntimeException("业务异常");
    }
    @Transactional
    public void insertOrder() {
    }
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void reduceStock() {
    }
 }
```

##### 3.4.1.6 没有被Spring管理
没有加@Service注解,导致无法被Spring管理,因此也不会生成动态代理类,事务自然会失效.

#### 3.4.2 解决方案
既然事务的底层原理是Spring生成了动态代理类用于实现注解,而失效的原因是方法内部没有调用动态代理类,而是使用了`this`方法.

**具体实现:** 借助AspectJ实现获取动态代理类
1. 引入AspectJ依赖;
2. 暴露代理对象:启动类上添加注解`@EnableAspectJAutoProxy(exposeProxy = true)`;
3. 使用代理对象: 不调用本类中的非事务方法,而是调用动态代理对象.
![[Pasted image 20240928210155.png]]

# Day11-领取优惠券的优化
## 1. 分布式锁
### 1.1 集群下的锁失效问题
**synchronized锁的原理:**
Synchronized中的重量级锁，底层就是基于**锁监视器(Monitor)** 来实现的。简单来说就是**锁对象头会指向一个锁监视器**，而在监视器中则会记录一些信息，比如：
- `_owner`：持有锁的线程
- `_recursions`：锁重入次数
因此每一个锁对象，都会指向一个锁监视器，而**每一个锁监视器，同一时刻只能被一个线程持有**，这样就实现了互斥效果。但前提是，**多个线程使用的是同一把锁**。

但是,在集群中,每一个实例都有自己的JVM运行环境,因此若同一个用户,请求进入了多个不同的实例(JVM)中,就会出现多个锁对象,此时Synchronized锁失效!

**解决方案:**
我们不能让每个实例去使用各自的JVM内部锁监视器，而是应该**在多个实例外部寻找一个锁监视器，多个实例争抢同一把锁.**
![[Pasted image 20240928212212.png]]
分布式锁必须要满足的特征：
- 多JVM实例都可以访问
- 互斥

实现分布式锁的方式也非常多，例如：
- 基于MySQL
- **基于Redis**(使用最广泛)
- 基于Zookeeper
- 基于ETCD

### 1.2 简单分布式锁
>1)Redis本身可被多JVM实例访问; 2)JVM的SETNX命令具备互斥性.
#### 1.2.1 基本原理
**获取锁:**
`SETNX lock thread1`:当key不存在时,执行成功并返回结果1;若key存在,则执行失败,返回0.
**释放锁:**
`DEL lock`:业务执行完毕,释放锁.

**超时释放锁策略:**
若SETNX获取锁了,但业务未执行完成当前实例就宕机了,此时释放锁操作就不会执行,此时锁就一直被thread1占用,不会被释放,**造成死锁**!!!
为了避免死锁问题,为每个key设置一个远超任务预计执行时间的**超时时间**!
	`EXPIRE lock XX`:设置XX秒超时时间.

仍旧有问题,因为SETNX和EXPIRE是分步执行的,即实例依旧有可能在两步操作之间宕机.为了解决这种问题,我们需要**保证SETNX和EXPIRE操作的原子性**:`SET lock thread1 NX EX XX`

**最终流程如下:**
![[Pasted image 20240928232836.png|450]]

#### 1.2.2 代码实现
```Java
@RequiredArgsConstructor
public class RedisLock {

    private final String key;
    private final StringRedisTemplate redisTemplate;

    /**
     * 尝试获取锁
     * @param leaseTime 锁自动释放时间
     * @param unit 时间单位
     * @return 是否获取成功，true:获取锁成功;false:获取锁失败
     */
    public boolean tryLock(long leaseTime, TimeUnit unit){
        // 1.获取线程名称
        String value = Thread.currentThread().getName();
        // 2.获取锁
        Boolean success = redisTemplate.opsForValue().setIfAbsent(key, value, leaseTime, unit);
        // 3.返回结果
        return BooleanUtils.isTrue(success);
    }

    /**
     * 释放锁
     */
    public void unlock(){
        redisTemplate.delete(key);
    }
}
```
**由Synchronized锁->基于Redis实现的分布式锁:**
![[Pasted image 20240928233245.png]]

### 1.3 分布式锁的问题
#### 1.3.1 锁误删问题
1. 线程1获取到锁,执行业务,然而此时某种原因导致**阻塞**,释放锁的操作还未执行,锁就已经超时过期了;
2. 此时由于锁已过期,所以线程2可以成功获取锁,开始执行业务. 但是此时线程1醒来,继续执行释放锁的操作,然而**此时释放的不是线程1的锁,而是线程2的锁!!**
3. 此时线程3再次可以获取锁,线程2又会删除线程3的锁,导致连环的并发安全问题.
![[Pasted image 20240928234614.png]]
![[Pasted image 20240928234637.png]]
![[03909b9c-7fde-464e-98fa-6c7cbf50f628.gif]]

![[Pasted image 20240928234647.png]]

**解决方案:**
在删除锁之前判断当前锁的中保存的是否是当前线程标示，如果不是则证明不是自己的锁，则不删除；如果锁标示是当前线程，则可以删除：
![[Pasted image 20240928235439.png]]

#### ~~1.3.2 超时释放问题~~

### 1.4 Redisson
#### 1.4.1 介绍
![[Pasted image 20240929103724.png]]

![[Pasted image 20240929103740.png]]

#### 1.4.2 使用教程
1. 引入依赖;
2. 配置Redisson:
```Java
 @Configuration
 public class RedisConfig {
    @Bean
    public RedissonClient redissonClient() {
        // 配置类
        Config config = new Config();
        // 添加redis地址，这里添加了单点的地址，也可以使用config.useClusterServers()添加集群地址 
        config.useSingleServer()
            .setAddress("redis://192.168.150.101:6379")
            .setPassowrd("123321");
        // 创建客户端
        return Redisson.create(config);
    }
 }
```
3. 开始使用:
```Java
// 注入Redisson客户端
@Autowired
 private RedissonClient redissonClient;

 @Test
 void testRedisson() throws InterruptedException {
    // 1.获取锁对象,指定锁名称
    RLock lock = redissonClient.getLock("anyLock");
    try {
        // 2.尝试获取锁，参数：waitTime、leaseTime(释放时间)、时间单位
        // boolean isLock = lock.tryLock(1, 10, TimeUnit.SECONDS);
        boolean isLock = lock.tryLock(); // 不传入参数,使watchDog生效.
        if (!isLock) {
            // 获取锁失败处理 ..
        } else {
            // 获取锁成功处理
            `执行业务代码`
        }
    } finally {
        // 4.释放锁
        lock.unlock();
    }
 }
```
利用Redisson获取锁时可以传3个参数：
- waitTime:获取锁的等待时间。当获取锁失败后可以**多次重试**，直到waitTime时间耗尽。waitTime默认-1，即失败后立刻返回，不重试。
- leaseTime:锁**超时释放时间**,默认是30.同时会**利用WatchDog来不断更新超时时间**。需要注意的是，如果**手动设置leaseTime值，会导致WatchDog失效**。
	- watchDog生效时,默认过期时间为30s,若业务仍在执行,则会在还剩20s时重置过期时间.
- TimeUnit:时间单位

### 1.5 通用分布式锁组件
#### 1.5.1 实现思路分析
![[Pasted image 20240929145819.png|450]]
以上加分布式锁的流程如下,通用的部分很多,所以可以抽取出来. 这里**采用基于AOP的思想,将业务部分作为切入点,将业务前后的锁操作作为环绕增强.**

因为加锁的不是所有类,也不是个别方法,所以采用基于注解的方式切入. 同时,使用注解加锁时,还可以传入"锁的key名称",锁的waitTime,releaseTime等.

因此,注解的核心作用: 1)标记切入点; 2)传递锁参数.

#### 1.5.2 定义注解
**定义加锁注解:**
```Java
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface MyLock {
    String name();

    long waitTime() default 1;

    long leaseTime() default -1;

    TimeUnit unit() default TimeUnit.SECONDS;
}
```

#### 1.5.3 定义切面
定义切面类,实现: 
1) 将通用的业务模块写在`tryLock()`方法中,`pjp.proceed()`表示具体的加切面的方法;
2) 注解写在方法参数上,这样可以通过`myLock.xx`的方式来获取注解的属性;
3) @Around表示在方法执行前后添加自定义逻辑,用于环绕通知;
	- 典型切点表达式:`@Around("execution(* com.example.service..*(..))")`
	- 第一个`*`表示返回值任意;第一个`..`表示`service`包及其子包下都会扫描;第二个`*`表示包下所有类;(..)表示所有方法参数.
```Java hl:20,21,
@Component
@Aspect
@RequiredArgsConstructor
public class MyLockAspect implements Ordered{

    private final RedissonClient redissonClient;

    @Around("@annotation(myLock)")
    public Object tryLock(ProceedingJoinPoint pjp, MyLock myLock) throws Throwable {
        // 1.创建锁对象
        RLock lock = redissonClient.getLock(myLock.name());
        // 2.尝试获取锁
        boolean isLock = lock.tryLock(myLock.waitTime(), myLock.leaseTime(), myLock.unit());
        // 3.判断是否成功
        if(!isLock) {
            // 3.1.失败，快速结束
            throw new BizIllegalException("请求太频繁");
        }
        try {
            // 3.2.成功，执行业务
            return pjp.proceed();
        } finally {
            // 4.释放锁
            lock.unlock();
        }
    }
    
    @Override
    public int getOrder() {
        return 0;
    }
}
```

注意，Spring中的AOP切面有很多，会按照Order排序，**按照Order值从小到大依次执行**。Spring事务AOP的order值是Integer.MAX_VALUE，优先级最低。

我们的分布式锁一定要先于事务执行,因此,我们的**切面一定要实现Ordered接口，指定order值小于Integer.MAX_VALUE即可**。

#### 1.5.4 使用锁
![[Pasted image 20240929153123.png]]

#### 1.5.5 工厂模式切换锁类型


## 2. 异步领券
![[Pasted image 20240929204454.png]] 
![[Pasted image 20240929204430.png]]
![[Pasted image 20240929204426.png]]
![[Pasted image 20240929204421.png]]









#### 2.2.3 添加缓存
改造代码,对于立刻发放的优惠券,需要添加缓存到Redis中!

**将添加缓存封装成私有方法,并在"添加优惠券"的接口实现中调用!**
- 将时间转换成Long类型,方便后续的校验操作;
- 写操作是先将数据写入到Map中,再将Map写入Redis中,减少了操作Redis的次数!
```Java
public void beginIssue(CouponIssueFormDTO dto) {
	
	...
	
    // 5.添加缓存，前提是立刻发放的
    if (isBegin) {
        coupon.setIssueBeginTime(c.getIssueBeginTime());
        coupon.setIssueEndTime(c.getIssueEndTime());
        cacheCouponInfo(coupon);
    }
}
private void cacheCouponInfo(Coupon coupon) {
    // 1.组织数据
    Map<String, String> map = new HashMap<>(4);
    map.put("issueBeginTime", String.valueOf(DateUtils.toEpochMilli(coupon.getIssueBeginTime())));
    map.put("issueEndTime", String.valueOf(DateUtils.toEpochMilli(coupon.getIssueEndTime())));
    map.put("totalNum", String.valueOf(coupon.getTotalNum()));
    map.put("userLimit", String.valueOf(coupon.getUserLimit()));
    // 2.写缓存: 
	redisTemplate.opsForHash().putAll(PromotionConstants.COUPON_CACHE_KEY_PREFIX + coupon.getId(), map);
}
```

# Day12-优惠券的使用

## 1. 优惠券规则定义
## 1.1 业务流程分析
![[Pasted image 20240930101604.png]]
### 1.2 优惠券规则定义
![[Pasted image 20240930101701.png]]
所谓的优惠券方案推荐，就是从用户的所有优惠券中筛选出可用的优惠券，并且**计算哪种优惠方案用券最少，优惠金额最高**。
因此这里包含了对优惠券的下列需求：
- 判断一个优惠券**是否可用**，也就是检查订单金额是否达到优惠券使用门槛
- 按照优惠规则**计算优惠金额**，能够计算才能比较并找出最优方案
- 生成优惠券**规则描述**，目的是在页面直观的展示各种方案，供用户选择

在这里,抽象一个接口来标示优惠券规则,并针对不同的券,实现该接口.
```Java
/**
 * <p>优惠券折扣功能接口</p>
 */
public interface Discount {
    /**
     * 判断当前价格是否满足优惠券使用限制
     * @param totalAmount 订单总价
     * @param coupon 优惠券信息
     * @return 是否可以使用优惠券
     */
    boolean canUse(int totalAmount, Coupon coupon);

    /**
     * 计算折扣金额
     * @param totalAmount 总金额
     * @param coupon 优惠券信息
     * @return 折扣金额
     */
    int calculateDiscount(int totalAmount, Coupon coupon);

    /**
     * 根据优惠券规则返回规则描述信息
     * @return 规则描述信息
     */
    String getRule(Coupon coupon);
}
```
**使用工厂模式来实现优惠规则策略:**
- 定义一个Map,里面放的是不同优惠规则的实现类;
- 用户可以通过传入优惠券类型来取出相应的优惠规则实现类对象.
```Java
public class DiscountStrategy {

    private final static EnumMap<DiscountType, Discount> strategies;

    static {
        strategies = new EnumMap<>(DiscountType.class);
        strategies.put(DiscountType.NO_THRESHOLD, new NoThresholdDiscount());
        strategies.put(DiscountType.PER_PRICE_DISCOUNT, new PerPriceDiscount());
        strategies.put(DiscountType.RATE_DISCOUNT, new RateDiscount());
        strategies.put(DiscountType.PRICE_DISCOUNT, new PriceDiscount());
    }

    public static Discount getDiscount(DiscountType type) {
        return strategies.get(type);
    }
}
```
## 2. 优惠券智能推荐
### 2.1 思路分析
![[Pasted image 20240930102720.png]]
最终**找出优惠券组合方案的最优解**，需要满足：
- 用券相同时，**优惠金额最高**的方案
- 优惠金额相同时，**用券最少**的方案

### 2.2 定义接口
- **请求参数**为订单中各个课程的具体信息;
- **返回值**为优惠券不同排列组合的折扣金额等;
- 请求参数和返回值可以用DTO和VO进行封装.
![[Pasted image 20240930103444.png]]

### 2.3 接口实现
**实现类如下:**
```Java
@Slf4j
@Service
@RequiredArgsConstructor
public class DiscountServiceImpl implements IDiscountService {

    private final UserCouponMapper userCouponMapper;
    
    @Override
    public List<CouponDiscountDTO> findDiscountSolution(List<OrderCourseDTO> orderCourses) {
        // 1.查询我的所有可用优惠券
        // 2.初筛
        // 2.1.计算订单总价
        // 3.排列组合出所有方案
        // 3.1.细筛（找出每一个优惠券的可用的课程，判断课程总价是否达到优惠券的使用需求）
        
        // 3.2.排列组合
        
        // 4.计算方案的优惠明细

        // 5.筛选最优解
        return null;
    }
}
```
#### 2.3.1 查询用户券并初步筛选
##### 2.3.1.1 查询用户券及相关信息
1) 要查询用户的券有哪些 -> user_coupon表;
2) 查询用户券的具体信息 -> coupon表;
所以这里需要用连表查询,条件为1)券状态为"未使用"; 2)券属于该用户. 
由于查询的信息大部分都是coupon表的,所以使用coupon实体类来接收.但是还需要查询user_coupon表的用户id,考虑到用户id为BigInt类型,所以使**用coupon实体类中的`creater`属性来接收**.
最终SQL语句如下:
```Java
    <select id="queryMyCoupons" resultType="com.tianji.promotion.domain.po.Coupon">
        SELECT c.id, c.discount_type, c.`specific`, c.discount_value, c.threshold_amount,
               c.max_discount_amount, uc.id AS creater
        FROM user_coupon uc
            INNER JOIN coupon c ON uc.coupon_id = c.id
        WHERE uc.user_id = #{userId} AND uc.status = 1
    </select>
```

##### 2.3.1.2 实现初步筛选
```Java
@Slf4j
@Service
@RequiredArgsConstructor
public class DiscountServiceImpl implements IDiscountService {

    private final UserCouponMapper userCouponMapper;
    
    @Override
    public List<CouponDiscountDTO> findDiscountSolution(List<OrderCourseDTO> orderCourses) {
        // 1.查询我的所有可用优惠券:调用SQL语句
        List<Coupon> coupons = userCouponMapper.queryMyCoupons(UserContext.getUser());
        if (CollUtils.isEmpty(coupons)) {
            return CollUtils.emptyList();
        }
        // 2.初筛
        // 2.1.计算订单总价:累加订单中每个商品的价格
        int totalAmount = orderCourses.stream().mapToInt(OrderCourseDTO::getPrice).sum();
        // 2.2.筛选可用券:取出门槛达标的券
        List<Coupon> availableCoupons = coupons.stream()
                .filter(c -> DiscountStrategy.getDiscount(c.getDiscountType()).canUse(totalAmount, c))
                .collect(Collectors.toList());
		// 若可用券为空,则直接返回.
        if (CollUtils.isEmpty(availableCoupons)) {
            return CollUtils.emptyList();
    }
}
```

#### 2.3.2 细筛
前面根据总金额筛选优惠券无法作为最终结果,因为有些券是有限定范围的,所以计算门槛金额时应该**计算该券适用范围内课程的总金额**.
所以,细筛步骤有两步:  
- 首先要基于优惠券的限定范围对课程筛选，找出可用课程。如果没有可用课程，则优惠券不可用。
- 然后对可用课程计算总价，判断是否达到优惠门槛，没有达到门槛则优惠券不可用
最终是要**获得用户粗筛后的每个券对应的适用课程范围**,便于后面的进一步操作.
##### 2.3.2.1 代码实现
实现思路:
传参为**粗筛后的优惠券集合**和**订单内的课程id集合**.
返回值为**细筛后满足门槛的优惠券及其适用的课程id集合**.
```Java
private final ICouponScopeService scopeService;

private Map<Coupon, List<OrderCourseDTO>> findAvailableCoupon(
        List<Coupon> coupons, List<OrderCourseDTO> courses) {
    Map<Coupon, List<OrderCourseDTO>> map = new HashMap<>(coupons.size());
    // 对初筛后的每个券,查询其适用课程范围.
    for (Coupon coupon : coupons) {
        // 1.找出优惠券的可用的课程
        // 先初始化为courses;
        List<OrderCourseDTO> availableCourses = courses;
        // 判断是否限定范围.
        if (coupon.getSpecific()) {
            // 1.1.限定了范围,查询券的可用范围
            // (券的适用范围存储在coupon_scope表中)
            // 获得的是scope表符合要求的集合->进一步查询出biz_id(见1.2)
            List<CouponScope> scopes = scopeService.lambdaQuery().eq(CouponScope::getCouponId, coupon.getId()).list();
            // 1.2.获取范围对应的分类id
            Set<Long> scopeIds = scopes.stream().map(CouponScope::getBizId).collect(Collectors.toSet());
            // 1.3.筛选课程(利用contains判断每个课程是否在分类id集合中)
            availableCourses = courses.stream()
                    .filter(c -> scopeIds.contains(c.getCateId())).collect(Collectors.toList()); 
        }
        if (CollUtils.isEmpty(availableCourses)) {
            // 没有任何可用课程,抛弃
            continue;
        }
        // 2.计算课程总价(用于判断是否达到门槛)
        int totalAmount = availableCourses.stream().mapToInt(OrderCourseDTO::getPrice).sum();
        // 3.判断是否可用()
        Discount discount = DiscountStrategy.getDiscount(coupon.getDiscountType());
        if (discount.canUse(totalAmount, coupon)) {
            map.put(coupon, availableCourses);
        }
    }
    return map;
}
```

#### 2.3.3 优惠方案全排列组合 
**优惠券的使用顺序不同，可能导致最终的优惠金额不同。**
我们要找出优惠金额最高的优惠券组合，就必须先找出所有的排列组合，然后分别计算出优惠金额，然后对比并找出最优解。

利用封装好的工具类来实现排列组合,并**遍历可用的优惠券**,显示在前端页面.
```Java
// 3.2.排列组合
availableCoupons = new ArrayList<>(availableCouponMap.keySet());
List<List<Coupon>> solutions = PermuteUtil.permute(availableCoupons);
// 3.3.添加单券的方案
for (Coupon c : availableCoupons) {
	solutions.add(List.of(c));
}
```

#### ==2.3.4 计算优惠明细==


##### 2.3.4.2 代码实现
```Java
private CouponDiscountDTO calculateSolutionDiscount(
        Map<Coupon, List<OrderCourseDTO>> couponMap, List<OrderCourseDTO> courses, List<Coupon> solution) {
    // 1.初始化DTO
    CouponDiscountDTO dto = new CouponDiscountDTO();
    // 2.初始化折扣明细的映射
    Map<Long, Integer> detailMap = courses.stream().collect(Collectors.toMap(OrderCourseDTO::getId, oc -> 0));
    // 3.计算折扣
    for (Coupon coupon : solution) {
        // 3.1.获取优惠券限定范围对应的课程
        List<OrderCourseDTO> availableCourses = couponMap.get(coupon);
        // 3.2.计算课程总价(课程原价 - 折扣明细)
        int totalAmount = availableCourses.stream()
                .mapToInt(oc -> oc.getPrice() - detailMap.get(oc.getId())).sum();
        // 3.3.判断是否可用
        Discount discount = DiscountStrategy.getDiscount(coupon.getDiscountType());
        if (!discount.canUse(totalAmount, coupon)) {
            // 券不可用，跳过
            continue;
        }
        // 3.4.计算优惠金额
        int discountAmount = discount.calculateDiscount(totalAmount, coupon);
        // 3.5.计算优惠明细
        calculateDiscountDetails(detailMap, availableCourses, totalAmount, discountAmount);
        // 3.6.更新DTO数据
        dto.getIds().add(coupon.getCreater());
        dto.getRules().add(discount.getRule(coupon));
        dto.setDiscountAmount(discountAmount + dto.getDiscountAmount());
    }
    return dto;
}

private void calculateDiscountDetails(Map<Long, Integer> detailMap, List<OrderCourseDTO> courses,
                                      int totalAmount, int discountAmount) {
    int times = 0;
    int remainDiscount = discountAmount;
    for (OrderCourseDTO course : courses) {
        // 更新课程已计算数量
        times++;
        int discount = 0;
        // 判断是否是最后一个课程
        if (times == courses.size()) {
            // 是最后一个课程，总折扣金额 - 之前所有商品的折扣金额之和
            discount = remainDiscount;
        } else {
            // 计算折扣明细（课程价格在总价中占的比例，乘以总的折扣）
            discount = discountAmount * course.getPrice() / totalAmount;
            remainDiscount -= discount;
        }
        // 更新折扣明细
        detailMap.put(course.getId(), discount + detailMap.get(course.getId()));
    }
}
```


#### 2.3.5 CompleteableFuture并发计算
