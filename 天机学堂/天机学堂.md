# Day01:
## 1. 天机学堂介绍:
### 项目亮点:
![[Pasted image 20240912131056.png]]

## 2. 项目环境搭建:
### 2.1 导入虚拟机
**部署常用开发组件:**
修改host,直接访问域名即可映射到对应ip地址.访问域名时**自动访问80端口**,**nginx监听了80端口**,并进行反向代理.
![[Pasted image 20240912132332.png]]

## 3.阅读源码:
![[Pasted image 20240915093116.png]]
### 删除订单失效BUG分析:
#### 错误分析:
查看前端发送请求为
![[Pasted image 20240915095341.png]]
查看nginx的配置文件,发现api.tianji.com会被反向代理到![[Pasted image 20240915095955.png]]
即http://192.168.150.101:10010/ts/orders/~.再查看gateway路由,发现以ts开头的请求都被路由到了trade-service服务中,即lb://trade-service/orders/~.
![[Pasted image 20240915100222.png]]
#### 代码开发:
##### **调试方法:**
**方法一(远程调试):**
1. 新建启动项"Remote JVM DEBUG",配置Configuration;同时Jenkins中配置部署脚本,并运行,此时虚拟机中的tj-trade应多出一个5005端口,即远程调试的端口!![[Pasted image 20240915153653.png]]
==**方法二(本地调试):**==
1. 在启动trade-service时配置`-active profile: local`,此时在nacos就会新增一个trade-service服务,并且ip地址为`192.168.150.1`. 此时我们在nacos中将虚拟机中的trade-service下线,当用户访问trade-service服务时,就会走本地的trade服务,而不是虚拟机中的!!![[Pasted image 20240915154402.png]]
##### **bug修复:**
1. 经debug分析,发现是在判断用户id是否相等时出现问题,id为Long型,在进行比较时,是比较其地址.包装类提前将-128~127之间的Long包装类提前创建出来,共享使用,故当Long值在-128~127时,可以使用`==/!=`进行判断;当在这之外,则需要使用equals来判断!!!

##### **分支管理:**
- 避免直接使用lesson-init提交bug代码,新建`hotfix-delete-order-error`分支,提交代码;随后进行测试,再切换到lesson-init分支,并将hotfix分支`merge into lesson-init`分支!

# Day02:
**开发业务流程:**
![[Pasted image 20240915173012.png]]
## 我的课表:
需要强调的一点是，开发中最重要的环节其实是前两步：
- 原型分析、接口设计
- 数据库设计
那为什么要先设计接口呢？原因有两点：
- 第一：目前企业开发的模式往往是前后端分离，前后端并行开发。**前端开发需要调用后端接口**，**后端需要开发接口返回数据给前端**，要想并行开发，就必须有一套接口标准，前后端基于接口完成开发。
- 第二：设计接口的过程就是分析业务的过程，弄清楚了业务的细节，更有助于我们设计数据库结构，开发接口功能。
### 接口设计: 
#### 分析业务流程:
![[Pasted image 20240915191155.png]]

#### 接口统计:
根据业务流程,梳理可能需要开发的接口:
1) **加入课表:** 用户支付完成后,需要将已购买的课程加入课表. 支付完成后,交易服务会基于MQ通知(支付完成与加入课表无需同步进行)的方式,通知学习服务来执行加入课表的动作.
   ->**接口1:** 支付或报名课程后,监听到MQ通知,将课程加入课表.
2) **查询课表:** 课程加入课表后,用户可以在个人中心中查看课程.
   ->**接口2:** 分页查询我的课表.
3) **删除课程:** 课程学完后(或过期,退款等),用户可以选择将课程删除.
   ->**接口3:** 删除指定课程.
   ->**接口4:** 退款后,监听到MQ通知,删除指定课程.
4) **查询学习进度:** 用户可以查看最近的学习进度
   ->**接口5:** 查询最近正在学习的课程.
   ->**接口6:** 查询学习计划的进度.
   ![[Pasted image 20240915192307.png|600]]
5) **查询指定课程的学习状态:** 用户可以在课程中心查看指定课程的学习状态以及学习进度.
   ->**接口7:** 根据id查询指定课程的学习状态.![[Pasted image 20240915192558.png]]
6) **内部访问接口:** 除了页面原型中看到的接口以外,其它微服务也对`tj-learning`服务有数据需求,并且也定义了一些需要我们实现的Feign接口.在天机学堂的项目中,所有Feign接口都定义在了`tj-api`模块下，`learning`服务的接口定义在`com.tianji.api.client.learning`模块下:
   ->**接口8:** **统计某课程的报名人数**:后台管理的某些地方需要知道课程的报名人数
   ->**接口9:** **校验**当前用户是否报名了指定课程:用户学习课程的前提是报名了课程,某些业务中需要做校验![[Pasted image 20240915192742.png]]
**接口总结:**

| **编号** | **接口简述**                   | **请求方式** | **请求路径**                  |
| ------ | -------------------------- | -------- | ------------------------- |
| 1      | 支付或报名课程后，立刻加入课表            | MQ通知     |                           |
| 2      | 分页查询我的课表                   | GET      | /lessons/page             |
| 3      | 查询我最近正在学习的课程               | GET      | /lessons/now              |
| 4      | 根据id查询指定课程的学习状态            | GET      | /lessons/{courseId}       |
| 5      | 删除课表中的某课程                  | DELETE   | /lessons/{courseId}       |
| 6      | 退款后，立刻移除课表中的课程             | MQ通知     |                           |
| 7      | 校验指定课程是否是课表中的有效课程（Feign接口） | GET      | /lessons/{courseId}/valid |
| 8      | 统计课程学习人数（Feign接口）          | GET      | /lessons/{courseId}/count |
**MyBatisX插件使用方法:**
1. 配置数据源: `Tools-> Config Database`:
2. **设置代码生成:**![[Pasted image 20240915201844.png|800]]
3. 根据主键策略和枚举类调整相应属性:
```java
@ApiModelProperty(value = "主键")  
@TableId(value = "id", type = IdType.ASSIGN_ID)   // 根据数据库主键配置调整主键策略.  
private Long id;  
  
@ApiModelProperty(value = "课程状态，0-未学习，1-学习中，2-已学完，3-已失效")  
private LessonStatus status;    // 利用枚举类定义状态
  
@ApiModelProperty(value = "学习计划状态，0-没有计划，1-计划进行中")  
private PlanStatus planStatus;   
```
4. 根据接口设计调整Controller方法中的默认路径.

### 代码开发-添加课程到课表:
#### 接口设计:
![[Pasted image 20240915204756.png|600]]
#### 代码开发:
##### 1. **编写消息监听类:**
在`com.tianji.learning.mq`新建LessonChangeListener监听类. 
	1) 添加`@Component`注解,将监听类交由Spring容器管理;
	2) `@RequiredArgsConstructor`与`final`,实现构造器注入;
	3) `@RabbitListener`定义监听方法.
```java
@Component  
@Slf4j  
@RequiredArgsConstructor  
public class LessonChangeListener {  
  
    private final ILearningLessonService lessonService;  
  
    @RabbitListener(bindings = @QueueBinding(value = @Queue(value = "learning.lesson.pay.queue",durable = "true"),  
    exchange = @Exchange(value = MqConstants.Exchange.ORDER_EXCHANGE,type = ExchangeTypes.TOPIC),  
    key = MqConstants.Key.ORDER_PAY_KEY))  
    public void onMsg(OrderBasicDTO orderBasicDTO){  
        log.info("接收到消息！！");  
//        TODO 校验参数(健壮性处理)
        if (orderBasicDTO == null || orderBasicDTO.getUserId() == null  
                || CollUtils.isEmpty(orderBasicDTO.getCourseIds())){  
            log.info("订单数据为空！");  
		// 处理异常时,不可抛出,否则Mq会持续尝试,直到达到上限!  
            return;  
        }  

//        TODO 调用service,保存课程到课表  
        lessonService.addUserLesson(orderBasicDTO.getUserId(), orderBasicDTO.getCourseIds());  
    }  
}
```
##### 2. Service层:
- 监听类传递了userId与courseId给Serivce层,实现将课程保存到课表,需要PO类,故需要实现DTO->PO,故观察课表中的字段. 发现很多字段都有默认值,故只需设置`user_id,course_id,expire_time`三个字段即可.
![[Pasted image 20240916092854.png]]
- user_id,course_id已由Listener传递,故只需查询过期时间,即通过"加入课程时间+有效期"获得,由此通过**调用courseClient来查询课程信息,获得每个课程的有效期!**
```java
    @Override  
    public void addUserLesson(Long userId, List<Long> courseIds) {  
//        TODO 通过feign远程调用服务,得到课程信息  
        List<CourseSimpleInfoDTO> cinfos = courseClient.getSimpleInfoList(courseIds);  
  
        List<LearningLesson> list = new ArrayList<>();  
//        TODO 封装PO实体类，填充过期时间  
        for (CourseSimpleInfoDTO info : cinfos){  
            LearningLesson learningLesson = new LearningLesson();  
  
            learningLesson.setUserId(userId);  
            learningLesson.setCourseId(info.getId());  
            Integer validDuration = info.getValidDuration();  
            if (validDuration != null) {  
                LocalDateTime now = LocalDateTime.now();  
                learningLesson.setCreateTime(now);  
                learningLesson.setExpireTime(now.plusMonths(validDuration));  
            }  
  
            list.add(learningLesson);  
        }  
//        TODO 批量保存(MyBatisPlus的方法)
        saveBatch(list);  
    }
```
##### 3. Bug修复:
- 在这里出现了一个问题,添加课程时发现LeanringApplication无响应!?查看前端发送的请求,发现是先请求`/freecourse/{courseId}`,并且返回数据为`msg="课程已过期"`! 查询后发现是`OrderController`中的`enrolledFreeCourse()`,**追踪业务逻辑**,发现是在service层调用了`getOnShelfCourse`判断课程是否过期导致! 故将该判断逻辑注释,重新编译运行,发现请求可正确到达LearningApplication! 自此,成功修复该Bug!!
![[Pasted image 20240916095301.png]]

### 代码开发-分页查询我的课表:
#### **接口设计:**
![[Pasted image 20240915193407.png]]
#### 代码开发:
##### Controller层:
- 使用构造器注入: 1)利用final定义成员变量; 2)添加@RequiredArgsConstructors注解.
```java
private final ILearningLessonService lessonService;

@GetMapping("page")  
@ApiOperation("分页查询我的课表")  
public PageDTO<LearningLessonVO> queryMyLessons(PageQuery pageQuery){  
    return lessonService.queryMyLessons(pageQuery);  
}
```
##### Service层:
>[!实现分页查询的几种方法]
>1)利用MyBatis分页插件的`PageHelper.startPage(PageNum,PageSize)`方法;
>2)利用MyBatis中的Page方法


### 接口开发-查询正在学习的课程

# Day03:学习计划和进度
## 提交学习记录:
### 需求分析和接口设计:

#### 需求:
在课程学习页面播放视频时或考试后,需要提交学习记录信息到服务端保存.
![[Pasted image 20240917104006.png|300]]
#### 接口:
- 小节类型包含课程or考试.若考试,则直接记录未完成;若为课程,则需判断视频播放进度超过50%.
![[Pasted image 20240917104134.png]]![[Pasted image 20240917144410.png]]

## 课程过期定时任务
- 利用SpringTask实现定时任务: 1)启动类上开启@EnableScheduling注解; 2)编写定时任务类,如下
```java
@Component
public class LessonStatusCheckJob(){
	@Scheduled(cron = "0 * * * * ?") // 代表每分钟的第0秒执行一次
	public void lessonStatusCheck(){
		// 1. 查询所有未过期的课程 
		List<LearningLesson> list = lessonService.list(Wrappers.<LearningLesson>lambdaQuery()
										.ne(LearningLesson::getStatus, LessonStatus.EXPIRED);
					
		// 2. 判断是否过期
		for (LearningLesson lesson : list){
			if(now.isAfter(lesson.getExpireTime())){
				lesson.setStatus(LessonStatus.Expired);
			}
		}
		// 3. 批量更新
		lessonSerivce.updateBatchById(list);
	}
}
```

## 方案思考
### 思考题：思考一下目前提交学习记录功能可能存在哪些问题？有哪些可以改进的方向？
- 更新学习记录时,因为是每15秒查询一次,所以在用户量大时,对数据库的访问量很大! 所以在"更新最近学习小节"与"更新最近学习时间"时,需要进行优化!


# Day04:高并发优化
## 1. 高并发优化方案:
解决高并发问题从宏观角度来说有3个方向:
其中，水平扩展和服务保护侧重的是运维层面的处理。而**提高单机并发能力侧重**的则是业务层面的处理，也就是我们程序员在开发时可以做到的。
![[Pasted image 20240917191422.png]]
### 1.1 提高单机并发能力:
- 在机器性能一定的情况下,提高单机并发能力就是要尽可能**缩短业务的响应时间**（**R**esponse**T**ime）,而对响应时间影响最大的往往是对数据库的操作。
![[Pasted image 20240917191849.png]]
### 1.2 变同步写为异步写
![[Pasted image 20240917193108.png]]
利用MQ可以把同步业务变成异步，从而提高效率。
- 当我们接收到用户请求后,可以先不处理业务,而是**发送MQ消息并返回给用户结果**。
- 而后通过**消息监听器**监听MQ消息,处理后续业务。

#### **优点**:
- 无需等待复杂业务处理，大大减少响应时间
- 利用MQ暂存消息，起到流量削峰整形作用
- 降低写数据库频率，减轻数据库并发压力
#### 缺点：
- 依赖于MQ的可靠性
- 降低了写频率,但是没有减少数据库写次数
#### 应用场景：
- 比较适合应用于业务复杂,业务链较长,有多次数据库写操作的业务.

### 1.3 合并写请求:
- 合并写请求就是指当写数据库并发较高时，不再直接写到数据库。而是**先将数据缓存到Redis**，然后**定期**将缓存中的数据批量写入数据库。
![[Pasted image 20240917193640.png]]
- 由于Redis是内存操作，写的效率也非常高，这样每次**请求的处理速度大大提高,响应时间大大缩短**，并发能力肯定有很大的提升。
- 而且由于数据都缓存到Redis了，积累一些数据后再**批量写入**数据库，这样数据库的写频率、写次数都大大减少，对数据库压力小了非常多！
#### 优点:
- 写缓存速度快，响应时间大大减少
- 降低数据库的写频率和写次数，大大减轻数据库压力
#### 缺点:
- 实现相对复杂
- 依赖Redis可靠性
-  不支持事务和复杂业务
#### 场景:
- 写频率较高、写业务相对简单的场景

## 2. 播放进度记录方案改进
- 播放进度统计包含大量的数据库读,写操作, 尤其是写操作, 所以通过高并发优化方案2来实现,即合并写请求.
### 2.1 优化方案选择:
前端**每隔15秒**就提交一次请求。在一个视频播放的过程中，可能有数十次请求，但**完播（进度超50%）的请求只会有一次**。因此多数情况下都是更新一下播放进度即可。也就是说，**95%的请求都是在更新`learning_record`表中的`moment`字段，以及`learning_lesson`表中的正在学习的小节id和时间。** 并且我们只需记录最后一次的播放进度即可,故**==采用合并写的方案==**来降低数据库写的次数和频率.

### 2.2 Redis数据结构设计:
因为需要更新某个用户的某个小节的播放进度,所以Key为sectionId和userid,Value为播放进度(moment)和用户id. 因为sectionId和userId即为lessonId,故选择lessonId作为Key值即可. 
![[Pasted image 20240917194756.png#pic_center|300]]
这样设计有一个问题.课程有很多,每个课程的小节也非常多.每个小节都是一个独立的KEY，需要创建的KEY也会非常多,浪费大量内存.

而且，用户学习视频的过程中，可能会在多个视频之间来回跳转，这就会导致**频繁的创建缓存、缓存过期，影响到最终的业务性能**。该如何解决呢? 
	可以把一个课程的多个小节作为一个KEY来缓存:
![[Pasted image 20240917200513.png|400]]
这样做有两个好处：
- 可以大大**减少需要创建的KEY的数量**，减少内存占用。
- 一个课程创建一个缓存，当用户在**多个视频间跳转时，整个缓存的有效期都会被延续**，**不会频繁的创建和销毁缓存数据**
### 2.3 业务流程更新:
添加缓存以后，学习记录提交的业务流程就需要发生一些变化:
![[Pasted image 20240917200815.png]]
变化最大的有几点：
- 查询记录是否存在时,先查询Redis,再查询数据库.若Redis无而DB有,则将DB中的数据存入Redis,并继续走左侧分支.
- 提交播放进度后,如果是**更新播放进度则不写数据库,而是写缓存,即更新Redis中的moment**
- 需要一个定时任务，**定期将缓存数据写入数据库**
### 2.4 持久化思路 
对于合并写请求方案，一定有一个步骤就是持久化缓存数据到数据库。一般采用的是定时任务持久化. 但是又会有两个问题: 1)定时任务频率太高,则会造成数据库压力过大; 2)定时任务频率太低,则不满足续播的误差需求.

> 那么问题来了，有什么办法能够在**不增加数据库压力的情况下,保证时间误差较低**吗？

我们再次打开该视频续播的时候，肯定是从最后一次提交的播放进度来续播。也就是说**续播进度之前的N次播放进度都是没有意义的**，都会被覆盖。

既然如此，我们完全没有必要定期把这些播放进度写到数据库，只需要将用户最后一次提交的播放进度写入数据库即可。所以我们完全没有必要定期把这些播放进度写到数据库，只需要将用户**最后一次提交的播放进度写入数据库**即可。

> 但问题来了，我们怎么知道哪一次提交是最后一次提交呢？

只要用户一直在提交记录，Redis中的播放进度就会一直变化。**如果Redis中的播放进度不变，肯定是停止了播放，是最后一次提交。**

>因此，我们只要能判断Redis中的播放进度是否变化即可。怎么判断呢？

每当前端提交播放记录时，我们可以**设置一个延迟任务并保存这次提交的进度**。等待20秒后（因为前端每15秒提交一次，**20秒就是等待下一次提交**），检查Redis中的缓存的进度与任务中的进度是否一致。
- 不一致：说明持续在提交，无需处理
- 一致：说明是最后一次提交，更新学习记录、更新课表最近学习小节和时间到数据库中.

流程如下:![[Pasted image 20240917204209.png]]

## 3. 延迟任务
### 3.1 延迟任务方案
![[Pasted image 20240917204644.png]] 
### DelayQueue的用法:
- `Delayed`类型元素,即实现了Delayed接口的延迟任务类:
  - 实现getDelay()和compareTo()方法,功能为获取剩余延迟时间、比较执行顺序.
```Java
@Data
public class DelayTask<D> implements Delayed {
    private D data;
    private long deadlineNanos;

    public DelayTask(D data, Duration delayTime) {
        this.data = data;
        this.deadlineNanos = System.nanoTime() + delayTime.toNanos();
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return unit.convert(Math.max(0, deadlineNanos - System.nanoTime()), TimeUnit.NANOSECONDS);
    }

    @Override
    public int compareTo(Delayed o) {
        long l = getDelay(TimeUnit.NANOSECONDS) - o.getDelay(TimeUnit.NANOSECONDS);
        if(l > 0){
            return 1;
        }else if(l < 0){
            return -1;
        }else {
            return 0;
        }
    }
}
```

- `queue.add(new DelayTask<>(Object,Times))`:往延迟队列中添加`Delayed`类型元素;
- `queue.poll()`: 非阻塞式出队方法,即为空时也会执行并输出;
- `queue.take()`: 阻塞式出队方法,只有当非空时才会出队. 无元素时,线程会一直等待!

## 4. 代码改造
将业务流程封装成工具类,需要时直接调用工具类即可.
1. 添加播放记录到Redis，并添加一个延迟检测任务到DelayQueue
2. 查询Redis缓存中的指定小节的播放记录
3. 删除Redis缓存中的指定小节的播放记录
4. 异步执行DelayQueue中的延迟检测任务，检测播放进度是否变化，如果无变化则写入数据库
### 4.1 定义延迟任务工具类: 
定义延迟任务类,实现Delayed接口,实现其中的`getDelay()`与`compareTo()`方法.
```java
@Data  
public class DelayTask<D> implements Delayed {  
    private D data;  
    private long deadlineNanos;  
  
    public DelayTask(D data, Duration delayTime) {  
        this.data = data;  
        this.deadlineNanos = System.nanoTime() + delayTime.toNanos();  
    }  
  
    @Override  
    public long getDelay(TimeUnit unit) {  
        return unit.convert(Math.max(0, deadlineNanos - System.nanoTime()), TimeUnit.NANOSECONDS);  
    }  
  
    @Override  
    public int compareTo(Delayed o) {  
        long l = getDelay(TimeUnit.NANOSECONDS) - o.getDelay(TimeUnit.NANOSECONDS);  
        if(l > 0){  
            return 1;  
        }else if(l < 0){  
            return -1;  
        }else {  
            return 0;  
        }  
    }  
}
```

### 4.2 添加学习记录到Redis与添加延迟任务到DelayQueue

```java
public void addLearningRecordTask(LearningRecord record){  
    // 1.添加数据到Redis缓存  
    writeRecordCache(record);  
    // 2.提交延迟任务到延迟队列 DelayQueue    
    queue.add(new DelayTask<>(new RecordTaskData(record), Duration.ofSeconds(20)));  
}  
  
public void writeRecordCache(LearningRecord record) {  
    log.debug("更新学习记录的缓存数据");  
    try {  
        // 1.数据转换:转换为Json字符串存储到Redis中.
        String json = JsonUtils.toJsonStr(new RecordCacheData(record));  
        // 2.写入Redis,定义Key为learning:record:LessonId
        String key = StringUtils.format(RECORD_KEY_TEMPLATE, record.getLessonId());  
        redisTemplate.opsForHash().put(key, record.getSectionId().toString(), json);  
        // 3.添加缓存过期时间. 缓存过期时间为1mins,而Redis中数据每20秒不更新就会写入DB中,故无影响.
        redisTemplate.expire(key, Duration.ofMinutes(1));  
    } catch (Exception e) {  
        log.error("更新学习记录缓存异常", e);  
    }  
}
```
其中,RecordCacheData类如下,即对应了Redis中的HashValue中的属性.
![[Pasted image 20240917200513.png|400]]
```java
@Data  
@NoArgsConstructor  
private static class RecordCacheData{  
    private Long id;  
    private Integer moment;  
    private Boolean finished;  
  
    public RecordCacheData(LearningRecord record) {  
        this.id = record.getId();  
        this.moment = record.getMoment();  
        this.finished = record.getFinished();  
    }  
}
```

RecordTaskData类:
- 对应Redis中的属性.
```java
@Data  
@NoArgsConstructor  
private static class RecordTaskData{  
    private Long lessonId;  
    private Long sectionId;  
    private Integer moment;  
  
    public RecordTaskData(LearningRecord record) {  
        this.lessonId = record.getLessonId();  
        this.sectionId = record.getSectionId();  
        this.moment = record.getMoment();  
    }  
}
```

### 4.3 查询小节播放记录
从Redis中读取播放记录.
```java
public LearningRecord readRecordCache(Long lessonId, Long sectionId){  
    try {  
        // 1.读取Redis数据:拼接Key并查询!
        String key = StringUtils.format(RECORD_KEY_TEMPLATE, lessonId);  
        Object cacheData = redisTemplate.opsForHash().get(key, sectionId.toString());  
        if (cacheData == null) {  
            return null;  
        }  
        // 2.数据检查和转换  
        return JsonUtils.toBean(cacheData.toString(), LearningRecord.class);  
    } catch (Exception e) {  
        log.error("缓存读取异常", e);  
        return null;  
    }  
}
```

### 4.4 删除小节播放记录
```java
public void cleanRecordCache(Long lessonId, Long sectionId){  
    // 删除数据:拼接Key,查询然后删除.
    String key = StringUtils.format(RECORD_KEY_TEMPLATE, lessonId);  
    redisTemplate.opsForHash().delete(key, sectionId.toString());  
}
```

### 4.5 异步延迟任务
- @PostConstructor:当前**类实例化后且属性注入后执行**,常用来做初始化!
- `CompletableFuture.runAsync(this::handleDelayTask)`:会**开启一个新线程**来执行任务handleDelayTask任务.
- @PreDestory:当前**类实例销毁前执行**.
```java
@PostConstruct  
public void init(){  
    CompletableFuture.runAsync(this::handleDelayTask);  
}  
@PreDestroy  
public void destroy(){  
    log.debug("关闭学习记录处理的延迟任务");  
    begin = false;  
}  
private void handleDelayTask(){  
    while (begin){  
        try {  
            // 1.尝试获取任务: 阻塞式拉取任务
            DelayTask<RecordTaskData> task = queue.take();  
            log.debug("获取到要处理的播放记录任务");  
            RecordTaskData data = task.getData();  
            // 2.读取Redis缓存  
            LearningRecord record = readRecordCache(data.getLessonId(), data.getSectionId());  
            if (record == null) {  
                continue;  
            }  
            // 3.比较数据:拿Redis中的播放记录与任务中的播放记录进行比较!
            if(!Objects.equals(data.getMoment(), record.getMoment())){  
                // 4.如果不一致，播放进度在变化，无需持久化  
                continue;  
            }  
            // 5.如果一致，证明用户离开了视频，需要持久化: 更新数据库
            // 5.1.更新学习记录  
            record.setFinished(null);  
            recordMapper.updateById(record);  
            // 5.2.更新课表  
            LearningLesson lesson = new LearningLesson();  
            lesson.setId(data.getLessonId());  
            lesson.setLatestSectionId(data.getSectionId());  
            lesson.setLatestLearnTime(LocalDateTime.now());  
            lessonService.updateById(lesson);  
  
            log.debug("准备持久化学习记录信息");  
        } catch (Exception e) {  
            log.error("处理播放记录任务发生异常", e);  
        }  
    }  
}
```

### 4.6 源代码改造
需要改造的部分一共有以下几个:
![[Pasted image 20240919234412.png|450]]
#### 4.6.1 改造"查询学习记录":
![[Pasted image 20240919234236.png]]
原思路:直接查询数据库,判断记录是否存在. 
改造后思路:
1. 先查询缓存;
2. 若命中,则直接返回缓存数据;
2. 若未命中,则再查询数据库,并将数据库中的数据写入缓存!

```java
private LearningRecord queryOldRecord(Long lessonId, Long sectionId) {
	// 1.查询缓存
	LearningRecord cache = taskHandler.readRecordCache(lessonId, sectionId);
	// 2.如果命中，直接返回
	if (record != null) {
		return cache;
	}
	// 3.未命中，查询数据库
	LearningRecord dbRecord = lambdaQuery()
			.eq(LearningRecord::getLessonId, lessonId)
			.eq(LearningRecord::getSectionId, sectionId)
			.one();
	// 若数据库中的数据也为空,则返回null以便后面判断通过,以新增学习逻辑.
	if (record == null){
		return null;
	}
	// 4.写入缓存
	taskHandler.writeRecordCache(record);
	return record;
}
```
#### 4.6.2 改造"是否是第一次学完":
![[Pasted image 20240920000538.png]]
改造后思路:
- 若非第一次学完,则缓存学习记录到Redis;(调用4.2中的addLearningRecordTask方法)'
	- 封装LearningRecord对象;
- 若为第一次学完,则更新学习记录,并清楚缓存(即播放记录)
- 并提交延迟任务;
```java hl:5-13,26
        // 4.存在，则更新
        // 4.1.判断是否是第一次完成
        boolean finished = !old.getFinished() && recordDTO.getMoment() * 2 >= recordDTO.getDuration();
        if (!finished) {
            LearningRecord record = new LearningRecord();
            record.setLessonId(recordDTO.getLessonId());
            record.setSectionId(recordDTO.getSectionId());
            record.setMoment(recordDTO.getMoment());
            record.setId(old.getId());
            record.setFinished(old.getFinished());
            // 提交延迟任务
            taskHandler.addLearningRecordTask(record);
            return false;
        }
        // 4.2.更新数据
        boolean success = lambdaUpdate()
                .set(LearningRecord::getMoment, recordDTO.getMoment())
                .set(LearningRecord::getFinished, true)
                .set(LearningRecord::getFinishTime, recordDTO.getCommitTime())
                .eq(LearningRecord::getId, old.getId())
                .update();
        if (!success) {
            throw new DbException("更新学习记录失败！");
        }
        // 4.3.清理缓存
        taskHandler.cleanRecordCache(recordDTO.getLessonId(), recordDTO.getSectionId());
        return true;
```

## 5.1.线程池的使用

目前我们的延迟任务执行还是单线程模式,大家将其改造为线程池模式,核心线程数与CPU核数一致即可.
### 创建线程池的方式
不建议,会出现OutOfMemory异常!
(因为**无法指定内部BlockQueue的容量**,故可能因为任务量太大而导致内存溢出!)
`Executors.newFixedThreadPool()`:创建固定线程的线程池
`Executors.newSingleThreadPool()`:创建单线程的线程池
`Executors.newCachedThreadPool()`:创建缓存线程池
`Executors.newScheduledThreadPool()`:创建可执行延迟任务的线程池

上述四个创建方式的**底层**都是:
`new ThreadPoolExecutor(corePoolSize, maximumPoolSize, KeepAliveTime, TimeUnit, BlockQueue)`
**参数设置建议:**
1. 如果任务属于CPU运算型任务,推荐核心线程为CPU的核数.
2. 如果任务属于IO型(读写型) ,推荐核心线程为CPU核数的两倍.

### 线程池的使用:
- 调用线程池的submit方法,传入Runnable类的对象,并实现其run方法.
```
poolExecutor.submit(new Runnable(){
	@Override
	public void run(){
		// 需要执行任务
	}
})
```
### 线程池的执行流程:
![[Pasted image 20240920200013.png|450]]
1. 若有空闲核心线程,则调用线程执行任务;
2. 若核心线程已满,则进入阻塞队列排队,等待核心线程执行;
3. 若队列也已满,则会创建临时线程执行;
4. 若临时线程也已满,则会走拒绝策略!


# Day06:
## 1. 业务流程:
![[Pasted image 20240920221310.png|450]]

我们说过点赞服务必须独立，因此必须抽取为一个**独立服务**。多个其它微服务业务的点赞数据都有点赞系统来维护。
	如果业务方需要根据点赞数排序，就必须在数据库中维护点赞数字段。但是**点赞系统无法修改其它业务服务的数据库，否则就出现了业务耦合**。该怎么办呢？
**解决方法:**
![[Pasted image 20240920221823.png]]
## 2. 表设计:
点赞记录本质就是记录**谁给什么内容点了赞**，所以核心属性包括：
- 点赞目标id
- 点赞人id
不过点赞的内容多种多样，为了加以区分，我们还需要把**点赞的内容类型**记录下来：
- 点赞对象类型（为了通用性）
![[Pasted image 20240920222127.png]]

其中,user_id和biz_id为联合唯一索引,保证用户只能点赞该业务一次!
![[Pasted image 20240920222502.png]]

## 3. 实现点赞功能:
前端需要根据**是否点赞过**来相应的渲染点赞按钮,即灰色和点亮,所以需要实现**查询用户点赞状态**的接口,用于判断该用户是否点赞过该业务.因此需要实现两个接口:
1) 点赞/取消点赞
2) 根据多个业务id批量查询用户是否点赞多个业务
### 3.1.点赞或取消点赞
### 3.1.1.接口信息
点赞就是新增一条点赞记录，取消就是删除这条记录,可合并为同一个接口,便于前端交互. 所以**请求参数**首先要包含点赞相关的数据:
1) 用户id(ThreadLocal中,由jwt令牌(token)传递);
2) 业务类型(是问答还是评论)->**用于确保点赞功能的通用性!**
3) 业务id;
4) 是否点赞

返回值有两种设计：
- 方案一：无返回值，200就是成功，页面直接把点赞数+1展示给用户即可
- 方案二：返回点赞数量，页面渲染
这里推荐使用方案一，因为每次**统计点赞数量也有很大的性能消耗**。

综上,接口信息如下:
![[Pasted image 20240921093338.png]]
### 3.1.2 业务流程
点赞业务的几点需求：
- 点赞就新增一条点赞记录，取消点赞就删除记录
- 用户不能重复点赞
- **点赞数由具体的业务方保存，需要通知业务方更新点赞数**
	- 通过MQ实现,减少了每次点赞都需要统计点赞数量造成的大性能消耗.
![[Pasted image 20240921092926.png]]

业务方有两个:回答或者评论. 根据MQ通知业务方时,由于**每次点赞的业务类型不同，所以没有必要通知到所有业务方，而是仅仅通知与当前点赞业务关联的业务方即可**。

在RabbitMQ中，利用**TOPIC类型的交换机**，结合**不同的RoutingKey**，可以实现通知对象的变化。我们需要让**不同的业务方监听不同的RoutingKey**，然后发送通知时根据点赞类型不同，发送不同RoutingKey:
![[Pasted image 20240921093721.png]]

### 3.1.3 完整业务代码实现:
梳理业务逻辑:
1) 是点赞还是取消点赞;
2.1) 走点赞逻辑 -> 代码中为`like(recordDTO)`方法
	 新增点赞记录
2.2) 取消赞逻辑 -> 代码中为`unlike(recordDTO)`方法
	 删除点赞记录;
3) 统计该业务id下的总点赞数量 -> 根据业务id来统计
4) 发送消息到MQ ->参数为交换机,RoutingKey和消息内容.
	```java
	mqHelper.send(
	LIKE_RECORD_EXCHANGE,
	StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, recordDTO.getBizType()),
	LikedTimesDTO.of(recordDTO.getBizId(), likedTimes));
	```

```java
/**
 * <p>
 * 点赞记录表 服务实现类
 * </p>
 */
@Service
@RequiredArgsConstructor
public class LikedRecordServiceImpl extends ServiceImpl<LikedRecordMapper, LikedRecord> implements ILikedRecordService {

    private final RabbitMqHelper mqHelper;

    @Override
    public void addLikeRecord(LikeRecordFormDTO recordDTO) {
        // 1.基于前端的参数，判断是执行点赞还是取消点赞
        boolean success = recordDTO.getLiked() ? like(recordDTO) : unlike(recordDTO);
        // 2.判断是否执行成功，如果失败，则直接结束
        if (!success) {
            return;
        }
        // 3.如果执行成功，统计点赞总数
        Integer likedTimes = lambdaQuery()
                .eq(LikedRecord::getBizId, recordDTO.getBizId())
                .count();
        // 4.发送MQ通知
        mqHelper.send(
                LIKE_RECORD_EXCHANGE,
                StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, recordDTO.getBizType()),
                LikedTimesDTO.of(recordDTO.getBizId(), likedTimes));
    }

    private boolean unlike(LikeRecordFormDTO recordDTO) {
        return remove(new QueryWrapper<LikedRecord>().lambda()
                .eq(LikedRecord::getUserId, UserContext.getUser())
                .eq(LikedRecord::getBizId, recordDTO.getBizId()));
    }

    private boolean like(LikeRecordFormDTO recordDTO) {
        Long userId = UserContext.getUser();
        // 1.查询点赞记录
        Integer count = lambdaQuery()
                .eq(LikedRecord::getUserId, userId)
                .eq(LikedRecord::getBizId, recordDTO.getBizId())
                .count();
        // 2.判断是否存在，如果已经存在，直接结束
        if (count > 0) {
            return false;
        }
        // 3.如果不存在，直接新增
        LikedRecord r = new LikedRecord();
        r.setUserId(userId);
        r.setBizId(recordDTO.getBizId());
        r.setBizType(recordDTO.getBizType());
        save(r);
        return true;
    }
}
```

## 4. 批量查询点赞状态
### 4.0 Feign拦截器
Feign拦截器会在微服务间通过Feign实现远程调用时,校验ThreadLoca中是否包含userId,如果有则放入Feign请求的请求头中!
	Feign是一个声明式的HTTP客户端,主要作用是**简化服务间的HTTP调用**.通过Feign,开发者可以像调用本地方法一样调用远程服务,无需编写复杂的HTTP请求处理逻辑.
![[Pasted image 20240922112321.png]]
**具体代码实现如下:** 
- `UserContext.getUser()`即是将从ThreadLocal中获取userId封装起来了.
- `template.header`就是重新放入Feign请求头中!
```java
public class FeignRelayUserInterceptor implements RequestInterceptor {  
    @Override  
    public void apply(RequestTemplate template) {  
        Long userId = UserContext.getUser();  
        if (userId == null) {  
            return;  
        }  
        template.header(JwtConstants.USER_HEADER, userId.toString());  
    }  
}
```

### 4.1 暴露Feign接口
为了其他微服务能调用该接口,必须**暴露Feign客户端**,并定义好**fallback降级处理**.

#### 4.1.1 为接口创建client客户端:
1. 在`tj-api.com.tianji.api.client.remark`中创建RemarkClient,拷贝Controller中的isBizLiked方法,即查询点赞状态的服务.
	**`@FeignClient` 注解:**
		`value="remark-service"`,即被调用的服务名(注册在nacos中的名字)
		fallbackFactory="RemarkClientFallback.class"
	**`@fallbackFactory`注解**: 指定降级处理类!
```Java
@FeignClient(value = "remark-service", fallbackFactory = RemarkClientFallback.class)
public interface RemarkClient {
    @GetMapping("/likes/list")
    Set<Long> isBizLiked(@RequestParam("bizIds") Iterable<Long> bizIds);
}
```

#### 4.1.2 Feign降级处理:
![[Pasted image 20240921192054.png|450]]
因为微服务之间的长调用链路,当C挂掉时,B无法调用C就会一直等待,此时B中存在大量阻塞线程,直到超时,并导致B也挂掉,同理也会导致A,D也挂掉! 即**雪崩(级联失败)现象**!
此时引入**降级处理**,当C挂掉时,B不会一直等待,而是在等待一定时间后,走C的降级处理类,并返回假数据,此时B就不会阻塞,避免了雪崩出现.

**实现:**
1. 引入open-feign与sentinel依赖!
2. 在`~.client.remark`中创建子包fallback,并创建降级处理类`RemarkClientFallback`,**实现`FallbackBackFactory<T>`接口,重写create(Throwable cause)方法,返回Feign客户端!**
```java
@Slf4j
public class RemarkClientFallback implements FallbackFactory<RemarkClient> {

    @Override
    public RemarkClient create(Throwable cause) {
        log.error("查询remark-service服务异常", cause);
        return new RemarkClient() {

            @Override
            public Set<Long> isBizLiked(Iterable<Long> bizIds) {
                return CollUtils.emptySet();
            }
        };
    }
}
```
3. 编写FallbackConfig配置类与nacos中的shared-feign配置类(开启sentinel)
```Java 
@Configuration
public class FallbackConfig {
    @Bean
    public RemarkClientFallback remarkClientFallback(){
        return new RemarkClientFallback();
    }
}
```

```yaml
feign:
	sentinel:
		enabled: true
```

### 4.1.3 监听点赞变更的消息
当用户点赞后,会发送MQ消息到相应的业务方!以互动问答为例,需要**定义MQ监听器,自动监听消息队列中的消息并进行消费!

在learning模块中创建mq包,创建`LikeTimesChangeListener监听器`,并加上`@Component`注解交由Spring容器管理.注入`replyService`,以实现对数据库的更新操作!
**加上@RabbitListener注解:**
	`value = @Queue(name = "qa.liked.times.queue", durable = "true")`: **定义一个名称为`qa.liked.times.queue`的持久化队列!**
	`exchange = @Exchange(name = "likeRecordExchange", type = ExchangeTypes.TOPIC), key = "qa.liked.times`: 将队列绑定到`likeRecordExchange`交换机上,使用路由键`QA_LIKED_TIMES_KEY`来路由消息.
		**exchange的属性都在其他地方定义!** 
	
```java
@Slf4j
@Component
@RequiredArgsConstructor
public class LikeTimesChangeListener {

    private final IInteractionReplyService replyService;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "qa.liked.times.queue", durable = "true"),
            exchange = @Exchange(name = LIKE_RECORD_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = QA_LIKED_TIMES_KEY
    ))
    public void listenReplyLikedTimesChange(LikedTimesDTO dto){
        log.debug("监听到回答或评论{}的点赞数变更:{}", dto.getBizId(), dto.getLikedTimes());
        InteractionReply r = new InteractionReply();
        r.setId(dto.getBizId());
        r.setLikedTimes(dto.getLikedTimes());
        replyService.updateById(r);
    }
}
```
## 5. 点赞功能改进
点赞业务包含多次数据库读写操作,当点赞的用户,次数过多时,会造成数据库压力过大!当有人非常频繁的点赞、取消点赞.这样就会给数据库带来非常大的压力。
![[Pasted image 20240921201954.png]]

### 5.1 改进思路分析:
在前面改进"更新学习记录"功能时,就是利用了合并写请求的优化方案,使用Redis作缓存,以及MQ异步写来实现减少写操作.
然而,**此处虽然用了MQ异步写,此处更重要的是利用MQ来解耦(通过MQ来通知其他业务执行更新操作)**,数据库写的次数并没有减少,压力依旧很大!!!

此处,我们依然采用合并写请求的方案,并且保留异步处理,做到兼顾**异步写**、**合并写**的优势.但是,合并写请求必须是对中间的N次写操作不敏感!

>**无论用户中间执行点赞、取消、再点赞、再取消多少次，点赞次数发生了多少次变化，业务方只关注最终的点赞结果即可：**
- 用户是否点赞了
- 业务的总点赞次数
因此,点赞功能可以使用合并写方案!业务流程如下:
![[Pasted image 20240921224725.png]]
![[Pasted image 20240921225638.png]]
合并写请求有两个关键点要考虑：
- 数据如何缓存
- 缓存何时写入数据库

#### 5.1.1 点赞数据缓存
使用Redis记录缓存,需要决定: 
1)存储什么信息?
2)使用哪种结构存储;
3)KEY和VALUE是什么?

点赞中最重要的两条信息: **1)用户是否点赞; 2)某业务的点赞总次数**
##### 5.1.1.1 用户是否点赞
记录某个用户是否点赞了某个业务,参考数据库的表字段,可以知道需要 1)业务id; 2)给该业务点赞的所有用户的id. 并且业务可被多用户点赞, 所以需要集合来存储: List,Set,SortedSet,Hash.

而要判断用户是否点赞，就是判**断存在且唯一**。显然，Set集合是最合适的。我们可以用**业务id为Key，创建Set集合，将点赞的所有用户保存其中**，格式如下：
![[Pasted image 20240921230543.png]]

由于**Redis本身具备持久化机制**，**AOF提供的数据可靠性已经能够满足点赞业务的安全需求**，因此我们完全可以用Redis存储来代替数据库的点赞记录。

也就是说，用户的一切点赞行为，以及将来查询点赞状态我们可以都走Redis，**不再使用数据库查询.**

>[!Redis与数据库结合的思路]
>-  先利用Redis来记录点赞状态,并且**定期的**将Redis中的点赞状态持久化到数据库.
> 	 | 使用定时任务实现!(例如SpringTask)
>- 对于历史点赞记录，比如下架的课程、或者超过2年以上的访问量较低的数据都可以从redis移除，只保留在数据库中.
>- 当某个记录点赞时，优先去Redis查询并判断，如果Redis中不存在，再去查询数据库数据并缓存到Redis.

##### 5.1.1.2 点赞次数
对于点赞次数,需要持久化存储到业务方,故仍需使用数据库存储,**Redis只起缓存作用**即可!
点赞次数需要记录以下几个数据:①业务类型,②业务id,③点赞次数.
>(此处业务类型与业务id是区分开的,即对应数据库中的两个字段,感觉变成同一个字段也可以!类似于lesson_id为user_id与course_id)

根据需要存储的数据,可以使用2种结构进行存储:
- Hash:传统键值对集合，无序
- SortedSet：基于Hash结构，并且增加了跳表。因此**可排序**，但更占用内存.

如果是从节省内存角度来考虑，Hash结构无疑是最佳的选择；但是考虑到将来我们要**从Redis读取点赞数，然后移除（避免重复处理）**。为了**保证线程安全，查询、移除操作必须具备原子性**。而==**SortedSet则提供了几个移除并获取的功能，天生具备原子性**==。并且我们每隔一段时间就会将数据从Redis移除，并不会占用太多内存。因此，这里我们计划使用SortedSet结构:
![[Pasted image 20240921232539.png]]

#### 5.1.2 点赞数据入库
点赞数据写入缓存了，但是这里有一个新的问题：
**何时把缓存的点赞数，通过MQ通知到业务方，持久化到业务方的数据库呢？**

>前面的播放记录是每隔15秒发送一次请求,频率固定,故可以采用接收到播放记录后20秒检测数据变更来确定是否有新数据到达.

点赞任务具有随机性,无法判断用户何时点赞,点赞频率如何,故无法采用延迟手段!!!
	**这也是大多数合并写请求业务所面临的问题!**
我们在这采用定时任务,**定时将缓存的数据持久化到数据库**中!

#### 5.1.3 流程图
改造后的流程图如下:
![[Pasted image 20240921232928.png]]

### 5.2 改造点赞逻辑
需要改造的内容包括：
- `tj-remark`中所有点赞有关接口
    - 点赞接口(like,unlike方法)
    - 查询单个点赞状态
    - 批量查询点赞状态
- `tj-remark`处理点赞数据持久化的定时任务
- `tj-learning`监听点赞数变更消息的业务

#### 5.2.1 点赞接口

```java hl:22-23,16,27-31
/**
 * <p>
 * 点赞记录表 服务实现类
 * </p>
 */
@Service
@RequiredArgsConstructor
public class LikedRecordServiceRedisImpl extends ServiceImpl<LikedRecordMapper, LikedRecord> implements ILikedRecordService {

    private final RabbitMqHelper mqHelper;
    private final StringRedisTemplate redisTemplate;

    @Override
    public void addLikeRecord(LikeRecordFormDTO recordDTO) {
        // 1.基于前端的参数，判断是执行点赞还是取消点赞
        boolean success = recordDTO.getLiked() ? like(recordDTO) : unlike(recordDTO);
        // 2.判断是否执行成功，如果失败，则直接结束
        if (!success) {
            return;
        }
        // 3.如果执行成功，统计点赞总数
        Long likedTimes = redisTemplate.opsForSet()
                .size(RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId());
        if (likedTimes == null) {
            return;
        }
        // 4.使用ZSET缓存某业务点赞总数到Redis
        redisTemplate.opsForZSet().add(
                RedisConstants.LIKES_TIMES_KEY_PREFIX + recordDTO.getBizType(),
                recordDTO.getBizId().toString(),
                likedTimes
        );
    }

    private boolean unlike(LikeRecordFormDTO recordDTO) {
        // 1.获取用户id
        Long userId = UserContext.getUser();
        // 2.获取Key
        String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId();
        // 3.执行SREM命令
        Long result = redisTemplate.opsForSet().remove(key, userId.toString());
        return result != null && result > 0;
    }

    private boolean like(LikeRecordFormDTO recordDTO) {
        // 1.获取用户id
        Long userId = UserContext.getUser();
        // 2.获取Key
        String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + recordDTO.getBizId();
        // 3.执行SADD命令
        Long result = redisTemplate.opsForSet().add(key, userId.toString());
        return result != null && result >  0;
    }
}
```

#### 5.2.2 批量查询点赞状态统计
该接口是根据用户id查询对多个业务的点赞状态,而根据前面的点赞表结构(Set),只能使用`SISMEMBER bizId userId`来查询单个业务中该用户是否点赞.
![[Pasted image 20240921234029.png|400]]
所以为了实现该接口功能,一个方法就是多次执行ISMEMBER命令,也就**需要向Redis多次发起网络请求,给网络带宽带来非常大的压力**,影响业务性能。
	并且只有这种办法...!!!

并且,Redis提供了Pipeline功能,可用于在**一次请求中执行多个命令**,减小对网络带宽的压力.
>**不要在一次批处理中传输太多命令，否则单次命令占用带宽过多，会导致网络阻塞**

使用Pipeline功能改造获得的批量查询点赞状态的功能代码如下:
```Java hl:5-10,15-18
@Override
public Set<Long> isBizLiked(List<Long> bizIds) {
    // 1.获取登录用户id
    Long userId = UserContext.getUser();
    // 2.查询点赞状态
    List<Object> objects = redisTemplate.executePipelined((RedisCallback<Object>) connection -> {
        StringRedisConnection src = (StringRedisConnection) connection;
        for (Long bizId : bizIds) {
            String key = RedisConstants.LIKES_BIZ_KEY_PREFIX + bizId;
            src.sIsMember(key, userId.toString());
        }
        return null;
    });
    // 3.返回结果
    return IntStream.range(0, objects.size()) // 创建从0到集合size的流
            .filter(i -> (boolean) objects.get(i)) // 遍历每个元素，保留结果为true的角标i
            .mapToObj(bizIds::get)// 用角标i取bizIds中的对应数据，就是点赞过的id
            .collect(Collectors.toSet());// 收集
}
```

#### 5.2.3 定时任务
需要**定时读取这些点赞总数的变更数据**,通过MQ发送给业务方.
![[Pasted image 20240922001508.png|]]

1. 启动类上添加@EnableScheduling注解,开启定时任务功能!
2. 编写定时任务类`LikedTimesCheckTask`:
	`@Scheduled(fixedDelay = 20000)`:每隔20秒执行一次!
	`@Scheduled(cron = "0/20 * * * * ?)`:也是每隔20秒执行一次!
```Java
@Component
@RequiredArgsConstructor
public class LikedTimesCheckTask {

    private static final List<String> BIZ_TYPES = List.of("QA", "NOTE");
    private static final int MAX_BIZ_SIZE = 30;

    private final ILikedRecordService recordService;

    @Scheduled(fixedDelay = 20000)
    public void checkLikedTimes(){
        for (String bizType : BIZ_TYPES) {
            recordService.readLikedTimesAndSendMessage(bizType, MAX_BIZ_SIZE);
        }
    }
}
```

1. service层中实现具体逻辑:
   - `popMin(KEY,SIZE)`:返回SIZE条分数较小的数据的集合.(集合为VALUE-SCORE)
      - tuple为`<bizeId,likedTimes>集合`,从中获取单个业务id和点赞次数,然后封装到`LikedTimesDTO`中,并添加到集合中!
   - 发送MQ消息: 将多组数据通过MQ一次性发送到业务方.list中存储了maxBizSize个业务id及其点赞次数!
```Java hl:11-17
@Override
public void readLikedTimesAndSendMessage(String bizType, int maxBizSize) {
    // 1.读取并移除Redis中缓存的点赞总数
    String key = RedisConstants.LIKES_TIMES_KEY_PREFIX + bizType;
    Set<ZSetOperations.TypedTuple<String>> tuples = redisTemplate.opsForZSet().popMin(key, maxBizSize);
    if (CollUtils.isEmpty(tuples)) {
        return;
    }
    // 2.数据转换
    List<LikedTimesDTO> list = new ArrayList<>(tuples.size());
    for (ZSetOperations.TypedTuple<String> tuple : tuples) {
        String bizId = tuple.getValue();
        Double likedTimes = tuple.getScore();
        if (bizId == null || likedTimes == null) {
            continue;
        }
        list.add(LikedTimesDTO.of(Long.valueOf(bizId), likedTimes.intValue()));
    }
    // 3.发送MQ消息
    mqHelper.send(
            LIKE_RECORD_EXCHANGE,
            StringUtils.format(LIKED_TIMES_KEY_TEMPLATE, bizType),
            list);
}
```

>注意:这里MQHelper的`send()`方法的参数为泛型,所以既可以传递likedTimesDTO,也可以传递list集合! 前者单次更新一个业务的点赞次数,后者批量更新多个业务![[Pasted image 20240922004406.png]]

#### 5.2.4 监听点赞数变更
对MQ消息队列中的`list<LikedTimesDTO>`中的每个LikedTimesDTO对象,将其封装成`InteractionReply对象`,然后添加到list中,**批量更新**数据库中的`interaction_reply`表.
	执行批量更新,避免利用循环每次执行单条更新语句,这样效率低且对数据库压力大.
```Java hl:16-23
@Slf4j
@Component
@RequiredArgsConstructor
public class LikeTimesChangeListener {

    private final IInteractionReplyService replyService;

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "qa.liked.times.queue", durable = "true"),
            exchange = @Exchange(name = LIKE_RECORD_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = QA_LIKED_TIMES_KEY
    ))
    public void listenReplyLikedTimesChange(List<LikedTimesDTO> likedTimesDTOs){
        log.debug("监听到回答或评论的点赞数变更");

        List<InteractionReply> list = new ArrayList<>(likedTimesDTOs.size());
        for (LikedTimesDTO dto : likedTimesDTOs) {
            InteractionReply r = new InteractionReply();
            r.setId(dto.getBizId());
            r.setLikedTimes(dto.getLikedTimes());
            list.add(r);
        }
        replyService.updateBatchById(list);
    }
}
```

# Day07-积分系统
## 1. 签到功能
### 1.1 思路分析
签到功能组合新的两个要素:**1)谁签到:用户id; 2)什么时候签到的:签到日期**. 再补充一些功能要素: 补签功能,按照年月统计签到.
综上可得ER图:
![[Pasted image 20240922140709.png|450]]
若签到功能使用int(4字节)或者boolean进行存储,则在用户量增大的情况下可能会导致占用存储空间过大! 而签到功能只有两种状态:签到/未签到, 则可使**用BitMap进行存储, 用一行二进制数字来表示该用户一个月的签到记录.**(一个月最多31位,大大节省空间!)
### 1.2 BitMap用法
BitMap数据结构是基于String数据结构实现的.**Redis的String类型底层是SDS**，也会**存在一个字节数组用来保存数据**。而Redis就提供了几个按位操作这个数组中数据的命令，实现了BitMap效果。
#### Redis命令
>注意,偏移量OFFSET均从0开始.(偏移量为0就代表第一位)
- `SETBIT KEY OFFSET VALUE`: 修改某位上的数据. value为1或0.
	- **返回值为该位上原来的值!**
- `BITFIELD KEY GET ENCODING OFFSET`:
	- encoding：返回结果的编码方式，BitMap中是二进制保存，而返回结果会转为10进制，但需要一个转换规则，也就是这里的编码方式
    - u:无符号整数,例如 u2，代表读2个bit位，转为无符号整数返回
    - i:又符号整数,例如 i2，代表读2个bit位，转为有符号整数返回
	- `BITFIELD bm GET u3 0`:假设bm为11100111,则返回结果为7. 即从第1位开始,读取3个二进制数字,转换为无符号整数返回.
		- 若为`BITFIELD bm GET i3 0`,则仍是取111,但此时其补码为除符号位外,原码取反+1,即补码为101,十进制值为-1.
#### RedisTemplate操作BitMap命令:
- `redisTemplate.opsForValue.setBit(KEY,OFFSET,VALUE)`:设置某位的值,返回值为该位原来的值(布尔类型).
- `redisTemplate.opsForValue.bitField(KEY,BitFieldSubCommands subCommands)`
	- 偏移量为0,取前3位,转换为有符号整数. 返回值为list,利用get(0)取第一个就是结果.
```java
redisTemplate.opsForValue.bitField(KEY,
			   BitFieldSubCommands
			   .create()
			   .getCommands(BitFieldSubCommands.BitFieldType.signed(3))
			   .valueAt(0));
```

### 1.3 签到接口
在个人中心的积分页面，用户**每天都可以签到一次**，**连续签到则有积分奖励**，请实现签到接口，**记录用户每天签到信息**，方便做签到统计。

#### 1.3.1 接口设计和分析
签到记录用BitMap进行存储,为**每个用户每个月的签到记录都生成一个KEY**.KEY值需要包含用户id与年月,故为`sign:uid:xxx:202401`,

更新签到记录,需要知道是**哪个用户在什么时间签到(可通过ThreadLocal和LocalDateTime**获得,并且因为连续签到有积分奖励,所以这里需要返回**连续签到天数**以及**今日签到获得的积分值**.
![[Pasted image 20240922220610.png]]

#### 1.3.2 实体
使用VO封装返回参数:
额外多了一个签到得分,因为签到默认获得一分.
```java
@Data
@ApiModel(description = "签到结果")
public class SignResultVO {
    @ApiModelProperty("连续签到天数")
    private Integer signDays;
    @ApiModelProperty("签到得分")
    private Integer signPoints = 1;
    @ApiModelProperty("连续签到奖励积分，连续签到超过7天以上才有奖励")
    private Integer rewardPoints;

    @JsonIgnore
    public int totalPoints(){
        return signPoints + rewardPoints;
    }
}

```

#### 1.3.3 连续签到统计
>从最后一次签到开始,向前统计,直到遇到第一次未签到为止,计算总的签到次数,就是连续签到天数.![[Pasted image 20240922222807.png]]

存在两个问题:
1) 如何获得本月到今天截止的所有签到数据?
	`BITFIELD KEY GET u[dayOfMonth] 0`,实现获取到今天为止的所有位数,并转换为无符号整数返回.
2) ==**如何从后向前遍历每个bit位?**==
	 1. 将当月签到数据**与1做与运算**,即可获得最后一个bit位,即当天的签到记录;
	$$
	\begin{aligned}
	10011\\
	\frac{00001}{00001} \\
	\end{aligned}
	$$
	 2. 将签到数据右移一位,重复执行步骤1,即可获得前一天的签到记录.以此类推..
#### 1.3.4 实现接口
```Java hl:49-66
@Service
@RequiredArgsConstructor
public class SignRecordServiceImpl implements ISignRecordService {

    private final StringRedisTemplate redisTemplate;

    @Override
    public SignResultVO addSignRecords() {
        // 1.签到
        // 1.1.获取登录用户
        Long userId = UserContext.getUser();
        // 1.2.获取日期
        LocalDate now = LocalDate.now();
        // 1.3.拼接key
        String key = RedisConstants.SIGN_RECORD_KEY_PREFIX
                + userId
                + now.format(DateUtils.SIGN_DATE_SUFFIX_FORMATTER);
        // 1.4.计算offset
        int offset = now.getDayOfMonth() - 1;
        // 1.5.保存签到信息
        Boolean exists = redisTemplate.opsForValue().setBit(key, offset, true);
        if (BooleanUtils.isTrue(exists)) {
            throw new BizIllegalException("不允许重复签到！");
        }
        // 2.计算连续签到天数
        int signDays = countSignDays(key, now.getDayOfMonth());
        // 3.计算签到得分
        int rewardPoints = 0;
        switch (signDays) {
            case 7:
                rewardPoints = 10;
                break;
            case 14:
                rewardPoints = 20;
                break;
            case 28:
                rewardPoints = 40;
                break;
        }
        // TODO 4.保存积分明细记录 
        
        // 5.封装返回
        SignResultVO vo = new SignResultVO();
        vo.setSignDays(signDays);
        vo.setRewardPoints(rewardPoints);
        return vo;
    }
							\\ len为截止到当天的天数
    private int countSignDays(String key, int len) {
        // 1.获取本月从第一天开始，到今天为止的所有签到记录
        List<Long> result = redisTemplate.opsForValue()
                .bitField(key, BitFieldSubCommands.create().get(
                        BitFieldSubCommands.BitFieldType.unsigned(len)).valueAt(0));
        if (CollUtils.isEmpty(result)) {
            return 0;
        }
        int num = result.get(0).intValue();
        // 2.定义一个计数器
        int count = 0;
        // 3.循环获取最后一个bit位,直到为0(即未签到)
        while ((num & 1) == 1) {
            // 4.计数器+1
            count++;
            // 5.把数字右移一位，最后一位被舍弃，倒数第二位成了最后一位
	        // >>> 为无符号右移.
			num >>>= 1; // -> num = num >>> 1
        }
        return count;
    }
}
```

## 2. 积分功能
用户签到、学习、参与互动问答、提交学习笔记等行为都可以产生积分，并基于积分形成排行榜。积分当月有效，月底清零。
### 2.1 新增积分
签到,写评价,写问答,写笔记都可以增加积分,所以为了避免耦合,采用异步的方式,将原有业务与业务解耦.

#### 2.1.1 思路分析
异步解耦的方式有很多，比如：
- 利用Spring的`@EventListener`功能:往往在同一个服务内使用
- 利用MQ:往往用在跨服务业务中使用

不同业务都有新增积分的功能,因此可以定义不同的RoutingKey用来传递不同的MQ消息.
![[Pasted image 20240922235610.png]]
**积分记录表结构:**
![[Pasted image 20240923000109.png|450]]

考虑到积分记录需要记录新增积分,所以需要以下参数:
1)用户id;
2)积分值: 通过MQ消息传递;
3)积分类型: 可以根据不同的RoutingKey进行判断 
4)新增积分时间: 即当前时间.
#### 2.1.2 发送MQ消息
改造签到接口,添加"新增积分"功能.
- 签到完成后,使用mqHelper发送mq消息到`tj-learning`(积分记录表在`tj-learning`中)
	- 消息接收方通过交换机`MqConstants.Exchange.LEARNING_EXCHANGE`定义;
	- 消息类型通过`RoutingKey:MqConstants.Key.SIGN_IN`来定义;
	- 消息内容封装为`SignInMessage`.
```java
        // 4.保存积分明细记录
        mqHelper.send(
                MqConstants.Exchange.LEARNING_EXCHANGE,
                MqConstants.Key.SIGN_IN,
                SignInMessage.of(userId, rewardPoints + 1));// 签到积分是基本得分+奖励积分
```

#### 2.1.3 编写消息监听器
```Java 
@Component
@RequiredArgsConstructor
public class LearningPointsListener {

    // 监听签到的新增积分
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "sign.points.queue", durable = "true"),
            exchange = @Exchange(name = MqConstants.Exchange.LEARNING_EXCHANGE, type = ExchangeTypes.TOPIC),
            key = MqConstants.Key.SIGN_IN
    ))
    public void listenSignInMessage(SignInMessage message){
    // 在service中具体实现保存积分记录操作.
        recordService.addPointsRecord(message.getUserId(), message.getPoints(), PointsRecordType.SIGN);
    }
}
```

#### 2.1.4 保存积分记录
因为有些业务具有新增积分上限,所以在新增积分前还得**查询今天的新增积分是否达到上限**!
![[Pasted image 20240923000225.png|300]]

```Java
@Override
public void addPointsRecord(Long userId, int points, PointsRecordType type) {
    LocalDateTime now = LocalDateTime.now();
    int maxPoints = type.getMaxPoints();
    // 1.判断当前方式有没有积分上限
    int realPoints = points;
    if(maxPoints > 0) {
        // 2.有，则需要判断是否超过上限
        LocalDateTime begin = DateUtils.getDayStartTime(now);
        LocalDateTime end = DateUtils.getDayEndTime(now);
        // 2.1.查询今日已得积分
        int currentPoints = queryUserPointsByTypeAndDate(userId, type, begin, end);
        // 2.2.判断是否超过上限
        if(currentPoints >= maxPoints) {
            // 2.3.超过，直接结束
            return;
        }
        // 2.4.没超过，保存积分记录
        if(currentPoints + points > maxPoints){
            realPoints = maxPoints - currentPoints;
        }
    }
    // 3.没有，直接保存积分记录
    PointsRecord p = new PointsRecord();
    p.setPoints(realPoints);
    p.setUserId(userId);
    p.setType(type);
    save(p);
}

private int queryUserPointsByTypeAndDate(
        Long userId, PointsRecordType type, LocalDateTime begin, LocalDateTime end) {
  
        // 1.查询条件  
//        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
//        wrapper.lambda()  
//                .eq(PointsRecord::getUserId, userId)  
//                .eq(type != null, PointsRecord::getType, type)  
//                .between(begin != null && end != null, PointsRecord::getCreateTime, begin, end);  
//        // 2.调用mapper，查询结果  
//        Integer points = getBaseMapper().queryUserPointsByTypeAndDate(wrapper);  
//        // 3.判断并返回  
//        return points == null ? 0 : points;  
        // 1. 构建查询语句  
        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
        wrapper.select("sum(points) as totalPoints");  
        wrapper.eq("user_id", userId)  
                .eq("type", type)  
                .between("create_time",begin,end);  
        // 2. 获得查询结果  
        // sum()的返回值为BigDecimal类型.
        Map<String, Object> map = pointsRecordService.getMap(wrapper);  
  
        // 3. 返回查询结果  
        if (map != null){  
            BigDecimal points = (BigDecimal) map.get("totalPoints");  
            return points.intValue();  
        }  
        // 返回值为-1,代表失败.  
        return -1;
}
```
也可以使用MyBatisPlus中的SQL进行查询,即**调用了service层的getMap()方法,并且构建wrapper条件时带上`wrapper.select()`.** 

具体Mapper层中的查询语句:
因为需要调用sum函数,所以**在Mapper层中自定义SQL语句**
```Java
public interface PointsRecordMapper extends BaseMapper<PointsRecord> {

    @Select("SELECT SUM(points) FROM points_record ${ew.customSqlSegment}")
    Integer queryUserPointsByTypeAndDate(@Param(Constants.WRAPPER) QueryWrapper<PointsRecord> wrapper);
}
```
### 2.2 查询今日积分情况
#### 2.2.1 接口分析
在个人中心，用户可以查看**当天**各种**不同类型**的**已获得的积分**和**积分上限**:
![[Pasted image 20240923080225.png|350]]
所以,查询接口如下:
1) 不同类型: 返回类型参数;
2) 已获得积分: 返回该类型对应已获得的积分;
3) 积分上限: 根据类型返回该类型的积分上限.
因为有多种类型,所以返回值应该为`List<PointsStatisticsVO>`,内部包含多个Json字符串.
![[Pasted image 20240923080430.png]]
#### 2.2.2 实现接口
SQL语句如下: 按照类型分组.
```SQL
SELECT type,SUM(points)
FROM points_record
WHERE user_id = ? 
AND create_time 
BETWEEN 'begin' AND end 
GROUP BY type;
```

```Java
    @Override  
    public List<PointsStatisticsVO> queryMyPointsToday() {  
//        1. 用户id  
        Long userId = UserContext.getUser();  
//        2. 构建查询语句: 签到,课程学习,课程评论...  
        LocalDateTime now = LocalDateTime.now();  
        LocalDateTime begin = DateUtils.getDayStartTime(now);  
        LocalDateTime end = DateUtils.getDayEndTime(now) ;  
  
        QueryWrapper<PointsRecord> wrapper = new QueryWrapper<>();  
//        利用PointsRecord中的points属性暂存"当日已获得积分"  
        wrapper.select("type,sum(points) as points");  
        wrapper.eq("user_id", userId);  
        wrapper.between("create_time",begin,end);  
        wrapper.groupBy("type");  
        List<PointsRecord> list = pointsRecordService.list(wrapper);  
        if (CollUtils.isEmpty(list)){  
            return CollUtils.emptyList();  
        }  
//        3. 封装结果并返回  
        List<PointsStatisticsVO> res = new ArrayList<>();  
        for (PointsRecord r : list){  
            PointsStatisticsVO vo = new PointsStatisticsVO();  
            vo.setMaxPoints(r.getType().getMaxPoints());  
            vo.setPoints(r.getPoints());  
            vo.setType(r.getType().getDesc()); //getDesc()获取枚举类的String类型  
            res.add(vo);  
        }  
        return res;  
    }
```

# Day08-排行榜系统
 
## 1. 实时排行榜 
### 1.1 思路分析
计算每个用户获得的总积分,可以通过查询积分记录表,对用户进行分组,然后累加已获得积) 分,对应SQL语句为:
`SELECT user_id, sum(points) FROM points_record GROUP BY user_id ORDER BY SUM(points);`

但是这样调用SQL语句进行查询,会对数据库造成很大压力,不太靠谱,因此使用Redis实现.
要**存储赛季**,**用户id**以及**用户对应的积分**三项数据,可以采用SortedSet来实现!
![[Pasted image 20240923220336.png|400]]

### 1.2 生成实时榜单
在原有的新增积分记录的流程上添加"累加积分到Redis"的流程. SortedSet可以实现对Score进行累加(`ZINCRBY key increment member`),而不是替换!
![[Pasted image 20240923220531.png|300]]

#### 1.2.1 更新积分到Redis
- KEY前缀为:`boards:yyyyMM`,对应某一个赛季.
- `incrementScore(key,member,value)`:代表对KEY下的member累加value.
```Java
        // 4.更新总积分到Redis
        String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + now.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);
        redisTemplate.opsForZSet().incrementScore(key, userId.toString(), realPoints);
```

### 1.3 查询积分榜
### 1.3.1 分析和设计接口
在个人中心，学生可以查看**指定赛季积分排行榜(只显示前100)**,还可以查看**自己总积分和排名**。而且**排行榜分为本赛季榜单和历史赛季榜单**. 本赛季排行榜存在于Redis中,而历史赛季排行榜存在于MySQL数据库中.
	本赛季和历史赛季榜单可以视为同一个接口,无非就是传入的赛季id不同!
![[Pasted image 20240923222108.png]]

首先我们分析一下**请求参数**:
- 榜单数据非常多，不可能一次性查询出来，因此这里一定是**分页查询**（滚动分页），需要分页参数。
- 由于要**查询历史榜单需要知道赛季**，因此参数中需要指定赛季id。当赛季id为空，我们认定是查询当前赛季。这样就可以把两个接口合二为一。

然后是返回值，无论是历史榜单还是当前榜单，结构都一样。分为两部分:
- 当前用户的积分和排名。**当前用户不一定上榜，因此需要单独查询**
- 榜单数据。就是**N个用户的积分、排名形成的集合**。

**接口如下:**
![[Pasted image 20240923222506.png]]

#### 1.3.2 实现接口
##### Controller层
- 传入查询条件,分页查询;
- 根据返回参数,使用PointsBoardVO进行封装.
	```Java
	@Data  
	@ApiModel(description = "积分榜单汇总信息")  
		public class PointsBoardVO {  
			@ApiModelProperty("我的榜单排名")  
			private Integer rank;  
			@ApiModelProperty("我的积分值")  
			private Integer points;  
			@ApiModelProperty("前100名上榜人信息")  
			private List<PointsBoardItemVO> boardList;  
		}
	```

```Java
@GetMapping
@ApiOperation("分页查询指定赛季的积分排行榜")
public PointsBoardVO queryPointsBoardBySeason(PointsBoardQuery query){
	return pointsBoardService.queryPointsBoardBySeason(query);
}
```

##### Service层:
- 因为当前赛季的积分排行榜存储在Redis中,而历史赛季存储在MySQL中,所以**根据赛季不同,对应的查询方法也不同**.
- 
```Java hl:9-16,32
@Override  
public PointsBoardVO queryPointsBoardBySeason(PointsBoardQuery query) {  
    // 1.判断是否是查询当前赛季  
    Long season = query.getSeason();  
    boolean isCurrent = season == null || season == 0;  
    // 2.获取Redis的Key  
    LocalDateTime now = LocalDateTime.now();  
    String key = RedisConstants.POINTS_BOARD_KEY_PREFIX + now.format(DateUtils.POINTS_BOARD_SUFFIX_FORMATTER);  
    // 2.查询我的积分和排名  
    PointsBoard myBoard = isCurrent ?  
            queryMyCurrentBoard(key) : // 查询当前榜单（Redis）  
            queryMyHistoryBoard(season); // 查询历史榜单（MySQL）  
    // 3.查询榜单列表  
    List<PointsBoard> list = isCurrent ?  
            queryCurrentBoardList(key, query.getPageNo(), query.getPageSize()) :   
            queryHistoryBoardList(query);  
    // 4.封装VO  
    PointsBoardVO vo = new PointsBoardVO();  
    // 4.1.处理我的信息  
    if (myBoard != null) {  
        vo.setPoints(myBoard.getPoints());  
        vo.setRank(myBoard.getRank());  
    }  
    if (CollUtils.isEmpty(list)) {  
        return vo;  
    }  
    // 4.2.查询用户信息: 1. 获取id表; 2.根据id查询name
    Set<Long> uIds = list.stream().map(PointsBoard::getUserId).collect(Collectors.toSet());  
    List<UserDTO> users = userClient.queryUserByIds(uIds);  
    Map<Long, String> userMap = new HashMap<>(uIds.size());  
    if(CollUtils.isNotEmpty(users)) {  
        userMap = users.stream().collect(Collectors.toMap(UserDTO::getId, UserDTO::getName)); // 返回map,其中key为userId,value为userName 
    }  
    // 4.3.转换VO,用于返回赛季记录.
    List<PointsBoardItemVO> items = new ArrayList<>(list.size());  
    for (PointsBoard p : list) {  
        PointsBoardItemVO v = new PointsBoardItemVO();  
        v.setPoints(p.getPoints());  
        v.setRank(p.getRank());  
        v.setName(userMap.get(p.getUserId()));  
        items.add(v);  
    }  
    vo.setBoardList(items);  
    return vo;  
}
```

- `ZREVRANK key member`:查询key中成员member的排名(由大到小,从0开始);
- `ZSCORE key member`:查询key中成员member的分数.
- `ZREVRANGE key start stop`:查询第start到第stop条数据,起始索引为0.
	- 返回结果为`Set<ZSetOperations.TypedTuple<String>>`.每一个tuple中对应一个`member-score`;
- 通过`rank++`实现对用户排名,因为ZREVRANGE查询本身就是已排序的.
```Java hl:10-23
    public List<PointsBoard> queryCurrentBoardList(String key, Integer pageNo, Integer pageSize) {
        // 1.计算分页
        int from = (pageNo - 1) * pageSize;
        // 2.分页查询: 利用from计算每次查询的起始索引.
        Set<ZSetOperations.TypedTuple<String>> tuples = redisTemplate.opsForZSet()
                .reverseRangeWithScores(key, from, from + pageSize - 1);
        if (CollUtils.isEmpty(tuples)) {
            return CollUtils.emptyList();
        }
        // 3.封装
        int rank = from + 1;
        List<PointsBoard> list = new ArrayList<>(tuples.size());
        for (ZSetOperations.TypedTuple<String> tuple : tuples) {
            String userId = tuple.getValue(); // 获取member
            Double points = tuple.getScore(); // 获取score
            if (userId == null || points == null) {
                continue;
            }
            PointsBoard p = new PointsBoard();
            p.setUserId(Long.valueOf(userId));
            p.setPoints(points.intValue());
            p.setRank(rank++);
            list.add(p);
        }
        return list;
    }
    
// 需要查询当前用户的排名以及积分.
    private PointsBoard queryMyCurrentBoard(String key) {
        // 1.绑定key
        BoundZSetOperations<String, String> ops = redisTemplate.boundZSetOps(key);
        // 2.获取当前用户信息
        String userId = UserContext.getUser().toString();
        // 3.查询积分
        Double points = ops.score(userId);
        // 4.查询排名
        Long rank = ops.reverseRank(userId);
        // 5.封装返回(健壮性保证!)
        PointsBoard p = new PointsBoard();
        p.setPoints(points == null ? 0 : points.intValue());
        p.setRank(rank == null ? 0 : rank.intValue() + 1);
        return p;
    }
}
```

## 2. 历史排行榜
### 2.1 海量数据存储策略
![[Pasted image 20240924084505.png]]

#### 2.1.1 分区
##### 介绍:
**表分区（Partition)** 是一种数据存储方案，可以解决单表数据较多的问题。MySQL5.1开始支持表分区功能。

简单来说，就是按照某种规则，**把表数据对应的ibd文件拆分成多个文件来存储**。从物理上来看，一张表的数据被拆到多个表文件存储了；从逻辑上来看，他们对外表现是一张表。

表分区的本质是对数据的**水平拆分**，而拆分的方式也有多种，常见的有：
- **Range分区:**按照指定字段的取值范围分区
- List分区：按照指定字段的枚举值分区，必须**提前指定好所有的分区值**，如果数据找不到分区会报错;
- Hash分区：基于字段做hash运算后分区，一般做hash运算的字段都是数值类型
- Key分区：根据指定字段的值做运算的结果分区，与hash分区类似，但不限定字段类型

对表进行分区拆分,例如list拆分,需要在**一开始就列举除所有的分区值**,所以对于赛季榜单这种会持续更新的表可能不太适用!
##### **优缺点分析:**
**优点:**
1. 可以让**单表存储更多的数据**。
2. 分区表的数据更容易维护，可以通**过清除整个分区来批量删除大量数据**，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作。
3. 部分查询能够从查询条件确定**只落在少数分区**上，速度会很快（查询条件尽量扫描少的分区）。
4. 分区表的数据还可以**分布在不同的物理设备**上，从而高效利用多个硬件设备。
5. 可以**使用分区表来避免某些特殊瓶颈**，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争。
6. 可以备份和恢复单个分区。

**分区的限制和缺点**：
- 在mysql5.6.7之前的版本，一个表最多有1024个分区；从5.6.7开始，一个表最多可以有8192个分区。
- MYSQL的**分区字段，必须包含在主键字段内**。如果一个表有主键，那么分区字段必须包含在主键内，也就是分区字段必须是主键的一部分或者全部，不能以非主键的字段作为分区字段。当然，也可以为没有主键的表建立分区。
- 分区表无法使用外键约束。
- NULL值会使分区过滤无效。
- 所有分区必须使用相同的存储引擎。

#### 2.1.2 分表
##### 介绍:
**分表**是一种表设计方案，由开发者在创建表时按照自己的业务需求拆分表。也就是说这是开发者自己对表的处理，与数据库无关。分表从逻辑上和物理上都是一张表,所以在处理数据时需要考虑到哪张表进行处理!
##### 优缺点:
**优点:**
- 拆分方式更加灵活
- 而且可以**解决单表字段过多**的问题
**缺点:**
- 增删改查时，**需要自己判断访问哪张表**
- 垂直拆分还会导致**事务问题及数据关联问题**:原本一张表的操作，变为多张表操作。

#### 2.1.3 分库和集群
无论是分区，还是分表，我们刚才的分析都是**建立在单个数据库的基础**上。但是单个数据库也存在一些问题：
- 单点故障问题：数据库发生故障，整个系统就会瘫痪
- 单库的性能瓶颈问题：单库受服务器限制，其网络带宽、CPU、连接数都有瓶颈
- 单库的存储瓶颈问题：单库的磁盘空间有上限，如果磁盘过大，数据检索的速度又会变慢

综上，在大型系统中，我们除了要做分表、还需要**对数据做分库，建立综合集群。**

首先，在微服务项目中，我们会按照项目模块，**每个微服务使用独立的数据库**，**因此每个库的表是不同的**，这种分库模式成为**垂直分库**。

而为了保证**单节点的高可用性**，我们会给数据库建立**主从集群**，主节点向从节点同步数据。两者结构一样，可以看做是**水平扩展**。主节点宕机时,从节点可以充当主节点,保证了稳定性.
![[Pasted image 20240925134851.png]]

##### 优缺点:
**优点:**
- 解决了海量数据存储问题，突破了单机存储瓶颈
- 提高了并发能力，突破了单机性能瓶颈
- 避免了单点故障

**缺点:**
- 成本非常高
- 数据聚合统计比较麻烦
- 主从同步的一致性问题
- 分布式事务问题

#### **2.1.4 总结
![[Pasted image 20240924003713.png|400]]

### 2.2 历史榜单
综合考虑:1)用户数据规模不会太高; 2)解决单表数据量过大问题.所以无需采用分库和集群,这样会造成不必要的麻烦. 并且使用list分区需要在分区时列举出所有可能的赛季,而赛季是持续更新的,所以不太现实. 故**采用水平分表方案**.

将历史榜单根据赛季拆分,单个赛季对应一个独立的表. 故可以简化表字段,将赛季id略去用不同表进行区分;将id作为排名,故可以省略排名字段.
![[Pasted image 20240925135323.png]]
### 2.3 定时任务生成榜单表
积分榜先存于Redis,需要定时任务将其持久化于MySQL数据库中,所以在这里创建定时任务,通过SpringTask定时任务来生成历史榜单.

#### 2.3.1 定时任务
- 定义定时任务类,`@Scheduled(cron='')`注解用于执行定时任务.
- 调用service层执行具体业务逻辑: 创建历史赛季榜单表.
```Java
@Component
@RequiredArgsConstructor
public class PointsBoardPersistentHandler {

    private final IPointsBoardSeasonService seasonService;

    private final IPointsBoardService pointsBoardService;

    @Scheduled(cron = "0 0 3 1 * ?") // 每月1号，凌晨3点执行
    public void createPointsBoardTableOfLastSeason(){
        // 1.获取上月时间
        LocalDateTime time = LocalDateTime.now().minusMonths(1);
        // 2.查询赛季id
        Integer season = seasonService.querySeasonByTime(time);
        if (season == null) {
            // 赛季不存在
            return;
        }
        // 3.创建表
        pointsBoardService.createPointsBoardTableBySeason(season);
    }
}
```


### 2.4 分布式任务调度
SpringTask存在一些问题：
- 当微服务**多实例部署时，定时任务会被执行多**次。而事实上我们只需要这个任务被执行一次即可。**(SpringTask作为单机任务,不适用于分布式任务)**
- 我们除了要定时创建表，还要定时持久化Redis数据到数据库，我们希望这多个定时任务能够按照顺序依次执行，**SpringTask无法控制任务顺序**

不仅仅是SpringTask，其它**单机使用的定时任务工具，都无法实现像这种任务执行者的调度、任务执行顺序的编排、任务监控**等功能。这些功能必须要用到**分布式任务调度组件**。

#### 2.4.1 分布式任务调度原理
定时任务需要两个组件:1)任务(待执行的代码); 2)**任务触发器:基于定义好的规则触发任务**. 因此在多实例部署时, 每个实例都有任务触发器,可能会导致任务多次执行! 

因此,需要把任务触发器提取到各个实例之外,做统一触发,调度.
**任务的执行交由任务调度服务控制统一处理**,并且执行结果还可通过回调接口返回给各个实例,方便查看执行状态,任务等.
![[Pasted image 20240925142056.png]]

### 2.4.3 XXL-JOB介绍
XXL-JOB的运行原理与架构:
![[Pasted image 20240925142217.png]]

XXL-JOB分为两部分：
- **执行器:** 通过配置创建一个执行器,**负责与XXL-JOB调度中心交互，执行本地任务**。
- **调度中心:** 一个独立服务，负责**管理执行器、管理任务、任务执行的调度、任务结果和日志收集。**

### 2.4.4 XXL-JOB定时创建榜单表
#### 2.4.4.1 部署调度中心
**自定义部署调度中心:**
1. 执行官方SQL语句`XXL-JOB.sql`,创建数据库表;
2. 配置`application.properties`,配置端口,数据库地址,数据库账户密码;
3. 部署启动!
![[Pasted image 20240925143328.png]]

#### 2.4.4.2 微服务集成执行器
1. 引入XXL-JOB依赖;
2. ==**配置执行器:**==
	- adminAddress：调度中心地址，天机学堂中就是填虚拟机地址
	- appname：微服务名称
	- ip和port：当前执行器的ip和端口，无需配置，自动获取
	- accessToken：访问令牌，在调度中心中配置令牌，所有执行器访问时都必须携带该令牌，否则无法访问。
	- logPath：任务运行日志的保存目录
	- logRetentionDays：日志最长保留时长
```Java
@Configuration
@ConditionalOnClass(XxlJobSpringExecutor.class)
@EnableConfigurationProperties(XxlJobProperties.class)
public class XxlJobConfig {

    @Bean
    public XxlJobSpringExecutor xxlJobExecutor(XxlJobProperties prop) {
        log.info(">>>>>>>>>>> xxl-job config init.");
        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();
        XxlJobProperties.Admin admin = prop.getAdmin();
        if (admin != null && StringUtils.isNotEmpty(admin.getAddress())) {
            xxlJobSpringExecutor.setAdminAddresses(admin.getAddress());
        }
        XxlJobProperties.Executor executor = prop.getExecutor();
        if (executor != null) {
            if (executor.getAppName() != null)
                xxlJobSpringExecutor.setAppname(executor.getAppName());
            if (executor.getIp() != null)
                xxlJobSpringExecutor.setIp(executor.getIp());
            if (executor.getPort() != null)
                xxlJobSpringExecutor.setPort(executor.getPort());
            if (executor.getLogPath() != null)
                xxlJobSpringExecutor.setLogPath(executor.getLogPath());
            if (executor.getLogRetentionDays() != null)
                xxlJobSpringExecutor.setLogRetentionDays(executor.getLogRetentionDays());
        }
        if (prop.getAccessToken() != null)
            xxlJobSpringExecutor.setAccessToken(prop.getAccessToken());
        log.info(">>>>>>>>>>> xxl-job config end.");
        return xxlJobSpringExecutor;
    }
}
```
3. 配置执行器属性:
	**1)创建配置类:`XxlJob.properties`;**
```Java
@Data
@ConfigurationProperties(prefix = "tj.xxl-job")
public class XxlJobProperties {

    private String accessToken;
    private Admin admin;
    private Executor executor;

    @Data
    public static class Admin {
        private String address;
    }

    @Data
    public static class Executor {
        private String appName;
        private String address;
        private String ip;
        private Integer port;
        private String logPath;
        private Integer logRetentionDays;

    }
}
```

**2)nacos中配置了Shared-xxljob.yaml,会读取其中配置.**
```Java
tj:
  xxl-job:
    access-token: tianji
    admin:
      address: http://192.168.150.101:8880/xxl-job-admin
    executor:
    // 从bootstrap.yaml启动类配置文件中读取
      appname: ${spring.application.name} 
      log-retention-days: 10
      logPath: job/${spring.application.name}
```

#### 2.4.4.3 定义任务
同样还是Handler,将其中的`@Scheduled()`的SpringTask定时任务类用`@XXLJob(任务名称)`替代
![[Pasted image 20240925150017.png]]

#### 2.4.4.4 注册执行器
登录XXL-Job控制台,注册执行器,注意AppName与微服务名称保持相同.![[Pasted image 20240925152150.png|450]]

#### 2.4.4.5 配置任务调度
配置任务调度:1)分配任务何时执行; 2)任务由哪个执行器执行.
	- JobHandler
![[Pasted image 20240925152302.png]]


# 面试题:
## 学习计划和进度系统
### 你在开发中参与了哪些功能开发让你觉得比较有挑战性？
我参与了整个学习中心的功能开发，其中有很多的学习辅助功能都很有特色。比如视频播放的进度记录。我们网站的课程是以录播视频为主，为了提高用户的学习体验，需要实现**视频续播**功能。这个功能本身并不复杂，只不过我们产品提出的要求比较高：
- 首先续播**时间误差要控制在30秒以内**。
- 而且要做到用户突然断开，甚至切换设备后，都可以继续上一次播放
要达成这个目的，使用传统的手段显然是不行的。
首先，要做到切换设备后还能续播，用户的播放进度必须保存在服务端，而不是客户端。
其次，用户突然断开或者切换设备，续播的时间误差不能超过30秒，那播放进度的记录频率就需要比较高。我们会在**前端每隔15秒就发起一次心跳请求,提交最新的播放进度，记录到服务端**。这样用户下一次续播时直接读取服务端的播放进度，就可以将时间误差控制在15秒左右。

注：此时面试官会追问：播放进度写到服务端保存在哪里？如果写在数据库，那写数据库的压力是不是太大了？等一系列问题，这个会在下一节内容中讲解。

## 点赞系统:
###  能不能讲讲你们的点赞系统是如何设计的？

首先在设计之初我们分析了一下点赞业务可能需要的一些要求。

例如，在我们项目中需要用到点赞的业务不止一个，因此**点赞系统必须具备通用性，独立性，不能跟具体业务耦合。**

再比如，点赞业务可能会有较高的并发，我们要考虑到高并发写库的压力问题。

所以呢，我们在设计的时候，就**将点赞功能抽离出来作为独立服务**。当然这个服务中除了点赞功能以外，还有<u>与之关联的评价功能，不过这部分我就没有参与</u>了。**在数据层面也会用业务类型对不同点赞数据做隔离**。

从具体实现上来说，为了减少数据库压力，我们**会利用Redis来保存点赞记录、点赞数量信息**。然后**利用定时任务定期的将点赞数量同步给业务方，持久化到数据库中**。

### 那你们Redis中具体使用了哪种数据结构呢？

我们使用了两种数据结构，set和zset

首先保存点赞记录，使用了set结构，key是业务类型+业务id，值是点赞过的用户id。当用户点赞时就`SADD`用户id进去，当用户取消点赞时就`SREM`删除用户id。当判断是否点赞时使用`SISMEMBER`即可。当要统计点赞数量时，只需要`SCARD`就行，**而Redis的SET结构会在头信息中保存元素数量，因此SCARD直接读取该值，时间复杂度为O(1)，性能非常好。**

### 为什么不用用户id为key，业务id为值呢?如果用户量很大，可能出现BigKey?

您说的这个方案也是可以的，不过呢，考虑到我们的**项目数据量并不会很大，我们不会有大V**，因此点赞数量通常不会超过1000，因此不会出现BigKey。并且，由于我们采用了业务id为KEY，当我们要统计点赞数量时，可以直接使用SCARD来获取元素数量，无需额外保存，这是一个很大的优势。但如果是考虑到有大V的场景，有两种选择，一种还是应该选择您说的这种方案，另一种则是**对用户id做hash分片，将大V的key拆分到多个KEY中，结构为 `[bizType:bizId:userId高8位]`.**

不过这里存在一个问题，就是页面需要判断当前用户有没有对某些业务点赞。这个时候会传来多个业务id的集合，而SISMEMBER只能一次判断一个业务的点赞状态，要判断多个业务的点赞状态，就必须多次调用SISMEMBER命令，与Redis多次交互，这显然是不合适的。（此处略停顿，等待面试官追问，面试官可能会问“那你们怎么解决的”。如果没追问，自己接着说），所以呢我们就**采用了Pipeline管道方式，这样就可以一次请求实现多个业务点赞状态的判断了**。

### 那你ZSET干什么用的？

严格来说ZSET并不是用来实现点赞业务的，因为点赞只靠SET就能实现了。但是这里有一个问题，我们要**定期将业务方的点赞总数通过MQ同步给业务方，并持久化到数据库**。但是如果只有SET，我没办法知道哪些业务的点赞数发生了变化，需要同步到业务方。

因此，我们又添加了一个ZSET结构，用来记录点赞数变化的业务及对应的点赞总数。可以理解为一个待持久化的点赞任务队列。

每当业务被点赞，除了要缓存点赞记录，还要把业务id及点赞总数写入ZSET。这样定时任务开启时，只需要从ZSET中获取并移除数据，然后发送MQ给业务方，并持久化到数据库即可。

### 那为什么一定要用ZSET结构，把更新过的业务扔到一个List中不行吗？

扔到List结构中虽然也能实现，但是存在一些问题：

首先，假设定时任务每隔2分钟执行一次，一个业务如果在2分钟内多次被点赞，那就会多次向List中添加同一个业务及对应的点赞总数，数据库也要持久化多次。这显然是多余的，因为只有最后一次才是有效的。而**使用ZSET则因为member的唯一性，多次添加会覆盖旧的点赞数量，最终也只会持久化一次**。

>（面试官可能说：“那就改为SET结构，SET中只放业务id，业务方收到MQ通知后再次查询不就行了。”如果没问就自己往下说）

当然要解决这个问题，也可以用SET结构代替List，然后当业务被点赞时，只存业务id到SET并通知业务方。<u>业务方接收到MQ通知后，根据id再次查询点赞总数从而避免多次更新的问题</u>。但是这种做法会导致多次网络通信，增加系统网络负担。而**ZSET则可以同时保存业务id及最新点赞数量，避免多次网络查询**。

不过，并不是说ZSET方案就是完全没问题的，**毕竟ZSET底层是哈希结构+跳表**，**对内存会有额外的占用**。但是考虑到我们的定时任务每次会查询并删除ZSET数据，ZSET中的数据量始终会维持在一个较低级别，内存占用也是可以接受的。

## 积分系统:

### 1. 你项目中使用过Redis的那些数据结构啊？

**答:** 很多，比如String、Hash、Set、SortedSet、BitMap等

### 2. 能不能具体说说使用的场景?
**答:** 
比如很多的缓存，我们就使用了String结构来存储。还有点赞功能，我们用了Set结构和SortedSet结构。签到功能，我们用了BitMap结构。

就拿签到来说吧。因为签到数据量非常大嘛，而BitMap则是用bit位来表示签到数据，31bit位就能表示1个月的签到记录，非常节省空间，而且查询效率也比较高。

### 3. 你使用Redis保存签到记录，那如果Redis宕机怎么办?
**答:**
对于Redis的高可用数据安全问题，有很多种方案。

比如：我们可以给Redis添加**数据持久化机制,比如使用AOF持久化**。这样宕机后也丢失的数据量不多，可以接受。

或者呢，我们可以搭建**Redis主从集群,结合Redis哨兵**。主节点会把数据持续的同步给从节点，宕机后也会有哨兵重新选主，基本不用担心数据丢失问题。

当然，如果对于数据的安全性要求非常高。肯定还是要用传统数据库来实现的。但是为了解决签到数据量较大的问题，我们可能就需要**对数据做分表处理**了,或者及时将历史数据存档。

总的来说，签到数据使用Redis的BitMap无论是安全性还是数据内存占用情况，都是可以接受的。但是具体是选择Redis还是数据库方案，最终还是要看公司的要求来选择。