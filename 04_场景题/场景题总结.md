## 1. 不用redis分布式锁， 如何防止用户重复点击？
防重复提交，往往都是前后端结合进行。
#### 前端
前端按钮点击一次后，在一定时间内置灰，用户无法再次点击。

缺点：
- 用户可能通过某种手段绕过前端，直接调用后端接口，此时前端置灰会失效。
#### 后端
基本思路：**利用某个集中式存储服务将用户的某个唯一标识存储起来**，并在下次访问时通过查询是否存在该标识来判断是否为重复提交。
##### 方案一：利用token机制
用户访问某个页面后，返回一个token给前端，下次请求时会继续携带该token。此时会对该token进行校验，判断是否被使用过。token的存储、校验可以放在数据库。
##### 方案二：滑动窗口限流
利用滑动窗口限流。当用户访问时，例如以用户的手机号作为KEY，保存用户访问次数。下次访问时，`tryAcquire()`判断用户是否超过一定时间内的访问次数限制，若超过则拒绝请求。=
##### 方案三：布隆过滤器
用户访问后，将用户某个唯一标识计算哈希后存储在布隆过滤器中，下次用户访问后，可以快速判断是否已访问过：
- 布隆过滤器判定为"已存在"，则可能有误判率，不一定真的请求过，因此还需要去数据库（或Redis）中兜底一次；
- 布隆过滤器判定为"不存在"，则一定不存在，则直接放行。
因此，原有的逻辑为都需要进入数据库进行判断；而现在只有判定为"存在"的才需要进入数据库进行判断！
##### 方案四：基于表单信息校验【参考Ruoyi框架】
基于表单信息校验，

## 2. 订单到期关闭如何实现？
#### 定时任务轮询扫描关闭★
**方案描述：**
- 利用定时任务工具（SpringTask、Quartz、XXL-JOB）每隔一段时间就扫描订单表，将超时订单关闭。

**优点：**
- 实现简单。对时间精确度要求不高的情况下适合使用。

**缺点：**
- **时效性差**：若间隔时间过长，则可能导致查询订单超时未能及时关闭；若间隔时间过短，则会导致订单表查询压力大。
- **无法处理大订单量**。若订单量较大，则会导致任务执行时间过长，关闭时间变晚！
- **对数据库压力大**。定时任务扫表，会使得数据库IO在短时间内被大量占用，可能影响线上的正常业务。
- **分库分表问题**。若订单分库分表，则定时任务会全表扫描。

#### 基于Redisson延时队列
- 将订单与过期时间放到ZSet中，启动延时任务。线程不断从Redisson的延时队列中取出数据，进行订单关闭。
#### 基于延时队列DelayQueue
- 利用JDK自带的DelayQueue放置订单，并创建一个线程不断从队列中取出需要关单的订单。

**优点：**
1. 实现简单，适合单机、数据量不大的场景。

**缺点：**
- 基于JVM内存，可能会导致OOM问题；
- 无法持久化，；
- 集群部署时多个DelayQueue的配合问题很大。

#### 基于Netty时间轮
在DelayQueue的基础上，实现O(1)时间复杂度的插入和删除操作。

优缺点同DelayQueue。
#### 基于Kafka的时间轮

#### 基于MQ延迟消息
- MQ不可靠。
- 消息堆积问题。

## 3. 设计一个订单号生成服务。
考虑以下问题：
- **唯一性**。订单唯一，可以考虑UUID、SnowFlake、雪花算法等；
- **数据量**大。预留足够多的位数，避免出现用尽的情况。
- **可读性**。易于理解和记忆，分段构造订单号格式。
- **安全性**。不能被预测，
- **基因法**。为了后续的分库分表，提前考虑分表字段。
- **可扩展性**。使用分布式ID生成，支持分布式部署和横向扩展。
- **高性能**。具备高性能、低延迟的特点，可以使用**内存缓存、异步处理**来优化性能
- **高可用**。多节点部署、负载均衡等技术来提高系统稳定性。

#### 可行的技术方案：【参考Hollis】
包含三部分：系统标识码（业务类型）、唯一ID、分表ID。
- **业务码**：2位，用于区分不同的业务类型。
- **唯一ID**：19位利用雪花算法保证订单ID唯一性。
- **分表ID**：4位，用于实现分表后的订单查询。【根据分表策略获得】

## 4. 设计一个购物车系统。
#### **需求分析：
- 用户未登录时，可以加购，并且关闭浏览器后，商品无需保存；
- 用户未登录时，可以加购，并且登录后，加购商品需要保存到登录后用户的购物车内。
#### 功能设计
##### 暂存购物车
- 资源在客户端做临时缓存，可以1）节约服务器资源；2）无需考虑购物车标识。
- 不同存储方式的选择：
	- Session：保存时间短，并且资源实质上仍存储在服务端；
	- Cookie：
		- 客户端和服务端的每次交互，都会自动携带Cookie，所以可以方便服务端读写Cookie中的数据；
		- 容量上限为4KB，不适用于面向批发的电商场景；
	- LocalStorage：只能由客户端访问。
		- 容量更大；
		- 无需每次请求都携带Cookie，节省带宽资源。
- 临时缓存中保存的JSON数据格式：商品ID、时间戳、数量、是否选择。
	- ![[Pasted image 20241227000517.png|300]]
#### 表设计
用户购物车需要持久化，并且做到多端同步，因此使用MySQL进行存储，表设计如下：
![[Pasted image 20241227000645.png|450]]

若使用Redis存储，则可使用HASH结构，将USER_ID提取出来做KEY，其余字段转换为JSON字符串作为VALUE。

推荐使用MySQL进行存储：
1. 支持丰富的查询方式与事务机制！
## 5. 如何实现朋友圈点赞功能？
#### 需求分析
- 支持点赞、取消点赞、查看点赞数量；
- （用户可以查看我的点赞；）
- 查看某条朋友圈点赞时，头像是按点赞顺序排列的。

#### 存储设计
使用ZSet存储，KEY为朋友圈ID，VALUE为点赞的用户ID，SCORE为时间戳。
#### 接口设计
- 点赞：ZADD
- 取消点赞：ZREM
- 查看点赞列表：ZRANGEBYSCORE

## 6. 如何实现排行榜功能？
#### 需求分析
- 实现按照分数排序，分数相同则按照时间排序。

#### 存储设计
使用ZSet存储：
- KEY为业务ID，VALUE为用户ID；
- SCORE采用整数+小数的形式，整数为得分，小数为时间戳。由于需要遵循时间早的排名优先，因此将小数部分采用：`1-时间戳除以位数`。

#### 接口设计：
- **排名**：ZRANGEBYSCORE；
- **查看用户的分数**：SCORE；
- **查看用户排名**：ZRANK。
## 7. 如何实现百万级排行榜功能？
基于ZSet实现排行榜功能可行，但是若数据量过大，则会导致大Key问题【单个Key的数据条数超过10000个】。

1. **数据分片与分区**。将大Key进行拆分，例如实现全国排行榜功能，则可以通过将大Key划分为不同省份，对不同省份作排名，并在需要时查询再排序。
2. **持久化数据**。定期备份排行榜数据到数据库，或者结合Redis的持久化机制，防止Redis宕机导致数据丢失。
3. **Redis集群部署**。提高
## 8. 如何实现查找附近的人功能？
#### 需求分析
- 实现获取以当前用户为中心的附近的人的信息。
#### 存储设计
使用Redis的Geospatial数据类型：
- KEY为USER_LOCATION；
- VALUE为USER_ID；
- SCORE为经纬度信息。
#### 接口设计
- 存储用户位置：`GEOADD key longitude latitude member`
	- 需要考虑动态更新，例如距离变化超过100m再写入Redis。
- 查找附近的人：使用 `GEORADIUS` 按给定半径查询指定范围内的用户。
	- `GEORADIUS locations 116.4074 39.9042 100 km`：查询以`(116.4074, 39.9042)`为圆心，100km半径的所有用户。
## 9. 消息队列使用拉模式好还是推模式好？为什么？
#### 推模式
- 消费者和中间件建立TCP长连接或者注册一个回调，当服务端数据发生变化，立即通过长连接或回调将数据推送到客户端。
- **应用场景**：适用于对实时性要求比较高的场景。
- **优点**：
	- 消息是实时的，消费者能马上感知消息；
	- 消费者实现简单，无需轮询，只需等待消息推送。
- **缺点**：
	- 若消息生产速度大于消费速度，则会造成消息堆积，甚至可能压垮消费者。
#### 拉模式
- 消费者轮询，通过不断轮询的方式检查数据是否发生变化，变化的话就将数据拉回来。
- **应用场景**：适用于实时性没那么高的场景。
- **优点**：
	- 消费者可以自己掌控消息的数量及速度，可以大大避免消息堆积发生；
- **缺点**：
	- 消费者需要不断轮询，可能会对消息中间件造成一定压力。
#### 长轮询模式
- 有些场景，服务器环境只能单向通信，因此无法实现推模式，只能采取拉模式。因此最常见的就是使用**长轮询**，将二者结合。
- **长轮询**：消费者向中间件发起长轮询请求，如果有消息就直接返回，没有就等待一会，如果等待过程中有消息到达，就把消息返回，若无则超时断连，等待下次长轮询。


## 10. 一个订单，在11:00超时关闭，但在11:00也支付成功了，怎么办？
#### 数据库层面
首先，订单有几种状态（如下）。其中，已取消与支付成功为终态，**不可再变化**。
![[Pasted image 20241227205252.png|200]]
订单超时关闭和支付成功同时请求，典型的并发问题，一个请求需要将状态由支付中→已取消，另一个请求将状态由支付中→支付成功。因此，我们可以在数据库层面做状态的判断：
- 在update时加上`status = "PAYING"`的判断。
```SQL
update pay_order set status = "PAY_SUCCESS",lock_version = lock_version + 1 where pay_order_no = #{parOrderNo} and status = "PAYING" and lock_version  = #{lock_version}

update pay_order set status = "PAY_EXPIRED",lock_version = lock_version + 1 where pay_order_no = #{parOrderNo} and status = "PAYING" and lock_version  = #{lock_version}
```
#### 两种不同支付状态的处理
此时，就只会出现两种情况：
1. 订单状态变为支付成功，订单已取消处理失败；
2. 订单状态变为已取消，支付成功的请求处理失败。

对于情况1：订单支付成功，无需额外处理。
**对于情况2**：订单超时取消，但是钱已经付完了！此时有两种处理方式：
1. **将钱原路退还**；
2. 将订单状态由已取消更改为支付成功。
只能采取方式1！因为对于方式2，①相当于将订单状态由终态「已取消」→终态「支付成功」，状态流转不合理；②此时订单取消，那么库存、优惠券都可能已经退还，因此再修改订单状态不合理。
#### 退还失败的考虑
钱款有可能退还失败。此时就需要引入对账机制，在订单表额外添加两个字段：①支付金额；②冲退金额。对于已支付订单，满足`支付金额>0,冲退金额=0`；对于已取消订单，满足`支付金额-冲退金额=0`。
#### 优化处理
在操作业务逻辑之前，抢支付单的锁，避免同时操作两种请求。
## 11. 一个支付单，多个渠道同时支付成功了怎么办？
在支付单中冗余一个支付渠道和渠道支付单号。回调时，检查是否有成功流水，对后来的支付流水进行退款操作。

## 12. 如何解决消息重复消费、重复下单等问题？
**做好幂等控制，避免重复导致脏数据。**
#### 基于token的幂等控制
- **基本思路**：用户每一次访问页面时，都向后端请求一个token，并在之后的页面操作中，都携带此token。只要页面不刷新，token都不变。
- **token校验**：后端生成token后（可以使用UUID、分布式ID等），将其存储在Redis中，KEY为token，VALUE可以设置为1，代表只能使用一次，并设置合理的过期时间，如1小时。VALUE为1，保证了token只能使用1次。
  ![[Pasted image 20241227214751.png|200]]
- **高并发场景的处理**：
	- 使用LUA脚本，保证获取与删除是原子性的；
	- 使用事务控制；
	- 直接使用DEL命令，通过判断DEL返回值是否为1来判断是否校验成功。

## 13. 使用CAS机制实现线程安全的单例
```java
public class Singleton {
    private static final AtomicReference<Singleton> INSTANCE = new AtomicReference<Singleton>(); 

    private Singleton() {}

    public static Singleton getInstance() {
        for (;;) {
            Singleton singleton = INSTANCE.get();
            if (null != singleton) {
                return singleton;
            }

            singleton = new Singleton();
            if (INSTANCE.compareAndSet(null, singleton)) {
                return singleton;
            }
        }
    }
}
```
## 14. 40亿个QQ号，限制1G内存，如何去重？
使用BitMap进行去重操作。

因为QQ号都是最大为11位的，并且都是整数，因此可认为一个QQ号占用4字节。那么40亿个QQ号，需要占用$4\times10^9\times4/1024/1024/1024=14.9G$

若使用位图，则可认为一个QQ号对应BitMap中的1位！因此40亿个QQ号最多占用$\frac{4000000000}{8\cdot1024\cdot1024\cdot1024}=0.47G$

>**1字节=8位，1kb=1024字节**

## 15. 高并发的库存系统，在数据库扣减库存，怎么实现？
热点数据更新问题。多个事务尝试修改同一行数据，锁竞争激烈，可能增加事务的等待时间和冲突概率，导致性能下降。

解决思路分3种：排队、拆分和合并执行。

#### 排队
针对于多个事务尝试更新同一行数据，让一个事务处理，其它事务排队执行。虽然UPDATE语句竞争行锁也是类似于排队，但是会不断自旋尝试获取锁，导致耗费CPU资源。

例如阿里和腾讯云数据库的Inventory Hint，针对于热点更新问题做了优化。让同一个热点行的更新语句，在**执行层进行排队**。这样的排队相比update的排队，要轻量级很多，因为他不需要自旋，不需要抢锁。
#### 拆分
将大库存拆分成小库存，分散到不同的表、库中，将请求分散，以减少单行记录的锁竞争问题。
**缺点**：会造成碎片，例如某个订单需要扣减999个库存，但虽然各分库存的加起来有999个，但各分库存都无法做到扣减。
#### 合并写
将多个UPDATE请求合并，减少更新次数，但是不适用于实时性要求高的场景，因为合并写需要有等待窗口来聚合多次更新请求。

## 16. MySQL热点数据更新会带来哪些问题？
1. 锁竞争问题。事务UPDATE行记录，会对该行数据加行排它锁，因此其它事务请求会被阻塞，并不断自旋尝试获取锁，造成CPU资源的浪费、以及降低系统整体吞吐量。
2. 占用数据库连接。事务尝试获取锁时，会占用数据库连接，导致数据库连接池被占满，影响其他事务进行连接更新，导致系统可用性以及吞吐量降低。
3. 死锁问题。![[Pasted image 20241228184004.png|300]]
4. 索引维护开销大。若更改的字段上建立了索引，那么还需要维护索引树，导致相关索引频繁维护，增加数据库开销，降低性能。
5. 主从不一致。主从复制延迟时，热点数据更新会增大数据不一致的概率。

## 17. MySQL有2kw条数据，Redis中只存20W数据，如何保证Redis中都是热点数据？
1. **缓存预热**：提前预测热点数据，往Redis缓存中提前存入热点数据。
2. **热点数据更新**：热点数据，实质上就是热Key，可以实时检测热Key，并做好维护与更新。
3. **缓存过期策略**：要保证都是热点数据，那么就要淘汰访问频次低、或者久不访问的数据，因此可以选用LRU/LFU淘汰策略，淘汰这两种数据。
	- LRU（最近最少使用）：适合短期内访问频率较高的数据
4. **内存淘汰策略**：给Key设置超时时间，并结合volatile-LRU过期策略移除不太常用的key。

## 18. 为什么一锁二判三更新，仍会出现重复数据？
**事务和锁的粒度问题**。一般是先提交事务，再释放锁。若将二者顺序颠倒，则会出现：
- 线程A开启事务、获取锁、修改数据、释放锁、提交事务。
- 线程B在A释放锁时就获取锁，此时事务A还未提交，那么数据变更也仍未提交，导致线程B的事务读不到未提交的数据，因此就会在原数据的基础上插入数据，导致出现了重复数据。

因此，我们需要保证先提交事务、再释放锁。方法可以是将①声明式事务改造成编程式事务，自己控制事务粒度；②控制锁的粒度，保证加锁和是否锁在事务外【例如环绕通知】。

## 19. 在100M内存下存储一亿个整数，其范围在１到2亿，如何快速判断给定到一个整数值是否存在？
大规模整数的去重问题。

#### BitMap
利用BitMap实现。1亿个整数，在BitMap中对应1亿位，也就是$\frac{100000000}{8\cdot1024\cdot1024}=11.9MB$。

本问题在实际场景中的应用：
1. 推荐系统中，为每个用户分配一个BitMap，将已推荐过的文章/视频ID放入BitMap，并在之后不再推荐。

**缺陷：**
- 稀疏整数问题。若存放的整数是不连续、跨度很大的整数，则会导致BitMap的占用由整数上界决定，导致浪费内存空间。
#### RoaringBitMap
>[java - 巧用RoaringBitMap处理海量数据内存diff问题 - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000042188742#item-8-8)

针对于稀疏整数存储与计算上进行了优化，因此在内存占用和运算时间耗时上都更优。
![[Pasted image 20241228192058.png|450]]
![[Pasted image 20241228192052.png|450]]
## 20. 为什么很多公司数据库不允许物理删除数据？
1. **数据留痕**。便于后续的数据分析等。
2. **合规要求**。某些行业受约束，需要保留业务数据。
3. **性能考虑**。物理删除可能会导致索引重建，会影响数据库性能。
4. **内存碎片**。InnoDB在删除数据后，空间不会立即释放，因此可能导致内存碎片，需要后续通过`OPTIMIZE TABLE`来重建索引，清理碎片。

## 21. 数据库逻辑删除后，怎么做唯一性约束？
数据宝贵，因此在实际业务中，往往都不会删除数据，而是定义字段进行逻辑删除，例如deleted或is_deleted.

以用户服务开通记录为例：
![[Pasted image 20241228192915.png|450]]
- 若是物理删除，则可以将`user_id`作为主键，那么就保证了只有一条记录。

#### 方案一：物理删除+数据归档
利用

#### 方案二：>0都表示逻辑删除

#### 方案三：引入新字段


## 22. 单表数据量大，只能考虑分库分表吗？
单表数据量超过2000W，会导致查询效率下降。但是，分库分表又会带来跨库事务、分页查询等问题。因此，可以先考虑以下几种方案，万不得已再进行分库分表。

1. **数据库优化**：构建索引、避免索引失效，可以提高查询效率。
2. **缓存**：构建本地缓存、分布式缓存，避免所有查询都由数据库承担。
3. **数据分区**：按照某些字段将数据分区，使得在逻辑上是一张表，但在物理存储上是多表。此时在查询时只会访问相关分区，而不会扫描整张表。
4. **数据归档**：可以将一些过期、不需要的数据归档，减少主表数据量，以提高查询效率。
5. **分布式数据库**：将数据分散到多个节点，每个节点存储一部分数据，降低单表存储压力。

## 23. 如何实现缓存预热？

## 24. 如何实现百万级数据从Excel导入到数据库？
存在的问题：
1. 内存溢出。百万级数据都加载到内存中，可能会OOM。
2. 性能问题。可能会很慢，需要优化导入速度。

**整体方案：**
- 将数据分为不同的sheet，使用线程池，每个线程处理一个sheet，提高读取速度；
- 读取数据到ArrayList中【读取每一行数据时都会验证数据是否有效】，当到达一定数量时再批量写入数据库中，避免对数据库压力过大。

## 25. 如果需要跨库join，该如何实现？

## 26. 如果要存IP地址，用什么数据类型比较好？
IPV4地址的格式：192.0.2.235
IPV6地址的格式：2001:0db8:86a3:08d3:1319:8a2e:0370:7344

两种地址都可利用3种方式存储：可变长字符串varchar、二进制、整数。
- 字符串存储可读性强，但是不便于做运算；
- 二进制和整数便于做运算，并且节省存储空间，但是可读性很差。

## 27. ⭐为什么不建议使用MQ实现订单到期关闭？
1. **MQ不可靠**。使用MQ会出现丢消息的问题；
2. **大量无效消息**。MQ实现订单关闭是在创建订单时添加延迟任务，因此当订单主动取消时，就会导致MQ出现很多无效信息。
3. **MQ延迟消息有限制**。例如RocketMQ，只支持固定时间的延迟消息，例如1、3、5分钟等；RabbitMQ使用死信队列或者插件实现延迟消息。
4. **消息堆积**。当订单量大时，为每个订单都创建延迟消息，可能会导致消息积压过多，会增加消息队列的资源消耗，并增加成本。
5. **精确性问题**。消息延迟，可能导致订单无法准时关闭。

综上，订单到期关闭一般使用定时任务实现，如XXL-JOB。

## 28. 敏感词过滤如何实现？
1. **字符串匹配**。
2. **前缀树匹配**。为敏感词构建前缀树，在判断某段文本是否有敏感词时，就以每一个字符作为开头在前缀树上寻找，判断是否能匹配上敏感词。
3. **DFA算法**。Deterministic Finite Automaton，确定有限自动机。^

具体实现可以通过基于DFA算法的开源敏感词过滤框架sensitive-word。

## 29. 为什么不建议在事务中做外部调用？
1. **增加事务持续时间**：外部的网络调用会**显著增加事务的执行时间**，特别是网络延迟或外部服务响应慢的情况下。事务持续时间的增加会占用数据库资源更长时间，如锁定资源，这会影响数据库的并发处理能力和整体性能。
2. **增加事务失败的风险**：外部调用会增加事务失败的可能性，提高了复杂度与风险。
	- 例如用户下单发送MQ，若将MQ发送卸载事务内部，并且在下单成功后发送MQ消息。则会出现MQ发送失败导致的事务回滚，使得原本下单成功的操作回滚了，不合理。
3. **无法保证原子性**：外部调用可能不易于回滚，若外部调用返回TimeOutException使得事务回滚，但由于是超时导致的回滚，因此外部调用可能已经执行成功，不符合事务原子性。

**正确做法：**
1. 事务与外部调用分离。尽量在事务提交后再进行外部调用。
2. 使用补偿事务。事务回滚，但外部调用成功，则可以通过补偿事务来撤销已经成功的外部操作。

## 30. 加分布式锁之后影响并发了怎么办？^
加锁

## 31. 数据库乐观锁和悲观锁以及redis分布式锁的区别和使用场景？
- **悲观锁**：假设总是会发生冲突，所以在数据处理前先加锁。如`SELECT FOR UPDATE`会加行锁。
	- **使用场景**：竞争较多、冲突频繁；更新和删除操作比较多的场景。
- **乐观锁**：假设多个事务不会在同一时间修改数据。如`WHERE xx = ?`是通过数据版本的方式来实现乐观。
	- **使用场景**： 竞争较少、冲突没那么频繁的场景；读多写少的场景。
- **分布式锁**：
	- 利用Redis可以实现悲观锁、乐观锁，并且Redis的锁功能更多，如可重入、可续期等。
	- Redis的性能更好。
	- 数据库的悲观锁可能会锁表，影响整体性能。

## 32. 大型电商的订单系统，如何设计分库分表方案？^
分表：为了解决单表数据量过大、查询效率低的问题。
分库：为了解决并发量太高，数据库连接数不够，数据库的资源性能不够的问题。

## 33. 分布式架构一定比单体架构好吗？
没有银弹！
**单体架构的优缺点：**
1. 开发、部署简单；
2. 不需要网络交互，无需通过HTTP、RPC协议与其他分布式系统交互。
3. 不需要考虑分布式问题。无需考虑分布式事务、分布式锁等问题。

**缺点：**
1. 性能瓶颈。
2. 开发效率低。
3. 单点故障问题。共用一个JVM，可能会导致某个模块出问题，对整个系统造成较大影响。

**分布式架构的优缺点：**
1. 易于扩展。可以通过应用拆分、加机器的方式，快速扩展，抗更高并发。
2. 模块化开发，提高开发效率。可以每个人或者每个团队负责某个模块，相互依赖只需要通过HTTP、RPC协议调用即可。
3. 减少了单点故障。多集群部署

**缺点：**
1. 系统复杂度提高。需要考虑服务间的调用、一致性等问题。
2. CAP理论。可用性、一致性、分区容错性无法做到面面俱到。

## 34. Redis如果挂了怎么办？
1. **使用集群模式**，如哨兵、集群、Cluster模式等，避免单点故障。
2. **对Redis加监控**。基于Redis的调用成功率做监控，发现长时间不可用或者超时，就考虑应急机制。
3. **限流降级机制**。提前做好预案，例如Redis做预扣减抗并发时挂了，则切换预案，将请求直接打到数据库上，并做好限流处理，防止数据库被击垮。
4. **备份**。做好备份，主节点挂了后切换到从节点提供服务。

## 35. 代码中使用长事务，会带来哪些问题？
1. 占用数据库连接，导致整体吞吐量下降。
2. 锁一直被持有，也会导致吞吐量下降，甚至死锁问题。
3. 旧版本数据一直存在，无法被Purge线程清理，影响整体性能。
4. RR和RC级别下，会让其他事务访问长事务锁定的行数据时需要额外更多的操作来重建旧版本数据。
5. 其他事务无法有效利用覆盖索引，需要回表查询完整数据，影响查询性能。
![[Pasted image 20241229201521.png]]
## 36. Redis 的内存如果用满了，会挂吗？
不会！因为Redis存在内存淘汰策略，在内存满了时会基于所使用的淘汰策略去移除Key来腾出空间。即使选择的是noeviction，也会拒绝写入，抛出OOM错误。

## 37. 给第三方提供接口调用，需要注意什么？
1. **授权机制**。在用户申请接口时，返回密钥，在接口调用时验证身份。
2. **访问控制**。可以为密钥分配不同的权限，保证某些用户只能访问特定的接口。
3. **接口语义明确**。避免接口的参数不明确，如使用包装类、字段名使用success，可以提供详细的接口文档。
4. **错误信息屏蔽**。使用错误码来代替异常，根据不同的异常定义不同的错误码返回给调用者。

## 38. 分库分表时，每个城市的人口不一样，有的密集，有的稀疏，如何实现均匀分布？
分库分表的数据倾斜问题，考虑以下几种方案：
1. **更换分表字段**。更换一个使数据分布更均匀的分表字段。【在业务允许的前提下】
2. **定义合适的分表算法**。
	- **方式一**：为人口多的城市单独分表，而其他人口少的城市共享几个分表。
	  ![[Pasted image 20241229204801.png|400]]
	- **方式二**：人口多的城市，进一步结合区ID等更细致的分类进行取模分表。
	  ![[Pasted image 20241229204817.png|400]]
## 39. 分布式系统，用户登录信息保存在服务器A上，服务器B如何获取到共享Session？
分布式Session问题。
利用Redis存储用户的登录信息，服务器B获取的话就直接查Redis就可以。
## 40. 实现一个登录拉黑功能，实现拉黑用户和把已经登陆用户踢下线。
#### 登录拉黑功能
1. 可以设置一个单独的黑名单表，存储被拉黑的用户信息。
2. 在用户表上添加黑名单字段，黑名单后设置字段即可。

还可以把黑名单用户缓存到布隆过滤器中，直接在布隆过滤器就把黑名单用户拦截。
#### 踢下线
Redis存储用户登录信息与Token（或token），踢下线时就将Redis中对应用户的token删除即可。

具体实现基于Sa-Token也可以。
![[Pasted image 20241229224823.png|550]]
## 41. 读取一千个文件，一个线程读取和开十个线程读取，哪种方式效率高？
读取文件是I/O密集型资源，可以通过多线程提高效率。I/O密集时，CPU会有等待，多线程可以合理利用这些空闲时间。
## 42. 大量的手机号码被标记成骚扰电话，如何存储这些号码?
骚扰电话，基本都是只增不减。
1. **数据库存储**。建立手机的索引。
2. **Redis存储做缓存**，定期更新。
	- 避免占用过多内存，可以使用LFU淘汰策略，只保存前20%高频的手机号。
	- 使用BitMap存储。
3. **本地缓存**。只增不减，可以利用本地缓存。
## 43. 把商品加入购物车时断网了，该怎么在重新联网时同步？

## 44. 外卖系统，一天一千万条数据，用户需要查到近30天的数据，商家也要查询到30天的数据，怎么设计表？
#### 问题分析
- 一天一千万条数据，那么一个月就是3亿条数据，单表肯定是无法存储的；
- 并且用户和商家都需要查询订单信息，因此单纯按照商家ID或者买家ID进行分表都不太合理，会导致跨表查询慢；
- 利用缓存也不太合理。因为数据量太大，同时订单信息频繁更改，容易出现数据不一致问题。
- 可划分为冷热数据，因为只需要查询最近30天的数据。
#### 方案设计
##### 方案一：分布式数据库
使用支持海量存储的分布式数据库，如TIDB，并针对`买家ID+时间`与`卖家ID+时间`建立索引，提高查询效率。

##### 方案二：分库分表
- 考虑数据量大、查询请求可能很大，可以将数据分库分表，降低单表的存储压力，并将请求分配到不同数据库，使得单库压力不过大。
	- 分表字段可以选择买家ID，这样可以保证买家的高效查询；
	- 针对于卖家的查询问题，可以采用数据同步方案，将数据冗余一份，再以卖家ID做分表。【也就是两张表】
		- 两张表时，买家ID作为主表，写时只写主表，卖家ID表通过数据同步方案写入【如监听Binlog、MQ、定时同步】。
- 对于查询问题，可以建立索引提高查询速度：`卖家ID + 时间`，`买家ID + 时间`；
- 冷热数据，可以将久远数据进行归档，降低存储压力。

```SQL
CREATE TABLE orders (
    order_id BIGINT AUTO_INCREMENT PRIMARY KEY,
    buyer_id BIGINT NOT NULL,
    seller_id BIGINT NOT NULL,
    order_date DATETIME NOT NULL,
    amout DECIMAL(10, 2),
    status ENUM('Pending', 'Completed', 'Cancelled', 'Refunded'),
    INDEX idx_user_date (buyer_id, order_date)
);
```
```SQL

CREATE TABLE orders_seller (
    order_id BIGINT AUTO_INCREMENT PRIMARY KEY,
    buyer_id BIGINT NOT NULL,
    seller_id BIGINT NOT NULL,
    order_date DATETIME NOT NULL,
    amout DECIMAL(10, 2),
    status ENUM('Pending', 'Completed', 'Cancelled', 'Refunded'),
    INDEX idx_seller_date (seller_id, order_date)
);
```


## 45. 有100个优惠券，有几千万流量，怎么保证服务器不跨掉，怎么保证最前面的人能抢到这个券？
1. **限流**：做好限流保护，如使用网关拦截用户请求，超过请求数则直接返回“繁忙”；或使用分布式限流工具，如Redis令牌桶对请求量进行控制。
2. **消息队列排队处理**：使用消息队列将抢券请求入队，排队处理，保证有序执行；
	- 可以使用分布式消息队列Kafka，将消息分散到多个分区，消费者可以并行消费。
3. **并发抢券**：Redis+Lua脚本做扣减，利用Redis的单线程与Lua脚本的原子性。
4. **异步写入**：Redis中扣减成功后，发送MQ消息，异步进行数据库的扣减。

利用分布式锁无法保证顺序获取，因为可能后面的人在尝试获取锁时，可能当前正好锁释放，从而可以获取锁，这就导致了后面的人先获取了优惠券。

## 46. 全国的酒店价格（千万级）需要在某个瞬间比如7点发生变动，怎样高性能准点去进行变更

1. 价格预计算。提前算好价格，避免在瞬间实时计算。
2. 利用**插入数据代替更新数据**。价格数据包含生效时间，这样可以保证提前插入数据，而非实时更新，并且还能保留旧版本数据。
	- 查询时，`start_time >= now() and end_time< now`，这样就可以保证新数据生效，旧数据失效。
![[Pasted image 20241230173910.png|300]]

若非要采用更新数据的方案，则可以通过**定时任务**处理，通过分库分表降低单库压力；同时采用批量更新，避免出现数据库连接数不够的情况。
## 47. 秒杀场景下，怎么加库存？
与秒杀扣减的思路一致：
1. Redis+Lua脚本进行库存的增加，此时新增库存不可用；
2. MQ异步通知数据库写入；
3. 消费消息，进行库存的增加，数据库库存增加成功后，通知Redis将新增库存标记为可用；
	- 幂等保证：新增一个operation_log表，用于记录消息每次库存操作是否成功。在消费消息时，先判断表中是否存在该库存更新操作，若存在且成功，则跳过此次消费。
4. 若数据库更新失败，则可重新发送消息进行重试；若多次失败，则可以通过死信队列进行人工干预；若最终未能成功，则可回滚Redis库存。

>感觉后续补偿也可以，因为此时可以以Redis中的库存作为保证，因为库存最终还是以实际中的库存作为兜底。Redis库存添加成功，就说明实际生活中就有对应这么多的库存。

若MQ写入失败，则可能导致“超卖”问题，解决方案有：
- 可以通过分布式事务TCC来保证数据库和Redis的强一致性；
- 为Redis的新增库存添加逻辑锁，只有在数据库更新成功后，才将新库存修改为可用。
- 异步更新数据库失败后重试或进行人工干预，多次失败后回滚Redis库存。

![[Pasted image 20241230202416.png|400]]
## 48. 分钟内最多允许用户尝试登录 3 次，如果错误次数超过限制，需要对该用户进行锁定。如何实现？ 

## 49. 两个不相关的网站A和B，如何实现A登录B也能自动登录
单点登录问题，有以下几种方案：
1. 基于Token。用户登录时，发送一个Token给前端，前端将Token存储在LocalStorage中，后续请求都携带该Token，此时其他网站也可基于该Token进行身份验证。
	- 优点：可解决跨域问题；
	- 缺点：Token会被泄露，有一定风险。
![[Pasted image 20241230204644.png|500]]
2. 基于共享Session。使用Redis存储用户Session，
![[Pasted image 20241230205113.png]]
3. 通过CAS（Central Auth Service）实现。
4. 通过OAuth2/ OpenID Connect实现。
## 50. MySQL单表一千万条数据怎么做分页查询？
1. 使用索引提高查询效率。
2. 避免深分页问题。
	- 通过记录上一页的最大ID的方式来实现查询
	  ```SQL
		  -- 第 1 页
		SELECT * FROM large_table WHERE id > 0 ORDER BY id ASC LIMIT 100;
		
		-- 第 N 页（假设上一页最后一条数据的 id 为 500）
		SELECT * FROM large_table WHERE id > 500 ORDER BY id ASC LIMIT 100;
			```
	- 通过子查询的方式来实现分页：
	  ```SQL
		-- 定位第 N 页起点
		SELECT * 
		FROM large_table 
		WHERE id >= (
		    SELECT id FROM large_table ORDER BY id ASC LIMIT 1000, 1
		) 
		ORDER BY id ASC 
		LIMIT 100;
			```
	- 可以在查询后几页数据时，通过倒序扫描来减少扫描数据量。
		```java
		-- 查询最后一页
		SELECT * 
		FROM large_table 
		ORDER BY id DESC 
		LIMIT 100;
		```

## 51. 什么是数据归档？


## 52. 一个长的事务方法a，在读写分离的情况下，里面既有读库操作，也有写库操作，再调用个读库方法b，方法b该用什么传播机制呢？

需要结合具体情况看。

假设读操作是最后一步，那么应该让读操作失败而不影响写操作，避免因读失败而导致数据回滚，因此应该选用`NOT_SUPPORTED`，即以非事务方式执行。

假设读操作在中间（写操作之前），那么就出异常导致失败，最好还是回滚一下。

## 53. 扫描登录是如何实现的？
