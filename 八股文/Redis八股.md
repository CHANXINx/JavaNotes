# 数据结构:
## 1. 介绍一下Redis的底层数据结构:
共五种,分别是`String,List,Set,Hash,ZSet`. 后续版本更新又添加了`BitMap,HyperLogLog,GEO,Stream`.

**使用场景:**
BitMap: 常用来做状态统计,例如用户签到记录.
HyperLogLog: 海量数据基数统计, 比如百万级用户UV
GEO: 存储地理信息,比如滴滴打车的用户定位?
Stream: 消息队列,相比于使用List实现的消息队列,优点是:1)可以自动生成全局唯一消息id; 2)支持以消费组形式消费数据.
## 2. ZSet用过吗?
用过. 用于实现排行榜功能. 数据结构为:`key:member:score`.
赋值可用`ZADD key score member`,为
增加点赞数量用: `ZINCRBY key increment member`,可在原有score基础上增量增加.
查询排行可以用`ZREVRANGE key start stop`来查询降序的排行.

## 3. ZSet的底层实现是什么?
ZSet底层是使用**压缩列表或跳表**实现的.
当集合的元素个数小于128,且每个元素的值小于64字节,使用压缩列表.
当不满足上述条件,例如元素个数大于128个,或存在元素大于64字节,则采用跳表.
然后,在Redis7中废除了压缩列表,使用listpack数据结构替代.

## 4. ==跳表是怎么实现的?== ^
跳表是在链表的基础上改进过来的. 主要原因就是链表的查询需要逐一查找,时间复杂度是O(N),所以引入了跳表,实现了**多层的有序链表**,优点就是提高了查询效率(O(logN)),更快速定位数据.
![[Pasted image 20241009232226.png]]
**查询值为4的节点:**
链表查询:需要从头节点开始遍历,查询4次才能查询到目标节点.
跳表查询:可直接从L2层级跳到节点上,再往后查询一次就可以查询到目标节点了,只需要查找2次.

**跳表的数据结构:->如何实现多层级的?**
```C
typedef struct zskiplistNode {
	//Zset 对象的元素值 
	sds ele; 
	//元素权重值 
	double score; 
	//后向指针 
	struct zskiplistNode *backward; 
	//节点的level数组，保存每层上的前向指针和跨度 
	struct zskiplistLevel { 
		struct zskiplistNode *forward; 
		unsigned long span; } level[]; 
	} zskiplistNode;
```
内部存在**ele和score变量**,对应了ZSet中的member(元素)和score(元素权重). 
然后还有个**后向指针**,指向前一个节点,便于倒序查找.

跳表是一个**带有层级关系**的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的**zskiplistLevel 结构体类型的 level 数组**。

**level 数组中的每一个元素代表跳表的一层**，也就是由zskiplistLevel结构体表示，比如`level[0]`就表示第一层,`level[1]`就表示第二层。zskiplistLevel结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。
![[Pasted image 20241012202231.png]]

Redis 跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。  

具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。  

这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。  

虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点。
## 5. 跳表是怎么设置层高的?
跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。 

## 6. ==Redis为什么使用跳表而不是用B+树?==
1. **内存占用**上,跳表更加灵活:
	平衡树每个节点包含2个指针,而跳表的每个节点包含的指针平均数目是`1/(1-p)`个,取决于p的大小.在Redis中,p的值为0.25,因此平均每个节点包含的指针就是`4/3`,比平衡树更有优势.
2. **范围查找**时,跳表操作更简单:
	B+树在查找到区间的左边界时(也就是较小的值),还需要继续中序遍历查找右边界的节点,那么在实现上就略显困难. 而在跳表上进行范围查询,只需要查找到小值后,在第一层进行若干次遍历再查找到右边界即可.
3. **算法实现**上,跳表更简单:
	B+树的插入和删除操作可能会导致树的结构的改变,逻辑复杂;而跳表的插入和删除只需要修改相邻节点的指针即可.

## 7. 压缩列表是怎么实现的? ^
## 8. 介绍一下Redis中的listpack. ^

## 9. 哈希表是怎么扩容的？
首先,正常情况下数据都存储在`哈希表1`中. 当数据量逐渐增加时,此时需要就需要有`哈希表2`,分配的空间大小一般为表1的**2倍**. 然后**表1的数据会迁移到表2**中,然后**表2会被设置成表1**,最后表2中又会再次新建一个空白的哈希表,为下次扩容做准备.

这涉及到一个问题,就是如果数据量很大,并且由于**Redis是单线程**的,所以数据在由表1迁移至表2时,会**引起Redis的阻塞**,导致无法服务其他请求.

所以Redis采用了**渐进式rehash**,也就是将数据分多次迁移.具体而言,是 
1) **先给`哈希表2`分配空间**,
2) 然后在执行增删改查操作时,会**按顺序将数据迁移到`哈希表2`中**.

在渐进式更新过程中,新增操作会将数据保存到`哈希表2`中.
查询操作会先查询表1,再查询表2.

## 10. String是使用什么存储的?为什么不用C语言中的字符串?
是使用SDS(Simple Dynamic String)数据结构存储的,使用SDS保证了Redis的"快".
![[Pasted image 20241012202850.png]]
**len:** 记录了字符串长度,保证了在查询字符串长度时的时间复杂度为O(1).

**alloc:** 分配给字符数组的空间长度. 在修改字符串时,会先判断`alloc-len`是否满足修改需求.
若不满足修改需求,则会自动将SDS的空间扩展至所需大小,然后再执行修改操作.
**用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出的问题。**


**flags:** 用来表示不同类型的SDS,共有SDSHDR5,SDSHDR8,SDSHDR16,SDSHDR32和SDSHDR65五种.

**buf[]:** 字符数组,用来保存实际数据.既可以保存字符串,也可以保存二进制数据.

### 相比于C语言中的字符串,SDS的优点:
1. **查询速度快.** 定义了len元数据,使得查询的时间复杂度由O(n)下降到O(1).
2. **二进制安全.**
	- SDS使用len来记录字符串长度,而C语言使用`\0`作为字符串结束标志来记录字符串长度. C语言使用`\0`作为结束标志,使其无法正确处理包含`\0`的字符串.
	- SDS字符串仍旧存在`\0`字符,以更好的兼容部分C语言标准库函数.使得SDS既可以作为C语言字符串使用,也可保证二进制安全.

3. **不会发生缓冲区溢出.** C语言的字符串标准库中的操作都是不安全的,因为"缓冲区大小是否满足修改需求"的操作交由开发者自己判断,而程序内部并不会自己判断是否足够用,故有可能发生缓冲区溢出导致程序异常结束!
   而**SDS结构的API会判断`alloc-len`是否满足修改需求**,保证缓冲区不会溢出.

# Redis线程模型:
## 1. Redis为什么快?
1. 基于内存的数据库,数据存储在内存中,读写速度非常快.
2. Redis的**单线程模型**,所有操作都在一个线程内完成,无需线程切换,节省了线程切换带来的额外开销,并且也不会有死锁问题.
3. Redis在单线程的基础上,采用了**I/O多路复用技术**(epoll和select机制),实现了**单个线程同时处理多个用户端连接**的能力,从而提高了Redis的并发性能.
	- 在单线程时,允许内核中存在多个监听Socket和已连接的Socket,内核会一直监听这些Socket的连接请求或数据请求.
4. 采用了**高效的数据结构**,在设计上进行了性能优化,能实现O(1)复杂度的读写操作.
5. Redis6.0中引入了多线程机制。采用多线程，可以使请求处理并发进行，大大提升性能。当线程在处理网络IO时，其他线程可以继续处理其他请求，减少了阻塞时间.

## 2. 为什么Redis 6.0引入了多线程? ^
>**Redis 6.0中的多线程,只是针对处理网络请求过程采用了多线程，而数据的读写命令，仍然是单线程处理的。**

为了处理更高的QPS.

## 3. Redis哪些地方使用了多线程? ^

## 4. Redis怎么实现的IO多路复用? ^

## 5. Redis的网络模型是怎样的? ^

---
# Redis事务:
## 1. 如何实现Redis原子性?
>**原子性在并发编程中，和在数据库中两种不同的概念:**  
>	在数据库中，事务的ACID中原子性指的是"**要么都执行要么都回滚**.
>	在并发编程中，原子性指的是"**操作不可拆分、不被中断**"。

Redis是单线程的,所以执行一条命令时是原子性的; 当有多条命令时,可以**使用lua脚本保证原子性**. Redis会把Lua脚本封装成单独的事务,由Redi服务器自行处理并完成整个事务,当此时有其他请求时,会暂存,等Lua脚本处理完毕后再把暂存的请求恢复.

Lua脚本

>[!注意]
>**Redis保证以原子方式执行Lua脚本，但是不保证脚本中所有操作要么都执行或者都回滚。**

**lua脚本举例:** 
分布式锁的解锁操作: 1)先判断锁是不是自己的; 2)是自己的再解锁.
```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放 
if redis.call("get",KEYS[1]) == ARGV[1] then     
	return redis.call("del",KEYS[1]) 
else     
	return 0 
end
```

## 2. 除了lua有没有什么也能保证redis的原子性?
Redis的事务也可以保证多个操作的原子性,即Redis的MULTI和EXEC操作. 

Redis的事务中,若前面的操作失败了,不影响后面操作的执行.
但是当事务中执行出错了,**无法回滚**.

## 3. Redis的事务和Lua之间有哪些区别？
Redis的事务和Lua脚本都是用来保证原子性的手段.

**区别1:原子性保证**
事务和Lua脚本都是原子性保证,但是**都无法回滚**!
但是,Redis的事务中,某个命令失败不会影响后续命令的执行. 而Lua脚本,若某个命令失败,后续命令也会受影响.

**区别2:交互次数**
Redis的事务由MULTI开始,EXEC结束.在期间的操作都会被Redis服务器暂存起来,不会立即执行,但是每次命令的提交都会与Redis服务器进行一次交互.

Lua脚本只需要一次性将脚本提交给Redis服务器即可.

**区别3:前后依赖**
Redis事务内的命令时独立执行的,并且在EXEC命令执行前,事务内的命令是没有被真正执行的.所以后续的命令不会也不能依赖于前面的命令的.(无`IF ELSE`等条件语句)

Lua脚本中的命令是可以依赖于前面的命令的,并且可以利用前一个命令的执行结果进行后续处理.例如`IF ELSE THEN`.

---
# Redis日志:
## 1. Redis的持久化方式有什么?各有什么优缺点?
共有**2种**持久化方式:
### **AOF日志:**
AOF,Append Only File,是**将Redis的所有写操作追加到AOF文件的末尾**,从而记录了Redis服务器运行期间所有修改操作的详细记录.Redis重启后,可通过执行写操作来恢复数据.

若写操作刚执行完,Redis服务器就宕机,此时写操作可能还未被写入AOF文件,会导致命令和相应的数据丢失.

**优点:** 可以实现**更高的数据可靠性(比RDB可靠)**、支持**更细粒度的数据恢复**，适合做数据存档和数据备份。
**缺点:** 文件大占用空间更多，**每次写操作都需要写磁盘导致负载较高**.


### **RDB快照:**
RDB,Redis DataBase Snapshot,是**将Redis的内存中的数据定期保存到磁盘**上，以防止数据在Redis进程异常退出或服务器断电等情况下丢失。

**优点:** 快照文件小,恢复速度快,适合做备份和灾难恢复.
**缺点:** 定期更新可能会丢数据.


### 混合持久化:RDB-AOF
Redis4.0推出了RDB-AOF混合持久化,同时保留了两种持久化的优点.

开启混合持久化,AOF重写时会将Redis的持久化数据,以RDB的格式写在AOF文件的开头,之后的数据再以AOF的格式追加到文件的末尾.

恢复数据时,会先加载RDB的快照部分,然后再执行快照之后的AOF格式保存的增量写操作,最终实现数据恢复.

**优点:** 结合了AOF的实时性以及RDB的快速恢复能力,既能确保数据的安全性和完整性，又提升了数据恢复的速度.
**缺点:** AOF文件的可读性变差,并且混合AOF文件无法在旧版本中使用.

---
# Redis缓存淘汰与过期删除:
## 1. 介绍一下Redis的过期策略.
Redis 的过期策略采用的是**定期删除和惰性删除相结合**的方式。

### 定期删除:
每隔100ms就随机抽取一些设置了过期时间的key,并检查其是否过期,过期则删除. 
若$\frac{过期的key}{抽查的总数}$>25%,则会继续随机抽取20个key判断是否过期，直到比例小于25%.

同时,为了避免循环过度,导致线程卡死,**循环流程具有25ms的时间上限.**

**过期时间配置:**
> redis.conf中配置了10Hz,也就是1秒抽取10次
> 随机抽取的个数默认为20个,并且是固定值.

**定期删除的优缺点:**
定期删除是Redis的主动删除策略,能保证过期的key被及时删除,但同时会**占用CPU资源**来扫描key,可能会影响Redis的性能.

**内存处理:**
将过期键删除时,**不会立即释放**内存,而是**将过期的key标记为"已过期",并放入专门的链表中**.在Redis的内存使用率达到一定阈值时,Redis会对这些"已过期"的键进行一次内存回收操作,是否键占用的内存空空间.

### 惰性删除:
当key过期时,不会立即删除,而是在key被访问时才触发删除操作.

**惰性删除的优缺点:**
惰性删除是Redis的被动删除策略,可节省CPU资源,但会导致过期的key始终保存在内存中,**占用内存资源**.

**内存处理:**
访问时检查是否过期,过期了则删除键并释放内存。

>[!注意:]
>一般来说，这些**被删除的内存空间会被操作系统标记为“可重用的内存”，等待被重新分配**。因此，即使Redis进行了内存回收操作，也并不能保证Redis所占用的内存空间会立即释放给操作系统。

## 2. 介绍一下Redis的内存淘汰策略(也叫数据逐出策略).
Redis 的内存淘汰策略用于在内存满了之后，决定哪些key要被删除,以保存新的内容. Redis 支持多种内存淘汰策略，可以通过配置文件中的 **maxmemory-policy** 参数来指定。

Redis的内存淘汰策略共8种,分为"不进行数据淘汰"和"进行数据淘汰"两类.
![[Pasted image 20241013180555.png]]
**不进行数据淘汰的策略:**
	●**noeviction:** 当运行内存超过最大设置内存时，**不淘汰任何数据**，这时如果有新的数据写入，会**报错通知禁止写入**. 但若只是单纯的查询或者删除操作的话,还是可以正常工作.


>lru:The Least Recently Used,最近**最少使用,最久未被访问**的数据会被最早淘汰.
 lfu:The Least Frequently Used,**使用频次最低**的数据会被最早淘汰.
- **进行数据淘汰的策略:** 组合`(allkeys,volatile)`和`(lru,lfu,random)`
	- **allkeys-lru:** 从**所有key中选择最近最少使用**的那个key并删除。  
	- **volatile-lru:** 从**设置了过期时间的key中选择最近最少使用**的那个key并删除。  
	- **allkeys-random:** 从所有 key 中**随机选择**一个 key 并删除。  
	- **volatile-random:** 从设置了过期时间的 key 中随机选择一个key并删除。  
	- **volatile-lfu:** 淘汰的对象是带有过期时间的键值对中，访问频率最低的那个。  
	- **allkeys-lfu:** 淘汰的对象则是所有键值对中，访问频率最低的那个。	
	- **volatile-ttl:** 从**设置了过期时间的key中选择剩余时间最短的key** 并删除。  

## 3. 如何选择内存淘汰策略?
腾讯针对Redis的淘汰策略设置给出的建议:
1. 当 **Redis 作为缓存使用**的时候，推荐使用 **allkeys-lru 淘汰策略**。该策略会将最近最少使用的 Key 淘汰。默认情况下，使用频率最低则后期命中的概率也最低，所以将其淘汰。
2. 当 Redis 作为**半缓存半持久化**使用时，可以使用 volatile-lru。但因为 Redis 本身不建议保存持久化数据，所以只作为备选方案。

阿里Redis的默认内存淘汰策略为**volatile-lru**.
## 4. 过期删除策略和内存淘汰策略有什么区别？ 
过期删除策略是淘汰已过期的键值对,
而内存淘汰策略是当Redis的运行内存满了的时候,通过配置的策略来删除键值对,腾出内存空间以保存新的内容.

---
# Redis集群
## 1. Redis主从同步中的增量和完全同步怎么实现？^



---
# Redis场景题
## 1. 什么是热Key问题，如何解决热key问题?^
### 介绍:
当我们使用Redis作为存储时，如果发生一些特殊情况，比如明星官宣的突发事件，世界杯等重大活动，双十一的活动秒杀等等，就会**出现特别大的流量，并且会导致某些热词、商品等被频繁的查询和访问**。

如果在**同一个时间点上，Redis中的同一个key被大量访问**，就会导致流量过于集中，使得很多物理资源无法支撑，如网络带宽、物理存储空间、数据库连接等。

量化定义:
### 解决:
>**热点key拆分,多级缓存,热key备份,限流等方案**
- 在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。
- 使用读写分离架构。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。

## 2. 什么是大Key问题,如何解决大Key问题?
Big Key是Redis中存储了大量数据的Key,即某个key对应的value值所占的内存空间比较大,导致Redis的性能下降,内存不足,数据不均衡以及主从同步延迟等问题.

### BigKey造成的危害:
1. **影响性能:** 由于big key的values占用的内存会很大，所以读取它们的速度会很慢，会影响系统的性能.
2. **占用内存:** 大量的big key也会占满Redis的内存，让Redis无法继续存储新的数据，而且也会导致Redis卡住.
3. **内存空间不均匀:** 在 Redis 集群中,可能会因为某个节点上存储了Big Key，导致**多个节点之间内存使用不均匀**。
4. **影响Redis备份和恢复:** 如果从RDB文件中恢复全量数据时，可能需要大量的时间，甚至无法正常恢复。
5. **搜索困难:** 搜索key内容时非常困难，并且可能需要花费较长的时间完成搜索任务。
6. **迁移困难:** 大对象的迁移和复制压力较大，极易破坏缓存的一致性
7. **过期执行耗时:** 如果 Bigkey 设置了过期时间，当过期后，这个 key 会被删除，而大key的删除过程也比较耗时
### 识别办法:
可通过`redis-cli-bigkeys`来获取Redis中的BigKey: 搜索**所有Redis数据库中包含大量内存数据的key**，并且会将其**保存在本地标准输出文件**中.
### 解决办法:(拆分+删除+迁移)
1. **拆分大Key:** 
	- 将大Key拆分为多个数据在合理范围的key,比如根据日期等字段进行拆分. 
	- 或者在集群模式下,将BigKey分散到不同服务器上,加快响应速度.
2. **清理过期数据:** 合理设置缓存的过期时间,避免因不及时清理而增大Key大小.
3. **合理删除:** 合理删除访问频率低的BigKey,优化内存占用.
4. **部分迁移:** 将大Key迁移至数据库存储,并异步删除Redis中的大Key.

## 3. 什么是缓存击穿,缓存穿透,缓存雪崩?
### **缓存击穿:**
某一个key缓存过期,当有高并发量的请求同时访问该key时,瞬间**击穿缓存服务器,直接访问数据库**,使数据库处于高负载情况.
### 缓存穿透:
>**与击穿的区别就在于,穿透的情况中,数据库也不存在查询的数据.**

服务器中不存在缓存数据,**数据库中也不存在符合条件的数据**,因此也无法构建缓存数据来服务后续的请求,导致大量请求到达数据库,使数据库处于高负载.

>[!击穿与穿透的区别]
>**共同点:**缓存服务器中都没有要访问的数据.
>**区别:**
>	击穿时,数据库存在要访问的数据,所以**访问后可以构建缓存数据**;
>	穿透时,数据库也不存在要访问的数据,**后续所有请求都会直接访问数据库**.
### 缓存雪崩:
大量缓存在同一时间到期,获取缓存服务器宕机,此时所有请求都直接访问数据库,造成数据库高负载,影响性能,甚至数据库宕机.

## 4. 什么情况下会出现数据库和缓存不一致的问题 
### 非并发情况:
写缓存和写数据库具有时间差,当一个操作失败,一个操作成功时,会出现不一致.

### 并发情况:
1. **两个线程同时进行更新操作**:
![[Pasted image 20241016162551.png]]

2. **读写并行操作:**(可能性较小,因为读操作的耗时很短)
![[Pasted image 20241016163228.png]]
## 5. ==如何解决(保证)Redis和数据库的一致性问题?== ^
>1.先更新数据库,再删除缓存.(而不是更新数据库,然后更新缓存)
>2.延迟双删：先删除缓存，再更新数据库，再删除一次缓存  
>3.cache-aside：更新数据库，基于 binlog 监听进行缓存删除

### 删除缓存代替更新缓存: ^

## 6. 为什么需要延迟双删,两次删除的原因是什么? ^


## 7. ==介绍一下布隆过滤器.==
>主要用于判断**数据是否不存在**,数据存在的情况可能会误判!

### **介绍:**
布隆过滤器是一种数据结构，用于**快速检索一个元素是否可能存在于一个集合(bit数组)中**。

布隆过滤器由 **"N个哈希函数"和"初始值为0的位图数组"** 构成.写入数据库时,会在位图上做标记, 而下次查询时,只需要查询布隆过滤器,若不存在标记,则代表数据不存在!

**优点:** 空间效率和查询时间都远远超过一般的算法
**缺点:** 有一定的误判率和删除困难。

### **工作过程:**
1. **初始化布隆过滤器:**
在初始化布隆过滤器时，需要**指定集合的大小和误判率**。布隆过滤器内部包含一个bit数组和多个哈希函数，每个哈希函数都会生成一个索引值。

2. **添加元素到布隆过滤器:**
元素通过多个哈希函数生成多个索引,将位图中对应索引的位置赋1.
	(经哈希函数后还需要`%BitMap.size()`,将哈希值限制在位图数组范围内)

3. **查询元素是否在布隆过滤器中:**
元素经由多个哈希函数生成多个索引,若索引对应的值都为1,则元素**可能存在**,若存在对应值不为1,则肯定不存在!

### 使用场景
1. **缓存系统:** 缓存系统可以使用布隆过滤器来判断一个查询是否可能存在于缓存中，从而减少查询缓存的次数，提高查询效率。布隆过滤器也经常用来解决缓存穿透的问题.
2. **分布式系统:** 在分布式系统中，可以使用布隆过滤器来判断一个元素是否存在于分布式缓存中，避免在所有节点上进行查询，减少网络负载。

### 使用方法:
基于Guava实现的布隆过滤器:
```java
// 创建布隆过滤器，预计插入100个元素，误判率为0.01
        BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(), 100, 0.01);

        // 插入元素
        bloomFilter.put("Hollis");
        bloomFilter.put("666");
        bloomFilter.put("八股文");

        // 判断元素是否存在
        System.out.println(bloomFilter.mightContain("Hollis")); // true
        System.out.println(bloomFilter.mightContain("王星星"));  // false
```

注意,实现布隆过滤器时,需要传入 **"容量"和"误判率"** 两个参数,内部会**根据参数计算出所需的BitMap数组大小和哈希函数的数量**,使得在当前容量下存入的元素能满足误判率要求.
	注意,实际存放的元素数量可以超过容量,但此时误判率会增加.

## 8. 库存扣减如何避免超卖和少卖?
### 超卖问题:

**出现原因:** 
![[Pasted image 20241016213556.png|300]]
### 解决办法1:数据层面进行库存限制

借助数据库自己执行引擎的顺序执行机制，只要保证库存不要扣减成负数:
```sql
update inventory
set quantity = quantity - #{count}
where sku_id='123' and quantity >= #{count}
```

**缺点:**
- 完全依赖数据库,在高并发情况下,多个线程同时更新会发生阻塞.
### 解决办法2:Redis扣减

利用Redis的单线程执行特性,以及Lua脚本的原子性保障:
```lua
local key = KEYS[1] -- 商品的键名
local amount = tonumber(ARGV[1]) -- 扣减的数量

-- 获取商品当前的库存量
local stock = tonumber(redis.call('get', key))

-- 如果库存足够，则减少库存并返回新的库存量
if stock >= amount then
    redis.call('decrby', key, amount)
    return redis.call('get', key)
else
    return "INSUFFICIENT STOCK"
end

```

### 解决办法3:方案融合(实际应用)

先在Redis中做扣减,利用Redis来抗高并发,然后再同步到数据库扣减进行持久化存储,避免Redis挂了导致数据丢失.

一般的做法是: 先在Redis中做扣减，然后发送一个MQ消息，消费者在接到消息之后做数据库中库存的真正扣减及业务逻辑操作。
![[Pasted image 20241021000228.png]]

但是,若Redis中扣减成功,但是MQ消息发送失败或者消息丢了,则可能导致少卖问题.

#### 少卖问题解决办法:
引入一些**对账机制**，做一些**准实时的核对**，针对这类情况及时发现，如果少卖很多的话，那么就需要再把这些库存加回去。（比如用zset在redis中添加流水记录，然后定时拉一段时间内的所有记录，和数据库比对，发现不一致，则进行补偿处理）

### 解决办法4:分布式锁?

利用分布式锁,保证同一时间只能有一个客户端拿到锁,其他客户端会循环等待来尝试获取锁.
#### 不使用分布式锁的原因:
- 分布式锁,在不使用Lua脚本的情况下,**每次库存扣减操作都需要与Redis服务器进行多次通信**(如加锁,读取库存,扣减库存,释放锁).**既增加了网络延时,还增加了系统的复杂性.**
- Lua脚本在Redis服务器内部执行,可以直接操作内存数据,执行效率很高.并且使用 Lua 脚本实现的话，我们可以**将库存扣减的逻辑集中处理,不需要在应用层做额外的同步处理**。
- 分布式锁需要细致的管理，包括锁的设置、维护锁的存活时间、处理死锁问题等。如果锁没有正确管理，可能会导致死锁或者锁失效，进而影响系统的稳定性和数据一致性。
