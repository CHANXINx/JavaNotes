# Java基础:
## 1. 

# 集合类:

# Spring:

## 1. 介绍一下Spring的IOC:
IOC,全称Inverse Of Control,控制反转.
传统的程序设计中,应用程序代码通常控制对象的创建和管理.例如,当一个对象需要依赖其他对象时,程序通过new等方式创建对象.而在IOC中,控制关系反转,**控制权交由Spring容器管理,容器负责创建和管理对象**!并在有需要时**注入**程序中.

**优点:**
1. 使用者无需关心引用bean的全部细节.
2. 不用创建多个相同的bean导致浪费.
3. Bean的修改使用方无需感知.

## 2. 介绍一下Spring的AOP:
AOP,全称Aspect-Oriented Programming,面向切面编程,即把公用的逻辑抽出,让开发者能更专注于业务!
面向切面编程是面向对象编程思想的补充. AOP面向不同切面,并且**一个切面可以横跨多个类和对象操作**,极大地丰富了开发者的使用方式,提高了开发效率.

# MySQL:

# Redis:
## 1. 介绍一下Redis的底层数据结构:
共五种,分别是`String,List,Set,Hash,ZSet`. 后续版本更新又添加了`BitMap,HyperLogLog,GEO,Stream`.

**使用场景:**
BitMap: 常用来做状态统计,例如用户签到记录.
HyperLogLog: 海量数据基数统计, 比如百万级用户UV
GEO: 存储地理信息,比如滴滴打车的用户定位?
Stream: 消息队列,相比于使用List实现的消息队列,优点是:1)可以自动生成全局唯一消息id; 2)支持以消费组形式消费数据.
## 2. ZSet用过吗?
用过. 用于实现排行榜功能. 数据结构为:`key:member:score`.
赋值可用`ZADD key score member`,为
增加点赞数量用: `ZINCRBY key increment member`,可在原有score基础上增量增加.
查询排行可以用`ZREVRANGE key start stop`来查询降序的排行.

## 3. ZSet的底层实现是什么?
ZSet底层是使用**压缩列表或跳表**实现的.
当集合的元素个数小于128,且每个元素的值小于64字节,使用压缩列表.
当不满足上述条件,例如元素个数大于128个,或存在元素大于64字节,则采用跳表.
然后,在Redis7中废除了压缩列表,使用listpack数据结构替代.

## 4. ==跳表是怎么实现的?== ^
跳表是在链表的基础上改进过来的. 主要原因就是链表的查询需要逐一查找,时间复杂度是O(N),所以引入了跳表,实现了**多层的有序链表**,优点就是提高了查询效率(O(logN)),更快速定位数据.
![[Pasted image 20241009232226.png]]
**查询值为4的节点:**
链表查询:需要从头节点开始遍历,查询4次才能查询到目标节点.
跳表查询:可直接从L2层级跳到节点上,再往后查询一次就可以查询到目标节点了,只需要查找2次.

**跳表的数据结构:->如何实现多层级的?**
```C
typedef struct zskiplistNode {
	//Zset 对象的元素值 
	sds ele; 
	//元素权重值 
	double score; 
	//后向指针 
	struct zskiplistNode *backward; 
	//节点的level数组，保存每层上的前向指针和跨度 
	struct zskiplistLevel { 
		struct zskiplistNode *forward; 
		unsigned long span; } level[]; 
	} zskiplistNode;
```
内部存在**ele和score变量**,对应了ZSet中的member(元素)和score(元素权重). 
然后还有个**后向指针**,指向前一个节点,便于倒序查找.

跳表是一个**带有层级关系**的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的**zskiplistLevel 结构体类型的 level 数组**。

**level 数组中的每一个元素代表跳表的一层**，也就是由zskiplistLevel结构体表示，比如`level[0]`就表示第一层,`level[1]`就表示第二层。zskiplistLevel结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。
![[Pasted image 20241012202231.png]]

Redis 跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。  

具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。  

这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。  

虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点。
## 5. 跳表是怎么设置层高的?
跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。 

## 6. ==Redis为什么使用跳表而不是用B+树?==
1. **内存占用**上,跳表更加灵活:
	平衡树每个节点包含2个指针,而跳表的每个节点包含的指针平均数目是`1/(1-p)`个,取决于p的大小.在Redis中,p的值为0.25,因此平均每个节点包含的指针就是`4/3`,比平衡树更有优势.
2. **范围查找**时,跳表操作更简单:
	B+树在查找到区间的左边界时(也就是较小的值),还需要继续中序遍历查找右边界的节点,那么在实现上就略显困难. 而在跳表上进行范围查询,只需要查找到小值后,在第一层进行若干次遍历再查找到右边界即可.
3. **算法实现**上,跳表更简单:
	B+树的插入和删除操作可能会导致树的结构的改变,逻辑复杂;而跳表的插入和删除只需要修改相邻节点的指针即可.

## 7. 压缩列表是怎么实现的? ^
## 8. 介绍一下Redis中的listpack. ^

## 9. 哈希表是怎么扩容的？
首先,正常情况下数据都存储在`哈希表1`中. 当数据量逐渐增加时,此时需要就需要有`哈希表2`,分配的空间大小一般为表1的**2倍**. 然后**表1的数据会迁移到表2**中,然后**表2会被设置成表1**,最后表2中又会再次新建一个空白的哈希表,为下次扩容做准备.

这涉及到一个问题,就是如果数据量很大,并且由于**Redis是单线程**的,所以数据在由表1迁移至表2时,会**引起Redis的阻塞**,导致无法服务其他请求.

所以Redis采用了**渐进式rehash**,也就是将数据分多次迁移.具体而言,是 
1) **先给`哈希表2`分配空间**,
2) 然后在执行增删改查操作时,会**按顺序将数据迁移到`哈希表2`中**.

在渐进式更新过程中,新增操作会将数据保存到`哈希表2`中.
查询操作会先查询表1,再查询表2.

## 10. String是使用什么存储的?为什么不用 c 语言中的字符串?
是使用SDS(Simple Dynamic String)数据结构存储的,使用SDS保证了Redis的"快".
![[Pasted image 20241012202850.png]]
**len:** 记录了字符串长度,保证了在查询字符串长度时的时间复杂度为O(1).

**alloc:** 分配给字符数组的空间长度. 在修改字符串时,会先判断`alloc-len`是否满足修改需求.
若不满足修改需求,则会自动将SDS的空间扩展至所需大小,然后再执行修改操作.
**用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出的问题。**


**flags:** 用来表示不同类型的SDS,共有SDSHDR5,SDSHDR8,SDSHDR16,SDSHDR32和SDSHDR65五种.

**buf[]:** 字符数组,用来保存实际数据.既可以保存字符串,也可以保存二进制数据.

### 相比于C语言中的字符串,SDS的优点:
1. **查询速度快.** 定义了len元数据,使得查询的时间复杂度由O(n)下降到O(1).
2. **二进制安全.**
	- SDS使用len来记录字符串长度,而C语言使用`\0`作为字符串结束标志来记录字符串长度. C语言使用`\0`作为结束标志,使其无法正确处理包含`\0`的字符串.
	- SDS字符串仍旧存在`\0`字符,以更好的兼容部分C语言标准库函数.使得SDS既可以作为C语言字符串使用,也可保证二进制安全.

3. **不会发生缓冲区溢出.** C语言的字符串标准库中的操作都是不安全的,因为"缓冲区大小是否满足修改需求"的操作交由开发者自己判断,而程序内部并不会自己判断是否足够用,故有可能发生缓冲区溢出导致程序异常结束!
   而**SDS结构的API会判断`alloc-len`是否满足修改需求**,保证缓冲区不会溢出.


## 11. Redis为什么快?
1. 基于内存的数据库,数据存储在内存中,读写速度非常快.
2. Redis的**单线程模型**,所有操作都在一个线程内完成,无需线程切换,节省了线程切换带来的额外开销,并且也不会有死锁问题.
3. Redis在单线程的基础上,采用了**I/O多路复用技术**(epoll和select机制),实现了**单个线程同时处理多个用户端连接**的能力,从而提高了Redis的并发性能.
	- 在单线程时,允许内核中存在多个监听Socket和已连接的Socket,内核会一直监听这些Socket的连接请求或数据请求.
4. 采用了**高效的数据结构**,在设计上进行了性能优化,能实现O(1)复杂度的读写操作.
5. Redis6.0中引入了多线程机制。采用多线程，可以使请求处理并发进行，大大提升性能。当线程在处理网络IO时，其他线程可以继续处理其他请求，减少了阻塞时间.

## 12. 为什么Redis 6.0引入了多线程? ^
>**Redis 6.0中的多线程,只是针对处理网络请求过程采用了多线程，而数据的读写命令，仍然是单线程处理的。**

为了处理更高的QPS.

## 13. Redis哪些地方使用了多线程? ^

## 14. Redis怎么实现的IO多路复用? ^

## 15. Redis的网络模型是怎样的? ^

---

## 16. 如何实现Redis原子性?
>**原子性在并发编程中，和在数据库中两种不同的概念:**  
>	在数据库中，事务的ACID中原子性指的是"**要么都执行要么都回滚**.
>	在并发编程中，原子性指的是"**操作不可拆分、不被中断**"。

Redis是单线程的,所以执行一条命令时是原子性的; 当有多条命令时,可以**使用lua脚本保证原子性**. Redis会把Lua脚本封装成单独的事务,由Redi服务器自行处理并完成整个事务,当此时有其他请求时,会暂存,等Lua脚本处理完毕后再把暂存的请求恢复.

Lua脚本

>[!注意]
>**Redis保证以原子方式执行Lua脚本，但是不保证脚本中所有操作要么都执行或者都回滚。**

**lua脚本举例:** 
分布式锁的解锁操作: 1)先判断锁是不是自己的; 2)是自己的再解锁.
```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放 
if redis.call("get",KEYS[1]) == ARGV[1] then     
	return redis.call("del",KEYS[1]) 
else     
	return 0 
end
```

## 17. 除了lua有没有什么也能保证redis的原子性?
Redis的事务也可以保证多个操作的原子性,即Redis的MULTI和EXEC操作. 

Redis的事务中,若前面的操作失败了,不影响后面操作的执行.
但是当事务中执行出错了,**无法回滚**.

## 18. Redis的事务和Lua之间有哪些区别？
Redis的事务和Lua脚本都是用来保证原子性的手段.

**区别1:原子性保证**
事务和Lua脚本都是原子性保证,但是**都无法回滚**!
但是,Redis的事务中,某个命令失败不会影响后续命令的执行. 而Lua脚本,若某个命令失败,后续命令也会受影响.

**区别2:交互次数**
Redis的事务由MULTI开始,EXEC结束.在期间的操作都会被Redis服务器暂存起来,不会立即执行,但是每次命令的提交都会与Redis服务器进行一次交互.

Lua脚本只需要一次性将脚本提交给Redis服务器即可.

**区别3:前后依赖**
Redis事务内的命令时独立执行的,并且在EXEC命令执行前,事务内的命令是没有被真正执行的.所以后续的命令不会也不能依赖于前面的命令的.(无`IF ELSE`等条件语句)

Lua脚本中的命令是可以依赖于前面的命令的,并且可以利用前一个命令的执行结果进行后续处理.例如`IF ELSE THEN`.

---
## 19. Redis的持久化方式有什么?各有什么优缺点?
共有**2种**持久化方式:
### **AOF日志:**
AOF,Append Only File,是**将Redis的所有写操作追加到AOF文件的末尾**,从而记录了Redis服务器运行期间所有修改操作的详细记录.Redis重启后,可通过执行写操作来恢复数据.

若写操作刚执行完,Redis服务器就宕机,此时写操作可能还未被写入AOF文件,会导致命令和相应的数据丢失.

**优点:** 可以实现**更高的数据可靠性(比RDB可靠)**、支持**更细粒度的数据恢复**，适合做数据存档和数据备份。
**缺点:** 文件大占用空间更多，**每次写操作都需要写磁盘导致负载较高**.


### **RDB快照:**
RDB,Redis DataBase Snapshot,是**将Redis的内存中的数据定期保存到磁盘**上，以防止数据在Redis进程异常退出或服务器断电等情况下丢失。

**优点:** 快照文件小,恢复速度快,适合做备份和灾难恢复.
**缺点:** 定期更新可能会丢数据.


### 混合持久化:RDB-AOF
Redis4.0推出了RDB-AOF混合持久化,同时保留了两种持久化的优点.

开启混合持久化,AOF重写时会将Redis的持久化数据,以RDB的格式写在AOF文件的开头,之后的数据再以AOF的格式追加到文件的末尾.

恢复数据时,会先加载RDB的快照部分,然后再执行快照之后的AOF格式保存的增量写操作,最终实现数据恢复.

**优点:** 结合了AOF的实时性以及RDB的快速恢复能力,既能确保数据的安全性和完整性，又提升了数据恢复的速度.
**缺点:** AOF文件的可读性变差,并且混合AOF文件无法在旧版本中使用.

---
## 20. 介绍一下Redis的过期策略.
Redis 的过期策略采用的是**定期删除和惰性删除相结合**的方式。

### 定期删除:
每隔100ms就随机抽取一些设置了过期时间的key,并检查其是否过期,过期则删除. 
若$\frac{过期的key}{抽查的总数}$>25%,则会继续随机抽取20个key判断是否过期，直到比例小于25%.

同时,为了避免循环过度,导致线程卡死,**循环流程具有25ms的时间上限.**

**过期时间配置:**
> redis.conf中配置了10Hz,也就是1秒抽取10次
> 随机抽取的个数默认为20个,并且是固定值.

**定期删除的优缺点:**
定期删除是Redis的主动删除策略,能保证过期的key被及时删除,但同时会**占用CPU资源**来扫描key,可能会影响Redis的性能.

**内存处理:**
将过期键删除时,**不会立即释放**内存,而是**将过期的key标记为"已过期",并放入专门的链表中**.在Redis的内存使用率达到一定阈值时,Redis会对这些"已过期"的键进行一次内存回收操作,是否键占用的内存空空间.

### 惰性删除:
当key过期时,不会立即删除,而是在key被访问时才触发删除操作.

**惰性删除的优缺点:**
惰性删除是Redis的被动删除策略,可节省CPU资源,但会导致过期的key始终保存在内存中,**占用内存资源**.

**内存处理:**
访问时检查是否过期,过期了则删除键并释放内存。

>[!注意:]
>一般来说，这些**被删除的内存空间会被操作系统标记为“可重用的内存”，等待被重新分配**。因此，即使Redis进行了内存回收操作，也并不能保证Redis所占用的内存空间会立即释放给操作系统。

## 21. 介绍一下Redis的内存淘汰策略(也叫数据逐出策略).
Redis 的内存淘汰策略用于在内存满了之后，决定哪些key要被删除,以保存新的内容. Redis 支持多种内存淘汰策略，可以通过配置文件中的 **maxmemory-policy** 参数来指定。

Redis的内存淘汰策略共8种,分为"不进行数据淘汰"和"进行数据淘汰"两类.
![[Pasted image 20241013180555.png]]
**不进行数据淘汰的策略:**
	●**noeviction:** 当运行内存超过最大设置内存时，**不淘汰任何数据**，这时如果有新的数据写入，会**报错通知禁止写入**. 但若只是单纯的查询或者删除操作的话,还是可以正常工作.


>lru:The Least Recently Used,最近**最少使用,最久未被访问**的数据会被最早淘汰.
 lfu:The Least Frequently Used,**使用频次最低**的数据会被最早淘汰.
- **进行数据淘汰的策略:** 组合`(allkeys,volatile)`和`(lru,lfu,random)`
	- **allkeys-lru:** 从**所有key中选择最近最少使用**的那个key并删除。  
	- **volatile-lru:** 从**设置了过期时间的key中选择最近最少使用**的那个key并删除。  
	- **allkeys-random:** 从所有 key 中**随机选择**一个 key 并删除。  
	- **volatile-random:** 从设置了过期时间的 key 中随机选择一个key并删除。  
	- **volatile-lfu:** 淘汰的对象是带有过期时间的键值对中，访问频率最低的那个。  
	- **allkeys-lfu:** 淘汰的对象则是所有键值对中，访问频率最低的那个。	
	- **volatile-ttl:** 从**设置了过期时间的key中选择剩余时间最短的key** 并删除。  

## 22. 如何选择内存淘汰策略?
腾讯针对Redis的淘汰策略设置给出的建议:
1. 当 **Redis 作为缓存使用**的时候，推荐使用 **allkeys-lru 淘汰策略**。该策略会将最近最少使用的 Key 淘汰。默认情况下，使用频率最低则后期命中的概率也最低，所以将其淘汰。
2. 当 Redis 作为**半缓存半持久化**使用时，可以使用 volatile-lru。但因为 Redis 本身不建议保存持久化数据，所以只作为备选方案。

阿里Redis的默认内存淘汰策略为**volatile-lru**.
## 23. 过期删除策略和内存淘汰策略有什么区别？ 
过期删除策略是淘汰已过期的键值对,
而内存淘汰策略是当Redis的运行内存满了的时候,通过配置的策略来删除键值对,腾出内存空间以保存新的内容.

---
## 24. Redis主从同步中的增量和完全同步怎么实现？



---
<h1 align="center" style="color:red;font-size:50px">场景题</h1>
## 25. 什么是热Key问题，如何解决热key问题?^
### 介绍:
当我们使用Redis作为存储时，如果发生一些特殊情况，比如明星官宣的突发事件，世界杯等重大活动，双十一的活动秒杀等等，就会**出现特别大的流量，并且会导致某些热词、商品等被频繁的查询和访问**。

如果在同一个时间点上，Redis中的同一个key被大量访问，就会导致流量过于集中，使得很多物理资源无法支撑，如网络带宽、物理存储空间、数据库连接等。

### 解决:
对于热key的处理，主要在于**事前预测和事中解决**。

## 25. 什么是大Key问题,如何解决大Key问题?
Big Key是Redis中存储了大量数据的Key,即某个key对应的value值所占的内存空间比较大,导致Redis的性能下降,内存不足,数据不均衡以及主从同步延迟等问题.

### BigKey造成的危害:
1. **影响性能:** 由于big key的values占用的内存会很大，所以读取它们的速度会很慢，会影响系统的性能.
2. **占用内存:** 大量的big key也会占满Redis的内存，让Redis无法继续存储新的数据，而且也会导致Redis卡住.
3. **内存空间不均匀:** 在 Redis 集群中,可能会因为某个节点上存储了Big Key，导致**多个节点之间内存使用不均匀**。
4. **影响Redis备份和恢复:** 如果从RDB文件中恢复全量数据时，可能需要大量的时间，甚至无法正常恢复。
5. **搜索困难:** 搜索key内容时非常困难，并且可能需要花费较长的时间完成搜索任务。
6. **迁移困难:** 大对象的迁移和复制压力较大，极易破坏缓存的一致性
7. **过期执行耗时:** 如果 Bigkey 设置了过期时间，当过期后，这个 key 会被删除，而大key的删除过程也比较耗时

### 识别办法:
可通过`redis-cli-bigkeys`来获取Redis中的BigKey: 搜索**所有Redis数据库中包含大量内存数据的key**，并且会将其**保存在本地标准输出文件**中.
### 解决办法:(拆分+删除+迁移)
1. **拆分大Key:** 
	- 将大Key拆分为多个数据在合理范围的key,比如根据日期等字段进行拆分. 
	- 或者在集群模式下,将BigKey分散到不同服务器上,加快响应速度.
2. **清理过期数据:** 合理设置缓存的过期时间,避免因不及时清理而增大Key大小.
3. **合理删除:** 合理删除访问频率低的BigKey,优化内存占用.
4. **部分迁移:** 将大Key迁移至数据库存储,并异步删除Redis中的大Key.

## 26. 什么情况下会出现数据库和缓存不一致的问题 ^

## 27. ==如何解决(保证)Redis和数据库的一致性问题?== ^

## 28. ==介绍一下布隆过滤器.==


# 计算机网络

## 1. JWT令牌详解:
### 出现背景:
互联网服务离不开用户认证。一般流程是下面这样:
> 1、用户向服务器发送用户名和密码。
> 2、服务器验证通过后，在**当前对话（session）里面保存相关数据**，比如用户角色、登录时间等等。
> 3、服务器向用户返回一个session_id，**写入用户的Cookie。**
> 4、用户随后的每一次请求,都会**通过 Cookie将session_id 传回服务器**。
> 5、服务器收到session_id，找到前期保存的数据，由此得知用户的身份。

这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。

举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？

一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。

另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。

### JWT令牌原理:
JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户.

以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器**完全只靠这个对象认定用户身份**。为了防止用户篡改数据，服务器在生成这个对象的时候，会**加上签名**（详见后文）。

**服务器就不保存任何 session 数据了，也就是说，服务器变成==无状态==了，从而比较容易实现扩展。**

### JWT的数据结构:
JWT由三个部分组成:`头部(Header).负载(Payload).签名(Signature)`,三者之间通过`.`隔开.
#### Header:
Header 部分是一个JSON对象，描述JWT的元数据,样例如下:
```JavaScript
{
  "alg": "HS256",
  "typ": "JWT"
}
```
- `alg`表示签名算法,默认为`HMAC SHA256`(写成HS256);
- `typ`表示token类型,JWT令牌统一写成JWT.

#### Payload:
Payload部分也是一个JSON对象，用来存放实际需要传递的数据.JWT规定了7个官方字段:
- iss (issuer)：签发人
- **exp (expiration time)：过期时间**
- sub (subject)：主题
- aud (audience)：受众
- nbf (Not Before)：生效时间
- iat (Issued At)：签发时间
- jti (JWT ID)：编号
除了官方字段，你还可以在这个部分**定义私有字段**，下面就是一个例子:
```JavaScript
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
```
**JWT 默认是不加密**的，任何人都可以读到，所以不要把秘密信息放在这个部分。

#### Signature:
Signature部分是对前两部分的签名,防止数据篡改.

首先，需要**指定一个密钥（secret）**。这个**密钥只有服务器才知道，不能泄露给用户**。然后，使用Header里面指定的签名算法（默认是HMAC SHA256），按照下面的公式产生签名。
>即`签名=HS257(Header.Payload,secret)`
```JavaScript
HMACSHA256(
  base64UrlEncode(header) + "." +
  base64UrlEncode(payload),
  secret)
```
计算出签名后,**将Header,Payload与Signature之间用`.`进行拼接**就得到了Token,就可以返回给用户了.
即对Header和Payload使用Base64URL算法生成JSON字符串,然后加上密钥,三者使用`.`进行拼接,获得最终的token.

### JWT的使用方式:
客户端收到服务器返回的 JWT，**可以储存在 Cookie 里面，也可以储存在 localStorage。**

此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息`Authorization`字段里面。

```javascript 
> Authorization: Bearer <token>
 ```

另一种做法是,跨域的时候,JWT就放在POST请求的数据体里面。

### JWT的几个特点:
1. JWT**默认是不加密**，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次.
2. JWT不加密的情况下，不能将秘密数据写入JWT。
3. JWT不仅可以用于认证，也可以**用于交换信息**。有效使用JWT，可以**降低服务器查询数据库的次数。**
4. JWT的最大缺点是，由于服务器不保存 session 状态，因此**无法在使用过程中废止某个 token**，或者更改token的权限。也就是说，一旦JWT签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。
5. JWT本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，**JWT的有效期应该设置得比较短**。对于一些比较重要的权限，使用时应该再次对用户进行认证。
6. 为了减少盗用，JWT不应该使用HTTP协议明码传输，要使用HTTPS协议传输。

![[Pasted image 20241011012123.png]]

## 2. WebSocket详解
### 出现背景:
根本原因在于HTTP协议的缺点,通信只能由客户端发起. 例如,如果想了解当天的天气,只能是由客户端想服务端发起查询请求,服务端返回查询结果. 而无法做到服务端向客户端主动推送消息.

这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用**轮询：每隔一段时候，就发出一个询问，了解服务器有没有新的信息**。最典型的场景就是聊天室。

轮询的效率很低,并且浪费资源,因为客户端和服务端必须不停连接,或者HTTP连接始终打开.

### 简介:
WebSocket的最大特点就是，**服务器可以主动向客户端推送信息,客户端也可以主动向服务器发送信息**，是真正的双向通信，属于服务器推送技术的一种。

WebSocket的其他特点:
1. 建立**在 TCP 协议**之上，服务器端的实现比较容易。
2. 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。
3. 数据格式比较轻量，性能开销小，通信高效。
4. 可以发送文本，也可以发送二进制数据。
5. 没有同源限制，客户端可以与任意服务器通信。
6. 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL.

### WebSocket出现之前的即时通讯方式:
1. **定期轮询:**
	- **客户端按照某个时间间隔不断地向服务端发送请求**，请求服务端的最新数据然后更新客户端显示。这种方式实际上**浪费了大量流量并且对服务端造成了很大压力**。
2. **SSE(Server-Sent Event,服务器推送事件):**
	- SSE是一种允许服务端向客户端推送新数据的HTML5技术.

# 面试题总结:
## 1. 表总结:
### employee表:
![[Pasted image 20241009170520.png]]
**主键id**,姓名,**用户名(unique)**,密码,电话号码,性别,状态,创建时间和修改时间.

### Catagory表:
![[Pasted image 20241009170708.png]]
利用type的值来区分是菜品还是套餐(0是菜品,1是套餐).
### shopping_cart表:
![[Pasted image 20241009183137.png]]
保存的是购物车中的菜品,当需要查询某个用户的购物车时,可以通过`listById()`来实现.

### address_book表:
![[Pasted image 20241009183849.png]]
### orders订单表:
![[Pasted image 20241009184509.png]]
![[Pasted image 20241009211945.png]]
### order_detail订单明细表:
![[Pasted image 20241009184455.png]]
## 2. 你的Redis主要的应用场景是什么?
**缓存逻辑分析：**
- **每个分类下的菜品保存一份缓存数据**
- 数据库中菜品数据**有变更时清理缓存数据**

![[Pasted image 20241009182953.png|400]]
- key名设计遵循`业务前缀:分类id`. (**业务前缀使用常量类来定义,避免出错.**)
	由阿里云Redis开发规范可知: Key的设计要遵循几个原则:
	1) **可读性+可管理性**:以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如`业务名:表名:id`
	2) **简洁性:** `user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}`,当key太大时,内存占用不可忽视.
	3) **不要包含特殊字符:** 
```java
//构造redis中的key，规则：dish_分类id
String key = "dish_" + categoryId;
```
Redis主要用于需要展示的菜品. 因为如果用户访问量比较大,那么全都查询数据库,数据库的压力会很大，因此我们将需要展示的菜品缓存到Redis中，在需要展示菜品时，就首先从Redis中查询，减小了数据库的压力！
![[Pasted image 20241009181231.png]]

查询菜品时，先查询Redis，若Redis不存在该数据，再去查询数据库。
修改菜品时，需要清理缓存，保证数据库和Redis中的数据一致性。然后在用户下次访问时，查询数据库，然后返回数据，同时将数据写入Redis中。

## 3. 你的SpringCache的使用场景是什么？

## 4. 考虑过商品超卖问题吗?


## 5. jwt验证流程

![[Pasted image 20241009165022.png]]
首先,用户登录时发起请求,登录成功后会生成jwt令牌.后端会返回jwt token给前端,前端会将令牌保存起来,并在后续的请求中都携带该令牌.后续的请求会被拦截器拦截,然后解析token,并存入ThreadLocal中,便于后续的使用.
## 6. ThreadLocal是什么?
ThreadLocal是一个线程内的局部变量,为每个线程提供一份单独的存储空间,具备线程隔离的效果,只有在该线程内才能获取到其中的值,线程外则无法访问.
## 7. 如何实现的公共字段填充？
首先是在菜品分类中，用户表中，都有创建时间和更新时间，创建人id和修改人id的字段，这些字段可以抽取出来进行统一处理，减少代码的冗余。
**实现思路：** 
- 首先我自定义了一个注解`@AUTOFILL`，用于标识需要实现自动填充的方法。
- 其次是需要更新的时候也就是INSERT和UPDATE操作，查询是不需要更新的。所以我定义了一个枚举类，用于标识是INSERT还是UPDATE。
- 自定义了切面类AutoFillAspect，**统一拦截加入了AutoFill注解**的方法，通过反射为公共字段赋值.
	- 具体而言,在切面类中**定义切点,用于定义哪些连接点会被拦截并应用通知**.
	- 然后是前置通知,在通知中**通过方法签名和注解中的标识类型**来判断要执行什么方法,最后就是在方法内对字段进行赋值了!
```Java
package com.sky.aspect;

/**
 * 自定义切面，实现公共字段自动填充处理逻辑
 */
@Aspect
@Component
@Slf4j
public class AutoFillAspect {

    /**
     * 切入点
     */
    @Pointcut("execution(* com.sky.mapper.*.*(..)) && @annotation(com.sky.annotation.AutoFill)")
    public void autoFillPointCut(){}

    /**
     * 前置通知，在通知中进行公共字段的赋值
     */
    @Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint){
        /////////////////////重要////////////////////////////////////
        //可先进行调试，是否能进入该方法 提前在mapper方法添加AutoFill注解
        log.info("开始进行公共字段自动填充...");

    }
}
```

```Java
/**
 * 自定义切面，实现公共字段自动填充处理逻辑
 */
@Aspect
@Component
@Slf4j
public class AutoFillAspect {

    /**
     * 切入点
     */
    @Pointcut("execution(* com.sky.mapper.*.*(..)) && @annotation(com.sky.annotation.AutoFill)")
    public void autoFillPointCut(){}

    /**
     * 前置通知，在通知中进行公共字段的赋值
     */
    @Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint){
        log.info("开始进行公共字段自动填充...");

        //获取到当前被拦截的方法上的数据库操作类型
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();//方法签名对象
        AutoFill autoFill = signature.getMethod().getAnnotation(AutoFill.class);//获得方法上的注解对象
        OperationType operationType = autoFill.value();//获得数据库操作类型

        //获取到当前被拦截的方法的参数--实体对象
        Object[] args = joinPoint.getArgs();
        if(args == null || args.length == 0){
            return;
        }

        Object entity = args[0];

        //准备赋值的数据
        LocalDateTime now = LocalDateTime.now();
        Long currentId = BaseContext.getCurrentId();

        //根据当前不同的操作类型，为对应的属性通过反射来赋值
        if(operationType == OperationType.INSERT){
            //为4个公共字段赋值
            try {
                Method setCreateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class);
                Method setCreateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER, Long.class);
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                //通过反射为对象属性赋值
                setCreateTime.invoke(entity,now);
                setCreateUser.invoke(entity,currentId);
                setUpdateTime.invoke(entity,now);
                setUpdateUser.invoke(entity,currentId);
            } catch (Exception e) {
                e.printStackTrace();
            }
        }else if(operationType == OperationType.UPDATE){
            //为2个公共字段赋值
            try {
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                //通过反射为对象属性赋值
                setUpdateTime.invoke(entity,now);
                setUpdateUser.invoke(entity,currentId);
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}
```
## 8. payload中的信息会被解密吗?

## 9. 密文密码能被存入负载中吗?

## 10. ==WebSocket的作用?==
使用WebSocket主要是**实现了管理端页面和服务端保持长连接状态**,当用户下单或点击催单功能时,都会调用WebSocket相关API实现服务端向客户端推送消息!

**具体实现:**
**在OrderServiceImpl中注入WebSocketServer对象，修改paySuccess方法，加入如下代码：**
- 用户支付成功后,调用WebSocket的相关API实现服务端向客户端推送消息;
- 获取相关信息,向客户端浏览器发送JSON字符串;
- 客户端浏览器解析JSON字符串,判断是来单还是催单,执行对应功能.
``` hl:7
Map map = new HashMap();
map.put("type", 1);//消息类型，1表示来单提醒
map.put("orderId", orders.getId());
map.put("content", "订单号：" + outTradeNo);

//通过WebSocket实现来单提醒，向客户端浏览器推送消息
webSocketServer.sendToAllClient(JSON.toJSONString(map));
```

**在OrderServiceImpl中实现reminder方法：**
用户点击催单,发送GET请求.
```
//基于WebSocket实现催单
Map map = new HashMap();
map.put("type", 2);//2代表用户催单
map.put("orderId", id);
map.put("content", "订单号：" + orders.getNumber());

webSocketServer.sendToAllClient(JSON.toJSONString(map));
```

- **WebSocket介绍:**
	WebSocket 是基于 TCP 的一种新的**网络协议**。它实现了浏览器与服务器**全双工通信**——浏览器和服务器**只需要完成一次握手**，两者之间就可以创建**持久性**的连接，并进行**双向**数据传输。
	
	**HTTP协议和WebSocket协议对比：**
	-  HTTP是**短连接**
	-  WebSocket是**长连接**
	-  HTTP通信是**单向**的，基于请求响应模式
	-  WebSocket支持**双向**通信
	-  HTTP和WebSocket底层都是TCP连接
	
	**WebSocket缺点：**
	- 服务器长期维护长连接需要一定的成本
	- 各个浏览器支持程度不一
	- WebSocket 是长连接，受网络限制比较大，需要处理好重连
	**结论：** WebSocket并不能完全取代HTTP，它只适合在特定的场景下使用
	
	**应用场景:** 视频弹幕, 网页聊天,体育实况,股票基金报价实时更新.
## 11. 你是如何校验收货地址是否超出配送范围的?

## 12. SpringTask定时任务.
1. 使用SpringTask实现每分钟检查一次支付超时订单,并将订单状态修改为"已取消";
2. 使用SpringTask实现每天凌晨定时检查是否存在"派送中"订单,将派送中订单修改为"已完成".

**具体怎么实现的?**
1. 引入SpringTask定时任务包,然后在启动类上加入@EnableScheduling开启任务调度;
2. 创建定时任务类,在里面实现业务逻辑,具体就是针对上面两种定时任务,添加两个实现逻辑的方法(具体的操作交由Mapper层实现),加上@Scheduled(Cron="")注解,同时加上Cron表达式,用来指示什么时候执行该方法.

>**cron表达式:**

`秒 分 时 日期 月份 星期 [年份]`
`*`:匹配任意值,例如在字段月中,`*`表示每个月;
`?`:不指定值,**仅适用于日期和星期**.当字段`日期`或`星期`其中之一被指定了值以后，为了避免冲突，需要将另一个字段的值设为`?`。
`,`:列出枚举值.
`/`:指定数值的增量.在字段`分钟`中，`0/15`表示从第0分钟开始，每15分钟。在字段`分钟`中`3/20`表示从第3分钟开始，每20分钟。
`-`:指定范围。|在字段`分钟`中，`5-20`表示从5分钟到20分钟之间每隔一分钟触发一次。

|                                 |                      |
| ------------------------------- | -------------------- |
| 每天上午10:15执行任务                   | `0 15 10 ? * *`      |
| 每天中午12:00执行任务                   | `0 0 12 * * ?`       |
| 每天上午10:00点、下午14:00以及下午16:00执行任务 | `0 0 10,14,16 * * ?` |
| 每天14:00开始,每隔5分钟执行一次.            | `0 0/5 14 * * ?`     |

