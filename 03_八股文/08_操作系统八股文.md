## 1. 计算机打开电源，操作系统做了什么？
1. 加载BIOS：插上电源时，主板的BIOS开始工作。BIOS会进行POST（Power-On Self-Test）自检，检测硬件是否正常；
2. 加载引导程序：自检完成后，BIOS会从预设的启动设备（硬盘、光盘等）加载操作系统的引导程序；
3. 初始化内核：引导程序会进一步加载操作系统内核和文件系统等组件，内核是操作系统的核心组件，负责管理计算机的各个部分、处理系统调用和线程调度等。一旦内核被找到并加载，操作系统就开始初始化内核，并设置必要的数据结构和内核变量。
4. 加载设备驱动程序：设备驱动程序时操作系统中的一部分，负责控制计算机中的各种硬件设备，如硬盘、显卡、网卡等。操作系统会加载设备对应驱动，以保证硬件设备的正常工作。
5. 启动系统服务：上述操作完成后，会启动系统服务，如网络服务、防火墙服务等，以满足计算机在不同环境下的需求。

## 2. 同步、异步、阻塞、非阻塞怎么理解？
同步、异步描述的是被调用方：
- 同步：被调用方B接收到A的请求后，需要立即处理；
- 异步：被调用方B接收到A的请求后，不必立即执行，但会保证执行，可在做好之后通知A。

阻塞、非阻塞描述的是调用方：
- 阻塞：调用方A发起调用后，需要一直等待B返回结果；
- 非阻塞：不必一直等待B返回结果。
## 3. ⭐什么是AIO、BIO和NIO？
#### BIO（同步阻塞模型）
Blocking I/O，同步阻塞I/O模型。线程发起IO请求后，**一直阻塞，直到缓冲区数据就绪后**，再进入下一步操作。
#### NIO（同步非阻塞模型）
Non Blocking I/O，同步非阻塞I/O。线程发起IO请求后，不需要阻塞，立即返回。用户线程不原地等待IO缓冲区，可以先做一些其他操作，只需要**定时轮询检查IO缓冲区数据是否就绪**即可。
#### AIO（异步非阻塞模型）
Asynchronous I/O，异步非阻塞I/O模型。线程发起IO请求后，不需要阻塞，立即返回，也不需要定时轮询检查结果，**异步IO操作之后会回调通知调用方**。

>注意：没有异步阻塞模型，想想，都异步了还阻塞等待，那不是浪费时间？

![[Pasted image 20241216161021.png|500]]

## 4. ⭐什么是IO多路复用？
核心思想：让单个线程去监视多个连接，一旦某个连接就绪，触发读写事件，就会通知对应的应用程序去**主动获取就绪的连接**进行读写操作。也就是，在应用程序内可以**实现单个线程同时处理多个客户端连接**，在对系统资源消耗较小的情况下，去提升服务端的连接处理数量。

## 5. ⭐SELECT、POLL和EPOLL有什么区别？
三者都是**Linux系统内提供的IO多路复用机制的实现**，他们能够同时监听多个文件描述符，当任意一个文件描述符就绪时，能够**非阻塞地读写数据**。其中select和poll是**基于轮询的方式**实现，而epoll是**基于事件驱动**的方式实现的。 

**区别1：性能差距**
- 由于select和epoll是**基于轮询**实现的，内核需要不断检查每个文件描述符的状态，因此性能会随着文件描述符数量线性下降；
- epoll是**基于事件通知**的，只需要监控状态变化，不需要遍历整个描述符集合，性能和文件描述符数量无关。

**区别2：**
- select使用固定长度的BitsMap表示文件描述符集合；poll使用动态数组来存储文件描述符，并且多个动态数组以链表的形式连接。二者都使用**线性结构**存储所文件描述符，因此随着连接数变多，性能也会有很大损耗！
- epoll使用红黑树来存储所有待检测的文件描述符，还维护了一个链表用来记录就绪时间。当有事件发生时，就会通过回调函数将其加入到就绪事件列表中，用户调用`epoll_wait()`函数，只会返回链表中的就绪事件，而不会遍历整个socket集合。
## 6. 什么是半双工和全双工？
#### 单工
只允许数据在一个方向传输，通信的一方只能发送数据，另一方只能接收数据。
#### 半双工
数据可以在通信双方双向传输，但不能同时进行。即双方可以交替发送和接收数据。
#### 全双工
数据可以在通信双方双向同时传输。每一方都可以独立地发送和接收数据，并且可以同时进行。
## 7. 为什么工作内存比主存更快？
1. 因为绝大多数运算任务并不能只依靠CPU，还需要与内存进行交互，如读取运算数据、存储运算结果。由于计算机的存储设备与CPU的处理器的运算速度有着几个数量级的差距，所以不得不加入一层或多层读写速度尽可能接近CPU的高速缓存（Cache）来作为CPU与内存之间的缓冲，让运算能快速进行，当运算结束后再从缓存同步会内存中，这样CPU就无需等待缓慢的内存读写了。
2. Cache比内存快的几个原因：
	1. **物理位置差异**：
		- Cache位于CPU内部或紧邻CPU，与内存相比，CPU访问Cache所需要的传输距离更短，因此传输时间更少，延迟更低。而内存位于CPU外部，需要通过总线方法，路径更长。
	2. **存储介质差异**：
		- Cache使用SRAM结构，内存使用DRAM结构，前者读写速度更快；
	3. **局部性原理**：
		- **时间局部性**：CPU倾向于重复访问近期使用过的数据，而Cache会缓存这些数据。
		- **空间局部性**：CPU可能访问相邻数据，而Cache会预存相邻内存块。

Java中的工作内存是一个逻辑概念，可能由CPU Cache或者寄存器实现。那么`为什么工作内存快`就可以转变为 =》`为什么Cache更快`

## 8. 什么是内核态和用户态？
#### 内核空间和用户空间
- 内核空间提供了访问硬件资源的能力；

#### 为什么要分两种状态？
为了保护系统的稳定性和安全性，操作系统将运行在不同的特权模式下，即内核态和用户态。

内核是操作系统的核心，负责管理和控制计算机硬件资源，提供系统级服务。假设所有进程都能直接访问硬件资源，可能会导致系统崩溃、数据丢失等问题。因此，操作提供将应用程序和系统内核进行了隔离，分为内核态和用户态，确保不同状态下具有不同的权限，以保证系统的稳定性和安全性。

#### 内核态
操作系统运行在特权模式下的状态，此时具有最高权限，可以访问所有的硬件资源和底层系统资源，如处理器、内存、I/O等。内核态下，系统可以执行所有指令，不受访问权限的控制。

#### 用户态
是指应用程序运行在非特权模式下的状态，此时应用程序只能访问被授权的资源，不能直接操作硬件资源和底层系统资源。

用户态下，应用程序只能执行一些受限的指令集，不能直接执行特权指令。当需要访问系统资源时，需要通过系统调用的方式切换到内核态，请求操作系统提供服务。
#### 如何切换？
二者之间的切换是通过操作系统内核提供的中断或异常机制实现的。有时，应用程序可能需要进行一些系统调用，如读写文件等IO操作，此时就会触发用户态向内核态切换。此时，CPU会暂停当前进程的执行，保存当前进程的状态并切换到内核态执行相应操作。操作执行完毕后，再将控制权切换回用户态，恢复进程的执行。

## 9. 软链接和硬链接的区别是什么？
#### 软链接
软连接可以理解为一个"快捷方式"，本身是一个特殊的文件，存储的内容是目标文件的路径。当访问软连接时，系统会自动跳转到目标文件。
![[Pasted image 20250410100838.png|600]]
相当于重新创建了一个文件，文件有独立的inode，只不过inode的值为另一个文件的路径。
#### 硬链接
硬链接可以理解为"同一个文件的不同名称"。与原文件共享相同的`inode`号，因此它们实际上是同一个文件，数据存储在同一个位置。硬链接和原文件共享同一个inode和数据块。不占用额外存储空间，只是增加一个目录结构。
![[Pasted image 20250410100440.png|600]]
**多个目录项指向同一个inode，只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。**
#### 文件的组成
文件由多个部分组成，例如
- **数据内容（Data Blocks）**
- **元数据（MetaData，存储在inode中）**
- **文件名（存储在目录结构中）**
- 权限信息
- 时间信息
- 扩展属性
![[Pasted image 20250410093933.png]]
#### `inode`
文件是通过`inode`进行管理的。创建一个文件时，系统会为文件分配一个`inode`，用于记录文件的各种信息（不包括文件名）。所以，可以认为`inode`（索引节点）是文件的身份信息，用于存储文件的元数据。每个文件都有唯一的`inode`号，指向文件存储的数据块。

inode主要存储以下信息：
- 文件类型（普通文件、目录或符号链接等）
- 权限（r、w、x）
- 文件所有者
- 文件所属组
- 文件大小
- 创建时间、修改时间、访问时间
- **硬链接数（count）**
- 文件数据所在的磁盘块指针；
- **inode号**（唯一标识该文件）

inode不存储文件名，文件名存储在目录结构中，目录本质上是文件名到inode号的映射。
## 10. IO多路复用和多线程有什么区别？
- IO多路复用主要是提升I/O操作的效率和利用率，适合IO密集型应用；
- 多线程则是提升CPU利用率的方法，所以适合CPU密集型应用。

#### IO多路复用
IO多路复用允许单个线程同时监控多个IO请求。当使用epoll、poll、SELECT等系统调用时，线程可以在不阻塞的情况下，检查多个IO流的状态，并在数据真正准备好时才进行处理。

优点：
- 减少多线程上下文切换的开销；
- 使得单个线程能够高效管理多个并发网络连接。
#### 多线程
多线程允许一个进程并发运行多个线程，每个线程可以独立执行任务。使用多线程能够充分利用多核CPU优势，在处理长时间计算的任务时，可以显著提高效率。

## 11. 进程间通信方式有哪些？
#### 管道
半双工通信方式，数据传输只能是单向的。若要进行双向通信，则需要建立两个管道。

优点：
- 实现简单，进程可以得知数据是否已经被另一个进程读取。

缺点：
- 通信效率低，不适合大量频繁的数据交换。
#### 消息队列
消息队列是保存在内核态中的消息链表，进程可以通过发送和接收消息来进行通信。

优点：
- 适用于进程间传递数据量较大的情况。

缺点：
- 存在内核态和用户态之间的数据拷贝开销。
- 不适合态度
#### 共享内存
通过多个进程访问同一块内存区域来实现数据共享。

优点：
- 共享内存，无需进行数据拷贝，因此通信速度很快。

缺点：
- 需要进行同步和互斥操作，有可能发生数据覆盖问题。
#### 信号量
一个整型计数器，用于实现进程间的互斥和同步。主要用于保护共享资源，防止多进程同时访问导致的数据错乱。

信号量有两个操作：
- P操作是对信号量减去1，用于访问资源时进行。若减1后信号量`<0`，说明资源已被占用，需要阻塞等待；若减1后信号量`>=0`，说明资源空闲，可以使用。
- V操作是对信号量加1，用于离开资源时进行。若加1后信号量`<=0`，说明有线程在阻塞等待，则需要唤醒资源；若加1后信号量`>0`，说明此时无线程等待，直接释放资源即可。

通过将信号量初始值设置为1，称为互斥信号量，可以保证同一时刻只有一个线程访问资源。

若将信号量初始值设置为0，称为同步信号量，进程A只进行V操作，进程B只进行P操作。这样只有进程A生成消息后执行V操作，进行B才能实现P操作对资源进行消费，实现了进程A在进程B之前执行。
#### 套接字`socket`
通过网络进行进程间通信。通过TCP/UDP协议实现。
## 12. 进程，线程和协程的区别是什么?

#### 进程
进程具有一个独立的执行环境。进程是系统进行资源分配和保护的基本单位，进程拥有一个完整、基本运行资源集合。每个进程都有自己的内存空间。

#### 线程
线程是处理器调度和分配资源的基本单位。线程是在进程中存在的，一个进程含有多个线程。线程具有以下特点：
- 线程之间共享进程的资源，包括内存和打开的文件。线程之间的通信不用进行系统调用，更节约时间。
- 线程是资源调度的基本单位。

#### 协程
协程是用户态的线程，调度由应用程序决定，不涉及内核态，也就无需进行线程上下文的切换。

总的来说，协程的出现，让用户能自己决定什么时候进行协程切换，而不是让操作系统进行抢占式调度，减少了多线程竞争CPU资源引起的不必要的资源浪费。
## 13. 零拷贝是什么？
传统的文件传输，需要进行用户态和内核态之间的多次切换和数据拷贝。（4次上下文切换和4次数据拷贝）
![[Pasted image 20250403100435.png|550]]
因此，为了提升文件传输性能，就需要减少上下文切换和内存拷贝的次数：
- 减少上下文切换：通过减少系统调用次数；
- 减少内存拷贝：由于用户缓冲区实质上不会进行数据加工，因此不必搬运到用户缓冲区。
#### `mmap + write`
调用`read()`函数，会请求将数据从内核缓冲区拷贝到用户缓冲区，因此通过mmap技术将数据从内核缓冲区映射到用户空间，而不进行拷贝操作。

具体过程如下：
1. 用户调用`mmap()`，DMA会将数据从磁盘拷贝到内核缓冲区，此时用户与内核共享缓冲区；
2. 此时用户再调用`write()`，操作系统会直接将数据拷贝到`socket`缓冲区；
3. 最后，再通过DMA拷贝将socket缓冲区中的数据拷贝到网卡的缓冲区。
![[Pasted image 20250410104600.png|600]]
综上，一共进行4次上下文切换和3次数据拷贝（减少了内核缓冲区到用户缓冲区的拷贝）。
#### `sendfile`
`sendfile()`是专门发送文件的系统调用函数，可以替代`read()`和`write()`两个系统调用，从而减少2次上下文切换。
并且，可以将内核缓冲区的数据直接拷贝到`socket`缓冲区，不再拷贝到用户态。
![[Pasted image 20250410104816.png|600]]
此时，只需要2次上下文切换和3次数据拷贝（相比于mmap，减少了`read()`和`write()`这两个上下文切换）。
#### `sendfile + SG-DMA`
 SG-DMA（_The Scatter-Gather Direct Memory Access_）技术，可以直接将数据从内核缓冲区拷贝到网卡，而无需经过socket缓冲区，因此能减少1次数据拷贝。

具体过程：
1. 用户调用`sendfile()`，通过DMA技术将数据从磁盘拷贝到内核内核缓冲区；
2. 缓冲区描述符和数据长度传到socket缓冲区，这样网卡的SG-DMA控制器就可以直接将内核缓存的数据拷贝到网卡缓冲区；（无需将内核拷贝到socket）。
![[Pasted image 20250410105207.png|600]]
只需要2次上下文切换（`sendfile`的两次）和2次数据拷贝（磁盘到内核、内核到网卡）。

这就是最终版零拷贝技术，**不通过内存层面进行数据拷贝，无需CPU参与数据搬运，全程通过DMA技术实现数据传输**。
#### DMA是什么？
DMA出现之前的数据传输过程：
![[Pasted image 20250410101804.png|600]]
整个过程都需要CPU亲自参与进行数据的搬运，此时CPU被占用，不能进行其他操作，导致性能很低。

因此有了直接内存访问（Direct Memory Access）技术，可以**在I/O设备和内存的数据传输过程中，将数据搬运工作交给DMA控制器，而CPU不再参与任何与数据搬运相关的事情**。
![[Pasted image 20250410102017.png|800]]
**CPU 不再参与「将数据从磁盘控制器缓冲区搬运到内核空间」的工作，这部分工作全程由 DMA 完成**。

## 14. 操作系统的多级缓存是什么？
#### 出现背景
计算机执行程序时，命令都是CPU执行的，并且一般需要操作数据，也就是是与主存进行交互。由于CPU执行速度快，与主存交互慢，二者速度差距大，导致了每次CPU每次操作都会耗费很长时间。

因此，在CPU和内存之间添加了高速缓存，保存一份数据拷贝，以提高操作数据的速度。

引入缓存后，程序的执行过程：【先复制到缓存中，再交互，结束后再刷回主存】
- 程序运行过程中，会将运算所需的数据从主存复制一份到CPU的高速缓存中，那么CPU进行计算时就可以从高速缓存读取数据并向其中写入数据，运算结束后，再将高速缓存中的数据刷新到主存当中。

随着CPU能力提升，一级缓存无法满足要求，因此衍生出多级缓存。按照数据读取顺序和与CPU结合的紧密程度，可划分为一级缓存、二级缓存、三级缓存，**每一级存储的全部数据都是下一级缓存的一部分**。

引入多级缓存后，程序的执行过程：
- CPU读取数据时，先从L1读取、再从L2读取、最后再从L3或者主存中读取。

单核CPU只含有一套L1、L2和L3缓存；对于多核CPU，每个核心都含有一套L1、L2缓存，多个核心共享一个L3缓存。
![[Pasted image 20250422013434.png]]
## 15. 什么是MESI缓存一致性协议？
主要用于解决多级缓存中的缓存一致性问题。

早期通过在总线加LOCK#锁的方式来解决，但这样只有一个CPU能使用这个变量的内存，导致效率低下，因此需要MESI缓存一致性协议来解决。
#### MESI缓存一致性协议
MESI协议保证了每个缓存中使用的共享变量的副本是一致的。

MESI的核心思想是：
- 当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，就会发出信号通知其他CPU将该变量的缓存行设置为无效状态。之后当其他CPU读取自己缓存中的无效变量后，就会需要从主存中重新读取。

MESI分别代表着缓存的4种不同的状态：
- M（Modified）：数据有效，但数据被修改了，和内存中的数据不一致，只存在于本Cache中；
- E（Exclusive）：数据有效，且和内存中的数据一致，数据只存在于本Cache中；
- S（Shared）：数据有效， 且和内存中的数据一致，数据存在于多个Cache中；
- I（Invalid）：数据无效。

读取缓存中的数据时，根据数据的状态不同，会执行不同操作：
- Exclusively和Shared，会直接从缓存中读取数据，因为此时是有效数据；
- Modified，此时数据被修改，但更新还未刷到主存中，因此需要先刷到主存中，再从主存中读取数据；
- Invalid，数据无效，需要从主存中读取最新数据到缓存中，并设置状态为Exclusive或Shared。
##### 为什么Modified状态还需要先写回主存？
1. 要保证其他CPU能读取到最新的数据；
2. 若数据未被及时写回主存，可能会导致缓存行呗其他数据覆盖或清除，导致修改丢失。
## 16. 什么是负载Load？``
负载Load是Linux机器的一个重要指标，反应了机器当前的状态。
``
系统负载是对当前CPU工作量的度量，定义为**特定时间间隔内运行队列中的平均队列数**。

Linux的负载高，主要是由于CPU的使用、内存使用和IO消耗三部分构成，任意一项过高都会导致负载升高。

### 如何查看负载？
#### uptime命令

#### w命令

#### top命令

## OS的进程调度算法有哪些？
#### FCFS-先进先出

#### SJF-短作业优先
#### 五种手粗