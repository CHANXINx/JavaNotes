# <font color="#245bdb">MySQL基础</font>
## 1. SQL和NOSQL的区别?
> [!abstract] 摘要
> 1. 存储方式不同

前者是关系型数据库，常见的有MySQL、Oracle、SQL Server等。关系型数据库存储结构化数据，逻辑上以二维列表存在，每一行代表一个数据记录，每一列代表一个数据属性。

后者是非关系型数据库，常见的有Redis、MongoDB等，存储方式可以是JSON文档、哈希表等方式。

## 2. 数据库三大范式是什么?
>[!abstract] 摘要
>1. 原子性；2. 每条记录都可被唯一区分；3. 字段不相互依赖。
1. 数据库表每一列都不可再分，具有原子性，例如地址，可以拆分为省份、市区等。
2. 数据库表中的每个实例或记录都可被唯一区分，即需要有主键。
3. 任何非主属性不依赖于其他非主属性，即非主键外字段必须互不依赖。

**反范式**：例如冗余字段，虽然违反了第三范式，使得非主键外的其他字段形成了相互依赖，但是这样避免了联表查询，用空间换时间，提高了查询效率。


## 3. Char和Varchar的区别?
> [!abstract] 摘要
> 1. 定长与非定长；
> 2. 丢失空格信息。

### char类型:
char是固定长度的字符串类型，定义时指定长度，存储时会在末尾补空格来填充至指定长度。
**优点：** 
1. 适合存储固定长度的数据，例如身份证等。
2. 无需额外的磁盘空间来存储长度信息；
3. **不会产生内存碎片**

**缺点：**
1. char类型会导致末尾空格数据丢失，如`"chanxin   "`会被填充至`"chanxin        "`，导致无法获取原本有几个空格；
2. 会浪费存储空间。
### varchar类型
varchar是可变长度的字符串类型，定义时需要指定最大长度。存储占用空间取决于字符串实际长度。
**优点：**
1. 节约存储空间；

**缺点：**
1. **会产生内存碎片。**
	- varchar(100)，假设存储的数据为51字节（包括50字节的字符串与1字节的长度信息），那么当该数据更新了，导致占用内存增加了，但是此时数据页无法扩展出新空间所以无法覆盖到原来位置，就会发生页分裂。
2. 需要额外1~2个字节(超过255字节则需要2个字节)来存储数据长度信息。
## 4. 什么是隐式类型转换？
当不同数据类型的值进行运算或比较时，会发生隐式数据类型转换。

## 5. 说一下外键约束。
> [!abstract] 摘要
> 1. 是什么？
> 2. 作用：维护一致性和完整性。

外键是用于建立表之间关系的，定义了**表中的某一列或某几个列，这些列的值必须在另一个表中作为主键出现**。作用是维护表中的数据一致性和完整性。

**一致性：** 向表中插入的数据，必须在另一张表中也存在。
**完整性：** 级联删除。

## 6. 为什么不推荐使用外键?
> [!abstract] 摘要
> 1. 需要额外检测；
> 2. 不适用于分库分表。

1. **性能问题**：每次执行DML语句都需要额外检测外键约束的完整性，降低了更新性能；
2. **无法适应分库分表**：分库分表环境中，数据存在于不同的数据库中，外键难以跨越数据库来建立关系。并且，分库分表环境中，数据的一致性更难维护。

## 7. 执行一条SQL请求的过程是什么?
> [!abstract] 摘要
> 1. 连接与鉴权；
> 2. 缓存；
> 3. 解析与预处理；
> 4. 优化；
> 5. 执行。

1. **连接与鉴权**：使用**连接器**，通过客户端/服务器通信协议与MySQL建立连接，并查询判断是否有权限；
2. **缓存**：在MySQL8.0之前，还会查询是否开启缓存，若开启且命中缓存，则直接返回查询结果；
3. **解析与预处理**：由**解析器**进行词法与语法分析，并生成解析树。**预处理器**会根据MySQL规则进一步分析解析树是否合法，如**表或列是否存在**。
4. **优化**：由**优化器**来生成执行计划，并根据索引看看是否能优化，选择查询成本最小的计划。
	- 执行EXPLAIN语句获取的就是执行计划。
5. **执行**：**执行器**来**操作存储引擎执行SQL语句**，获得查询结果并返回。同时，若开启缓存，在返回前还会将结果存储于缓存中。
## 8. 一条update语句是如何执行的?
1. **查询**：首先查询缓冲池buffer pool，判断需要查询的数据是否在缓冲池的内存页中；若在，则直接进行查询，若不在，则需要从磁盘中中读取内存页到缓冲池中；
2. **写Undo log**：在修改操作前，将旧数据写入undo log中，以便后续事务失败时进行回滚获取原数据。undo log是先写入到内存中，后续由Purge线程定时刷新到磁盘中（进行清理）。
3. **更新**：更新buffer pool中的数据，此时数据所在的内存页也被标记为脏页；后续会由Page Cleaner Thread刷脏页，将脏页数据持久化到磁盘中。
4. **写bin log**：至此，更新操作执行完毕，然后会将修改写入binlog，并保存到binlog cache中；（此时尚未持久化到磁盘中）
5. **两阶段提交**：最后是事务的两阶段提交：①写redo log，并将其标记为准备阶段；②然后是将binlog持久化到磁盘中；③最后是写redolog，将redo log持久化到磁盘中并标记为commit状态。

## 9. SQL语句如何实现insertOrUpdate功能?

使用`INSERT INTO ... ON DUPLICATE KEY UPDATE;`，如果数据库中已存在具有相同主键或唯一索引的记录，则更新记录，否则插入记录。

**需要满足以下条件：**
1. 表必须有主键或唯一索引；
2. 插入的数据必须包含主键或唯一索引列；
3. 主键或唯一索引列的值不能为 NULL。

**举例：**
```SQL
INSERT INTO student (id, name, age) VALUES (1, 'Alice', 20)
ON DUPLICATE KEY UPDATE name='Alice', age=20;
```

**实现原理：**
1. 首先尝试插入新行，在插入过程中会检查表中是否存在与新插入的数据相同的主键或者唯一索引；
2. 若无，则直接插入新记录；若存在冲突，则执行更新操作；
3. 根据`ON DUPLIACATE KEY`后面的字段与对应值执行更新操作。

## 10. 说说SQL的语法树解析。
语法树（或抽象语法树，AST）是 SQL 解析过程中的中间表示，它**使用树形结构表示 SQL 语句的层次和逻辑**。

**构成：**
- 根节点：SQL语句的操作，SELECT、UPDATE、DELETE、INSERT等；
- 内部节点：操作符、子查询、连接操作等，如WHERE子句、JOIN操作等
- 叶子节点：具体的标识符，常量、列名、表名等，

## 11. 介绍MySQL的三种存储引擎
> [!abstract] 摘要
> 1. 三种引擎；（发音：My-i-Sam)
> 2. 事务、锁的粒度、外键；
> 3. （可补充）行数保存、清空方式。

|          |     InnoDB     |    MyISAM     |     |
| :------: | :------------: | :-----------: | :-: |
|  **事务**  |       支持       |      不支持      |     |
|  **外键**  |       支持       |      不支持      |     |
| **聚簇索引** |       支持       |      不支持      |     |
| **锁级别**  |   支持行级锁、表级锁    |      表级锁      |     |
| **行数保存** | 不支持<br>需要扫描整张表 | 支持<br>有字段保存行数 |     |
| **清空方式** |      逐行删除      |      重建表      |     |
| **默认版本** |     5.5 之后     |    5.5 之前     |     |
| **全文索引** |    5.6以后支持     |      支持       |     |
InnoDB适合频繁修改以及需要更高安全性的应用；MyISAM则适合查询较多的场景。
## 12. 为什么不建议使用多表join？
因为join使用了**嵌套循环**实现关联查询，因此效率比较低。

**嵌套循环算法：**
- **simple nested loop**：全量扫描两张表作关联；
- **index nested loop**：如果内循环的表中字段有索引，则可以用到索引进行查询然后作关联；
- **block nested loop**：引入buffer，把外循环的一部分结果放到JOIN Buffer中，然后内循环的每一行与buffer数据作比较。因为是基于内存，所以效率更高。

**不用JOIN作关联查询的方法：**
1. **在内存中作关联**：在代码中进行二次查询然后作关联。
2. **数据冗余**：添加冗余字段，避免联表查询。【反范式】![[Pasted image 20241220220334.png]]
![[Pasted image 20241220220156.png]]

## 13. `ORDER BY`是如何实现的？
**查询的SQL语句**：
`select city,name,age from t where city='杭州' order by name limit 1000;`
建立`(city)`索引。
#### 情况一：不能使用索引排序
对于全字段和rowid排序，当出现sort_buffer不足以放入所有数据的情况时，**会借助外部磁盘文件进行归并排序**。
##### 全字段排序：`sort_buffer`空间充足
此时`sort_buffer`空间充足，所以可以将需要查询的三个字段都放入`sort_buffer`中。因此，查询步骤为：
1. 初始化 `sort_buffer`，确定放入 `name、city、age` 这三个字段；
2. 从`city`索引中找到第一个满足`city = '杭州'`的记录的主键id；
3. 回表，到主键索引中取出整行，将需要查询的三个字段的值都放入`sort_buffer`；
4. 持续在`city`索引中获取，直到出现`city != '杭州'`；
5. 此时`sort_buffer`中即为满足所有`city =  '杭州'`的记录，按照name进行**快速排序**；【
6. 取出前1000条记录返回。
##### rowid排序：  `sort_buffer`空间不充足
`sort_buffer`空间不充足，内存不足以放入所有数据量，因此会**借助磁盘临时文件辅助排序**。此时就不会将需要查询的三个字段都放入`sort_buffer`，而是仅将`主键id`和需要排序的`name`字段放入`sort_buffer`中。此时查询流程为：
1. 初始化 `sort_buffer`，确定放入 `name`和`主键id` 两个字段；
2. 在`city`索引中找出第一个满足`city = '杭州'`的记录的主键id； 
3. 回表，到主键索引中取出整行，将`name`和`id`两个字段放入`sort_buffer`中；
4. 持续在`city`索引中获取，直到出现`city != '杭州'`；
5. 对`sort_buffer`中的数据按照name进行快速排序
6. 取出排序结果的前1000条，根据`主键id`回表查询出所需查询的三个字段的值。

使用`rowid`排序，相比于全字段排序，多了一个排序后根据主键id进行回表查询出所需字段值的过程。因此会多出`{limit}`次回表操作。
#### 情况二：可以使用索引排序
基于上述查询语句，建立`(city,name)`的联合索引。

假设`order by`的字段数据，天然就是递增排序的，那么就无需进行排序。此时查询过程为：
1. 从索引`(city, name)`中找到第一个满足`city='杭州'`条件的主键id；
2. 回表，到主键索引中取出整行记录，取`name, city, age`三个字段的值，作为结果集的一部分返回；
3. 继续在索引`(city, name)`中取下一个记录主键id；
4. 重复步骤2、3，直到满足取了1000条记录，或是出现`city != '杭州'`.

## 14. `limit 0,100`和`limit 10000000,100`一样吗？
>[动手实践！如何解决 MySQL 深度分页问题](https://chat2db.ai/resources/blog/deep-pagination#part-six-summary-and-recommendations)

不一样！后者是典型的深分页问题。
`LIMIT M N`的原理是读取`0~N`条数据，然后舍弃前M条，返回M~N条数据。
#### 为什么会有深分页问题？
1. 深分页问题中，偏移量很大，因此会**扫描大量的索引节点**来定位到偏移量所对应的行。
	- 扫描索引时，由于索引是通过链表连接的，因此必须从索引的起始位置开始扫描，并不支持直接随机跳转到某个偏移量的记录。。
2. 假设有二级索引，在找到主键后会进行**大量回表操作**，性能开销很大！
3. 构建结果集时，还需要处理并丢弃LIMIT前面的行。
#### 优化方案
优化策略的基本思路是**减少不必要的索引扫描和回表操作**，从而提高查询效率。
##### 方案一：`id`做辅助条件
`SELECT * FROM tablexx WHRER id > 9990 limit 10`，利用主键索引可以直接定位到第9900条数据，然后再取出10条。

**缺点**：
- 有局限性，因为需要id是自增的；
- 数据不能被删除，否则会出现数据重复的问题！

##### 方案二：`last_id`辅助分页
`SELECT * FROM tablexx WHERE id > last_id limit 10`，使用上一页的`last_id`作为`where`条件进行辅助分页。

**优点**：
- 使用广泛，适合生产环境。

**缺点**：
- 无法进行跳页，只能允许用户一页一页地翻页。因为若进行跳页，则无法获取上一页的`last_id`，也就无法基于`last_id`做条件了。

##### 方案三：子查询（延迟关联）
在子查询中找到满足条件的ID集合，主查询可以**直接从该ID中检索数据**。
子查询的优化原理实质上就是减少回表操作！主查询直接从子查询的ID集合中检索数据，无需在二级索引中检索数据后再进行回表操作。
```java
SELECT c1, c2, cn...
FROM table
INNER JOIN (
    SELECT id
    FROM table
    WHERE name = "Hollis"
    ORDER BY id
    LIMIT 1000000, 10
) AS subquery ON table.id = subquery.id
```
此时可以针对name建立索引，因此子查询无需回表。而基于子查询的id进行查询，会走主键索引，可以直接定位到

## 15. MySQL一般有几层？能容纳多少数据量？
$存储总记录数=指针数目\times单个叶子节点记录条数$

考虑两层的情况，单页大小（单个节点）为16KB。
- 对于非叶节点，主键大小为bigint（8字节），指针大小默认为6字节，那么单个节点可以存储的指针数为$\frac{16KB\times1024}{14}=1170$ 。
- 对于叶子节点，假设一行记录的大小是1KB，那么1页（1个节点）可以存储16条数据。
- 因此，非叶节点每个指针指向一个叶子节点，则一共可以存储$1170\times16=18720$条数据。
- 则若是三层，可以存储$1170\times1170\times16=21,902,400$条。

## 16. MySQL的更新操作是否会锁表？如何避免？
>[!口语化回答]
>“在MySQL中，更新操作是否会锁表取决于你使用的存储引擎和查询方式。如果用的是InnoDB，它默认采用行级锁，只有在缺乏索引或者执行全表扫描时才可能出现类似表锁的情况；而MyISAM则直接使用表级锁，更新时会锁整张表。为了避免不必要的锁，可以选用InnoDB、确保查询条件有合适的索引、缩短事务执行时间，必要时还可以分批更新或者采用合适的锁策略。”
#### InnoDB存储引擎
- 默认采用行级锁，但是在以下几种情况仍会锁表：
	1. **查询条件缺少索引，导致全表扫描；**
	2. 执行DDL操作，如修改表结构。
#### MyISAM存储引擎
- 默认使用表级锁，更新操作会整张表。

#### 案例
无索引行锁会升级成表锁。`UPDATE stu set name = 'Lei' where name = 'lily';`，因为行锁是针对索引加的锁，而name并非主键，也没有索引，因此此时行锁会升级成表锁。

## 17. UPDATE更新时的加锁情况
![[Pasted image 20250217201151.png]]
#### 加锁的基本原则
1. 原则0：锁是加在索引上的。
2. 原则1：加锁的基本单位是`next-key lock`，且是前开后闭区间。
3. 原则2：查找过程中访问到的对象才会加锁。
4. 优化1：索引上的等值查询，给唯一索引加锁时，next-key lock会退化成行锁。
5. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化成间隙锁。
#### 案例1：【原视频老齐】
![[Pasted image 20250213224206.png]]
id是主键，只有两行数据。
例如在以主键作为条件时
6. 当`where id = 10`更新条件精准匹配时，此时只加行锁，锁该索引值。
7. 当`where id = 12`更新条件无法精准匹配时，此时需要锁定间隙，但不锁定索引值，即锁定`(10,50)`的开区间。
8. 当`where id =  7` 更新条件无法精准匹配时，此时锁定`(-∞,10)`的开区间。 
9. 当`where id >=  8 and id <= 11`范围查询时，会锁定**所有囊括的间隙和索引值**，此时会锁定`(-∞,49)`。 

#### 案例2：【MySQL45讲】
![[Pasted image 20250213231845.png|200]]

##### 1. 等值查询间隙锁
![[Pasted image 20250213231947.png|500]]
- 根据原则1，会加临键锁，加锁范围`(5,10]`；
- 根据优化2，id有索引，且10不满足等值条件，则退化成间隙锁`(5,10)`.
- 综上，最终加锁范围为`(5,10)`，此时尝试插入id=8的数据，会被阻塞。
##### 2. 非唯一索引等值锁
![[Pasted image 20250213232428.png|500]]
- c上没有索引，`lock in share mode`会加读锁。
- 根据原则1，会加临键锁，加锁范围`(0,5]`；
- 由于c是普通索引，因此仍需向右查找，直到碰见`c=10`，因此`(5,10]`也会加临键锁；
- 根据优化2，索引、向右遍历时最后一个值不符合条件，则会退化会间隙锁，因此`(5,10]`退化成`(5,10)`；
- 根据原则2，只有访问到的才会加锁。由于sessionA的查询语句使用了覆盖索引，因此不会锁主键索引。
- 综上，会对索引c加读锁，锁的范围为`(0,10)`，而sessionB不涉及字段(索引)c，因此可以成功；而sessionC会被锁。
##### 3. 主键索引范围锁
![[Pasted image 20250213233258.png|500]]
- 查找到id=10时，会加锁临键锁(5,10]，并根据优化1，等值查询唯一索引加锁时，会退化成行锁，因此只锁`id=10`这一行。
- 查找到id<11时，会加临键锁`(10,15]`。
- 综上，会加行锁和临键锁，锁范围为`[10,15]`。
##### 4. 非唯一索引范围锁
![[Pasted image 20250213234045.png|500]]
- 查找到c=10时，会加锁临键锁(5,10]，由于不是唯一索引，因此不会退化成行锁，所以仍为临键锁`(5,10]`；
- 查找到c<11时，也是加临键锁`(10,15]`.
- 综上，锁的范围为`[5,15]`.
##### 5. 非唯一索引上存在"等值"的例子
新插入一行数据：`insert into t values(30,10,30`，此时存在2个c=10的行，索引C的状态为：
![[Pasted image 20250213235211.png]]
![[Pasted image 20250213235250.png|500]]
- delete语句的加锁逻辑与`SELECT ... FOR UPDATE`一致，即使不涉及主键，也会将主键索引的对应行加锁。
- 

## 18. MySQL通过什么实现高性能和高可用的？TODO
通过MVCC实现高并发性。通过插入缓冲、二次写、自适应哈希索引、预读等实现高性能和高可用。

## 19. MYSQL的缓冲池是什么？
>**参考《InnoDB存储引擎》缓冲池。**
![[Pasted image 20250305135805.png]]
#### 是什么？
因为MYSQL是基于磁盘的数据库，而由于磁盘的读写速度和CPU差距较大（因为要执行寻址等操作），因此使用基于内存的缓冲池，通过内存的速度弥补磁盘的速度来提升整体性能。

**注意**：
- 缓冲池不仅只缓存了数据页和索引页，这两者只是占比很大。还含有AHI自适应哈希索引、数据字典、锁信息、插入缓冲。
- 允许有多个缓冲池存在，并且每个页根据哈希值平均分配到不同的缓冲池实例中，以减少数据库内部的资源竞争，增强并发能力。
#### 如何使用？
**读操作**：
数据库在读取页时，先将磁盘读到的页放到缓冲池中，这个过程称为将页FIX在缓冲池中。后续再读相同的页时，先判断该页是否在缓冲池中，若在，则称该页在缓冲池中被命中，直接读取改页；否则读取磁盘中的页。

**写操作**：
页的修改操作，首先修改缓冲池中的页，此时被修改但未持久化到磁盘中的页被称为“脏页”。脏页会在后续通过Master线程以一定频率刷新到磁盘中，这个过程称为刷脏页。刷脏页操作不是在每次更新进行的，而是通过一种称为Checkpoint的机制刷新回磁盘。

**设置**：
- 用户可以通过参数`innodb_buffer_pool_instances`设置数据库实例数量，默认为1。
- 可以通过
#### 淘汰机制
基于传统LRU算法的改进，加入`midpoint`机制。当有新数据页进来时，不会立刻放入队首，而是放到`midpoint`处，这个算法称为`midpoint insertion strategy`。

采用改进的LRU算法，可以避免在执行某些SQL语句直接将缓冲池中的页被刷出，如某些需要扫描很多页的SQL，而这些SQL又只是本次查询操作需要，并不是活跃的热点数据。这样，就可能将查询很频繁的热点数据被刷出，导致之后的查询又要访问磁盘。

**参数设置**：
- `midpoint`默认在LRU队列的3/8的位置，可以通过参数`innodb_old_blocks_pct`设置，默认值为37（即队列尾端37%）；
- 参数`innodb_old_blocks_time`可用于设置页读取到mid位置后需要多少时间才加入到LRU队列的热端（前63%）
## 20. MySQL的重做日志缓冲是什么？
#### 是什么？
MySQL在写redo log时，会先写入到redo log buffer（重做日志缓冲）中，然后按照一定频率刷新到重做日志文件。

重做日志缓冲一般不需要设置很大，因为一般情况下**每一秒**都会将重做日志缓冲刷新到日志文件中，因此只要保证每秒产生的事务量在缓冲大小之内即可。重做日志缓存可由配置参数`innodB_log_buffer_size`设置，默认为8MB。
#### 什么时候写？
在以下三种情况会将重做日志缓冲刷新到重做日志文件中：
1. **Master Thread 每一秒**将缓存刷到文件中；
2. **每个事务提交**时都会刷到文件中（两阶段提交）；
3. 重做日志缓冲池**剩余空间小于1/2**时，会刷新到文件中。

## 21. MySQL的额外内存池是什么？
在InnoDB存储引擎中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。

## 22. MySQL的数据字典是什么？
>参考：[MySQL :: MySQL 8.4 参考手册 :: 16 MySQL 数据字典 --- MySQL :: MySQL 8.4 Reference Manual :: 16 MySQL Data Dictionary](https://dev.mysql.com/doc/refman/8.4/en/data-dictionary.html)

InnoDB的数据字典是一个内部系统，它为数据库中的所有对象（如表、视图、存储过程等）提供了一个详细的信息目录。

数据字典存储了有关**表结构的信息, 每个表具有的列, 表的索引等**。

MySQL 8 对数据字典进行了重新设计，并且使用InnoDB存储：
1. 将原来存储数据字典的文件全部删除，统一放到数据字典表空间中；
2. 
## 23. MySQL的插入缓冲是什么？（已升级为change buffer）TODO
>参考《InnoDB存储引擎》中的插入缓冲。

>[!abstract]
“Insert Buffer 就是 InnoDB 用来优化二级索引写入的一种机制。当你插入数据时，如果涉及到二级索引的更新而相关索引页不在内存中，InnoDB 不会马上加载这些页，而是把更新先记录到 Insert Buffer 中。等到需要读取这些索引页时，再把缓冲区的修改批量合并到磁盘上的索引中，从而大大减少了随机I/O操作，提高了整体写入效率。”

使用条件：
1. 非主键索引（是辅助索引）；
2. 索引不是唯一的。【不能是唯一的，否则在插入时需要校验唯一性，那么就又会导致发生离散读取】

对于此类索引的插入或更新操作，InnoDB不是每一次都直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放到`Insert buffer`对象中，之后再以一定频率和情况进行`Insert Buffer`和辅助索引页子节点的`merge`操作，此时往往能保证多个插入或更新操作合并到一个操作中（因为在一个索引页），以大大**提高非聚集索引插入的性能**。

#### 什么时候进行merge？
1. 当查询某个索引页，而当前索引页还有缓存未合并时，会先合并再将数据页加载到缓存中；
2. 定期检查，避免buffer占用过多内存。
#### 为什么需要插入缓冲？
对于聚集索引，主键一般是递增的（大多数），此时插入数据时是顺序插入，无需进行磁盘的随机读写，因此速度比较快。
- 注意：若主键是UUID等随机生成的，那么插入数据时仍然可能是非连续的；或者主键是自增的，但插入的ID是随机的。此时这两种情况的性能都比较低。

然而对于非聚集索引，**叶子节点的插入不再是顺序**，此时需要**离散地访问非聚集索引页**，由于**随机读取的存在**而导致了插入操作性能下降。
#### 会引出什么问题？
1. 若发生了大量的插入操作，且都涉及到非聚集索引，就会产生大量的`insert buffer`，此时若数据库宕机而`insert buffer`还未与辅助索引页合并，那么重启恢复就需要很长时间。

## 24. MySQL的Change Buffer是什么？
Change Buffer可以看作insert buffer的升级，能保

## 25. SQL注入是什么？ TODO

## 26. MySQL有几种查询状态？
- `Sleep`：线程正在等待客户端发送新的请求。
- `Query`：线程正在执行查询或者正在将结果发送给客户端。
- `Locked`：在MySQL服务器层，该线程正在等待表锁。在存储引擎级别实现的锁，例如InnoDB的行锁，并不会体现在线程状态中。
- `Analyzing and statistics`：线程正在检查存储引擎的统计信息，并优化查询。
- `Copying to tmp table [on disk]`：线程正在执行查询，并且将其结果集复制到一个临时表中，这种状态一般要么是在做GROUP BY操作，要么是在进行文件排序操作，或者是在进行UNION操作。如果这个状态后面还有“on disk”标记，那表示MySQL正在将一个内存临时表放到磁盘上。
- `Sorting result`：线程正在对结果集进行排序。
## 27. MySQL的能处理的动态优化类型有哪些？
#### 重新定义联接表的顺序
表的连接并不总是按照查询中指定的顺序进行，例如WHERE条件、库表结构等都可能会让一个外联接等价于一个内联接。MySQL能够识别并重写查询，让其可以调整联接顺序。
#### 使用代数等价变换规则
MySQL可以使用一些代数等价变换规则来简化并规范表达式。可以合并或减少一些比较、还可以移除一些恒成立和一些恒不成立的判断。例如，`5=5 AND a > 5`可以被重写为`a > 5`、`(a < b AND b = c) AND a = 5`可以被重写为`b > 5 AND b = c AND a = 5`.
#### 优化`COUNT()`、`MIN()`和`MAX()`
要找到某一列的**最小值**，只需要查询对应B-Tree索引中最左端的记录，MySQL可以直接获取索引的第一行记录。
要找到某一列的**最大值**，只需要查询对应B-Tree索引中最后一条记录。

利用这两点，优化器在生成执行计划时，会将这两个表达式**作为常数对待**。并且，此时在EXPLAIN生成执行计划时，可以看到`Select tables optimized away`信息。
# <font color="#245bdb">索引</font>
## 1. 索引是什么? 有什么好处?
> [!abstract] 摘要
> 1. 数据结构
> 2. 降低时间复杂度。

索引是一种数据结构，可以减少查询时扫描的数据量，提高查询速度。

## 2. MySQL的索引是怎么实现的?
> [!abstract] 摘要
> 1. B+树；
> 2. B+树结构：叶节点/非叶结点存储、双向链表。
> 3. 好处。

InnoDB引擎采用了B+树作为了索引的数据结构。
- 平衡树，查找效率较高；
- 非叶节点不存储实际数据，因此可以存储更多的索引数据；
- 非叶节点使用前后指针连接
- 叶子节点通过双向链表链接，方便进行范围查询。
B+树是一种多叉树，非叶结点只存储索引，叶子节点存储数据和用于链接节点的前后指针。
由于非叶结点只存储索引，所以相对B树和二叉树，树的高度更低，因此磁盘I/O次数更少，查询效率更更高。

>`千万数据只需要3-4层高度即可满足。`
>1个内存页16KB，假设一个索引键值16字节，那么一个结点（内存页）占用$1024\times16/16=1024$个键值。
## 3. 如何判断SQL是否使用了索引？
使用EXPLAIN分析某条SQL的执行计划。具体关注：possible_keys和key，其中possible_keys表示可能使用的索引，key表示实际使用的索引！

EXTRA字段 【TODO】
## 4. EXPLAIN执行计划中包含哪些信息？
![[Pasted image 20250228143914.png]]
`id`：查询的标识符；
`select_type`：
`table`：表示访问的表。
`partitions`：基于**分区表**查询时，会显示所访问的分区。【注意分区和分表的关系】
`type`：
`possible_keys`：可能使用的索引。
`key`：实际执行时使用的索引。
`key_len`：索引中使用的字节数，可通过该列计算查询时使用的索引的长度。
`ref`：
`rows`：
`filtered`：
`Extra`：
#### `type`

## 5. 聚簇索引和非聚簇索引的区别是什么?
> [!abstract] 摘要
> 1. 叶子节点所存储的数据不同；
> 2. 是否能获得完整数据；
> 3. 唯一性。
>

- 聚簇索引也叫主键索引，非聚簇索引也叫二级索引。
- **数据存储**：聚簇索引的叶子结点包含了索引主键和对应的整行数据；而非聚簇索引的叶子结点不包含完整数据，只包含对应指向该行数据的主键值。
- **索引和数据的关系**：进行查询时，通过聚簇索引可以直接获取完整数据；而通过非聚簇索引查询，若查询了索引字段之外的字段，还需要回表查询。
- **唯一性**：聚簇索引通常是基于主键构建的，因此每一个表只能有一个聚簇索引；而非聚簇索引，一个表可以有多个。

## 6. 若表中不含主键，会如何构建聚簇索引？
> [!abstract] 摘要
> 1. 不为空的unique索引；
> 2. 隐藏主键rowid

若表中不包含主键，那么首先会使用**①不为空的unique唯一索引**来作为聚簇索引。
若也不存在，则会选择**②隐藏主键rowid**作为聚簇索引。
[[#rowid是什么?]]

### rowid是什么?
> [!abstract] 摘要
> 1. 内部自动生成的隐藏自增列；
> 2. 行的唯一标识符；
> 3. 作用：快速定位。

rowid 是一个特殊的隐藏自增列，**它为表中的每一行分配一个唯一的标识符**。这个标识符是内部生成的，通常用于快速定位和访问表中的具体行，**提供了一个快速访问行的机制**。

## 7. 什么字段适合作为主键?
> [!abstract] 摘要
> 1. 唯一性，非空；
> 2. 自增，减少页分裂和内存碎片。
> 3. （通过自增id引出分布式id）

4. 主键字段具有唯一性，且不能为空。
5. 最好具有递增趋势，这样能减少插入删除带来的页分裂和内存碎片。
6. 不建议使用业务数据作为主键，因为无法预测业务字段未来是否会重用；
7. 通常采用自增id作为主键，但仅限于单机系统。对于分布式系统，需要采用分布式id方案。

## 8. 采用UUID和自增id作为主键，哪个好?/自增id作为主键的优点.
> [!abstract] 摘要
> 1. 占用内存；
> 2. 安全性；
> 3. 查询效率；
> 4. 写入效率：索引重排、页分裂。

### UUID:
UUID 是一个 128 位长的唯一标识符，通常以字符串形式表示。
**优点：**
1. **全局唯一**：采用不同算法生成，几乎可以保证全球范围内唯一，避免了多台机器之间的主键冲突问题，因此也适用于分布式系统。
2. **不可预测性**：随机生成，很难被猜测出来，安全性较高。

**缺点：**
1. **占用空间大**：通常以字符串形式存储，占用空间比较大；
2. **不适合范围查询**：UUID不是自增的，所以不支持范围查询。范围查询通常是依赖于主键的顺序性来快速定位数据，如果主键非自增，通常需要扫描更多的数据来确认数据是否在指定范围内。
3. **效率低**：
	1. **查询效率低**：UUID作为主键创建索引时，因为UUID占用16个字节，相比于主键id，会占用更多的内存空间，导致内存页所能包含的数据更少，因此增加了磁盘I/O的需求，导致查询效率低。
	1. **写入效率低**：由于UUID是随机生成的，不具有自增性。因此新的UUID可能会插入到叶子结点的中间位置，导致索引页分裂和更多的I/O操作，影响了写入性能。（同时，数据分布在不同的内存页，也影响了查询性能。）

### 自增ID:
**优点：**
1. **占用空间小**：自增ID是数字，占用内存远小于UUID，节省存储空间；
2. **顺序插入，减少页分裂**：ID是递增的，新记录一般插入在索引页的末尾，避免了随机写入带来的页分裂和性能开销；
3. **查询效率高**：ID自增，索引中的数据存储顺序和值一致。
	1. 因此。进行范围查询时可以更快定位范围的起始点，提高查询效率；
	1. 在物理存储上记录也较为连续，减少IO
4. **分页方便**：id连续自增，通过 `id > ? LIMIT ?` 的方式分页可以解决深度分页问题；
5. **索引效率**：保证索引顺序和插入顺序相同，减少了索引重排，提高了插入速度。

**缺点：**
1. **分库分表**：分库分表时，没办法依赖于单表的自增主键来做主键id，因为可能会发生重复；
2. **可预测**：ID是顺序自增的，所以是可预测的；
	1. 例如竞对利用自增id获取订单量。
3. **可能用尽**：自增id的数据类型是int(4字节)或者bigint(8字节)，可能会存在用完的情况。

## 9. MySQL主键一定是自增的吗?
不一定。只是一般采用自增id作为主键，这样有几个好处：
1. 自增id是顺序插入的，可以**减少插入删除时的页分裂、页合并等问题**，提高写入性能；
2. 由于是顺序插入的，所以物理存储上也是连续的，因此范围查询时效率更高。


---
## 10. 联合索引的实现原理
> [!abstract] 摘要
> 1. 多字段构建索引；
> 2. 依次排序。

多个字段一起构造一个索引。
联合索引的key值是字段的值，先按首个字段排序，若首字段相等，再按照第二个字段排序。

联合索引遵循最左匹配原则。例如(a,b,c)构建联合索引，则使用索引时必须带a，并且与顺序无关，a可以在后面，因为优化器在构建执行计划时会进行优化。

## 11. 索引失效有哪些?
> [!abstract] 摘要
>1. 模糊查询（不符合前缀）；
>2. 使用了聚合函数；
>3. 不符合最左匹配；
>4. 类型转换。

1. 模糊查询，如`like %xx`或者`like %xx%`；
2. 使用函数；
3. 表达式计算；
4. 字符串类型未带''，导致发生了类型转换；
5. 不遵循最左匹配原则，导致联合索引失效；
6. **WHERE语句中，如果OR前是索引列，而OR后的条件不是索引列，那么条件会失效。**

## 12. 什么是覆盖索引?
> [!abstract] 摘要
> 1. 走非主键索引；
> 2. 无需回表。

覆盖索引是指在使用非主键索引进行查找时，由于**叶子结点中包含所以需要查询的字段**，因此不需要回表查询，减少访问内存页次数，提高查询性能。

## 13. 什么是前缀索引?
> [!abstract] 摘要
> 1. 使用前n个字段作为索引；
> 2. 好处：增加单个结点所能存储的索引数量；
> 3. （如何选择：计算区分度。）
> 4. （缺点：不能用于覆盖索引）

使用前缀索引是取字段的前n个字符作为索引，减少索引字段大小，以增加一个内存页中所能存储的索引数量，提高查询性能。例如存储用户的邮箱，就可以只选择前n个长度的字符作为索引，最终长度可以通过计算区分度来决定
```MySQL
SELECT COUNT(DISTINCT LEFT(email, 4)) AS L4,
       COUNT(DISTINCT LEFT(email, 5)) AS L5,
       COUNT(DISTINCT LEFT(email, 6)) AS L6,
       COUNT(DISTINCT LEFT(email, 7)) AS L7
FROM users;
```
## 14. 什么是索引下推(Index Condition Pushdown)?
> [!abstract] 摘要
> 1. **前提：** 多个查询条件为联合索引，举例Where A = xx And B like xx;
> 2. 将部分条件判断从Server层下推到引擎层。
> 3. 减少回表次数。

允许**在访问索引时对数据进行过滤**，从而减少回表的次数。

people表中（zipcode，lastname，firstname）构成一个联合索引（前提），执行查询语句：
`SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;`
- 若没有索引下推优化机制，首先会通过索引获取`zipcode='95054'`查找到相应记录，并通过**主键回表判断后两个条件是否符合条件；**
- MySQL5.6引入索引下推优化后，MySQL会在查询号zipcode='95054'记录后，立刻**检查WHERE条件是否可以通过索引中的列进行判断**，只有当全部条件满足，才会使用主键定位并回表查询获取完整行记录。

**总结，索引下推就是通过将部分条件判断==从Server层下推到存储引擎层==进行处理，有效减少回表次数，提高查询性能。**
![[Pasted image 20241204200241.png|650]]
![[Pasted image 20241119223926.png|400]]

## 15. 什么是索引跳跃扫描(Index Skip Scan)?  TODO

**MySQL8.0.13**引入的新特性，对于range查询，**支持不符合连锁索引最左前缀匹配的SQL依然能够使用联合索引**，减少不必要的扫描，提高查询效率。

**优化原理：**
构建联合索引(f1,f2)，执行查询语句：`SELECT f1, f2 FROM t1 WHERE f2 = 40;`
通过获取f1字段的所有唯一值，然后进行范围查询，最后合并所有查询结果。
```SQL
SELECT f1, f2 FROM t1 WHERE f1 =1 and f2 = 40
UNION
SELECT f1, f2 FROM t1 WHERE f1 =2 and f2 = 40;
```

但是，当f1字段的区分度比较高时，需要扫描的行数还是会很多，此时查询还是会很慢。

## 16. MySQL为什么会选错索引?^

## 17. 慢查询是什么？
查询花费大量时间的日志，是指mysql记录所有执行超过`long_query_time`参数设定的时间阈值的SQL语句的日志。

## 18. 什么是WAL技术?
WAL，即Write Ahead Lock，预写日志技术，**利用了磁盘连续写的性能高于随机读写这一特性**。具体而言，是
1. 先修改缓冲池中的内存页的数据并将该内存也标记为“脏页”；
2. 然后写redo log（事务提交阶段），磁盘中的数据并不会立刻更新；
3. 在之后在空闲时间、或者连接正常关闭时，由后台线程**Page Cleaner Thread**进行刷脏页操作，将缓冲池中的数据持久化到磁盘中。【顺序写性能高于随机写】

## !=、IS NOT NULL、IS NULL条件查询会走索引吗？
不一定，可能走也可能不走。主要还是根据表中数据量的大小来判断扫描行数、执行成本。

例如：
建表，建立`unique_idx`的唯一索引与`nonunique_idx`的非唯一索引，插入100000条数据，此时执行以下语句：
`EXPLAIN SELECT unique_idx FROM test2 WHERE unique_idx != 100005;`
![[Pasted image 20250331014225.png]]
可以发现，实质上还是走了索引的。

但是执行以下语句：
`EXPLAIN SELECT * FROM test2 WHERE unique_idx != 100005;`，
![[Pasted image 20250331014311.png]]却又不走索引了。

因此，实质上走不走索引

>**NULL值在MySQL中的存储，是存放在B+树的最左侧，因为规定NULL值为最小的值**。
---
# <font color="#245bdb">事务</font>
## 1. 什么是数据库事务?
>[!abstract] 摘要
>1. 一条或多条SQL组成的执行单元，要么全部成功，要么全部失败；
>2. 四大属性ACID的介绍。

**数据库事务( transaction)是一条或多条SQL组层的执行单元**。事务应该具有四大属性：ACID.Atomic(原子性),Consistency(一致性),Isolation(隔离性),Durability(持久性)。

- Atomic：事务作为整体被执行，要么全部成功，要么全部失败。
- Consistency：数据库总是从一个一致性的状态转换到另一个一致性的状态。
	- 假设有一个订单系统，订单金额必须与库存中的商品价格相匹配。如果在处理订单时**发现价格不一致，则该事务将被回滚**，以保持数据的一致性。
- Isolation：多个事务并发执行时，一个事务的执行不应该影响另外一个事务的执行。
- Durability：一个事务一旦提交，修改应该永久保存到数据库中。

## 2. ACID是如何保证的？

1. 原子性：通过undo log来保证，事务失败时可以回滚。
2. 一致性：其他三个满足了，自然也就满足。
3. 隔离性：通过MVCC+版本号来实现；
4. 持久性：通过redo log和bin log来保证。

## 3. MySQL如何开启事务？
`BEGIN`或`START TRANSACTION;`：开启事务；
`COMMIT`：提交事务；
`ROLLBACK`：回滚事务。
## 4. MySQL可能出现什么并发安全问题?
>[!abstract] 摘要
>均为事务的行为。
### 脏读:
一个事务读取到了另一个事务**未提交的变更**。
### 不可重复读:
在一个事务内多次读取同一个数据，出现**数据前后不一致**的情况。
### 幻读:
在一个事务内多次查询某个符合查询条件的记录数量，出现前后查询的**数量不一致**。
## 5. InnoDB如何解决脏读、不可重复读和幻读的？
- **脏读**：通过MVCC解决。在每一次SELECT语句时都会创建一个Read View，只会读取当前已提交的数据版本。
- **不可重复读**：通过MVCC解决。在第一次SELECT语句时创建Read View，后续所有的快照读都是读的第一次生成的Read View中的数据。
- **幻读**：通过MVCC+间隙锁解决，但不可完全避免。通过Gap Lock锁定索引范围，防止其他事务在范围内插入数据。
## 6. 事务的隔离级别有哪些?都是如何实现的?
>[!abstract] 摘要
>1. 当前读；
>2. Read View（不同时期创建）；
>3. 锁
1. **读未提交**：可以读取到其他事务还未提交的变更。
	- 读取最新版本的数据。
2. **读已提交**：可以读取到其他事务已提交的变更。
	- 通过创建Read View实现，在每个语句执行前都会生成一个Read View。
3. **可重复读**：事务内前后查询的数据保持一致，与事务启动时看到的数据一致。
	- 通过创建Read View实现，在第一个读请求时创建Read View。
4. **串行化**：事务是串行进行，当某个数据被多个事务读写时，后面请求的事务会处于阻塞等待状态。
	- 通过对数据加读写锁实现。

## 7. 可重复读隔离级别下，A提交的事务，B可以看见吗?
>[!abstract] 摘要
>1. MVCC保证：Read View + undo log

看不见。RR级别下，事务启动时会创建一致性视图，即使事务更新了数据并提交，事务B也可以通过undo log进行回滚，读取创建一致性事务时的数据。

## 8. ==解释下RR级别下的幻读问题。==
 RR级别下，通过MVCC快照来避免了幻读问题，每一次读取的数据都是**第一次查询时生成的快照**。但是，若在事务内执行了**当前读**，仍会发生幻读问题。

注意，由于快照是在第一次查询时才生成的、并且当前读也会读取最新数据并生成新快照，因此在以下情况下依旧会导致幻读。
根本原因就在于执行了当前读，因此获取了最新数据生成快照，也就是其它事务所插入的数据被读取到了。不仅是FOR UPDATE，UPDATE、DELETE等语句都会执行当前读。
![[Pasted image 20250303154421.png|700]]

![[Pasted image 20250303154914.png]]
![[Pasted image 20250303150953.png]]
## 9. 为什么大厂要将默认隔离级别修改为RC？
>[!abstract] 摘要
>1. **目的**：提高并发！
>2. **如何**：①无间隙锁和临键锁，只有记录锁；②半一致读；

为了提高并发。
1. RC在加锁时，无需添加Gap Lock和Next Key Lock，只会对被修改的记录添加Record Lock，这使得RC级别的并发度会高于RR级别，同时减少死锁的发生；
2. RC支持“半一致读”，可以大大减少更新语句时行锁的冲突；对于不满足更新记录的条件，可以提前释放锁，提高并发度。
	1. **半一致读**：RC支持“半一致读”，即在读取数据时，如果该数据被其他事务修改但尚未提交，MySQL会返回该记录最近提交的版本。
3. RC支持三种binlog格式，而RR支持持
## 10. 什么是半一致读？TODO
MySQL的半一致性读（Semi-Consistent Read）是一种优化机制，主要用于提高在特定事务隔离级别下的并发性能，尤其是在执行更新操作时。以下是对半一致性读的详细解析。

### 半一致性读的定义
半一致性读是一种介于普通读和锁定读之间的读取方式，主要应用于 **READ COMMITTED**（RC）事务隔离级别下。当执行更新操作时，如果需要加锁的行已经被其他事务锁定，MySQL会在InnoDB引擎层再次读取这些行记录，以判断是否真的需要加锁。这种机制可以减少不必要的锁竞争，从而提升系统的并发能力[1][2][5].

### 工作原理
在RC隔离级别下，半一致性读通过以下步骤工作：
1. **行锁判断**：当一个更新语句的 `WHERE` 条件匹配到的记录已被其他事务锁定时，MySQL会首先返回最新已提交版本的记录。
2. **条件判断**：在确认读取到的数据后，再决定是否对该行加锁。如果当前事务持有的锁与要加锁的行不冲突，则可以提前释放锁，从而避免不必要的阻塞[2][4][6].

### 示例
假设有两个事务同时尝试更新表中的数据：
- **事务1**：执行 `UPDATE test SET name='test' WHERE name='a';`
- **事务2**：同时执行 `UPDATE test SET name='test1' WHERE name='b';`

在没有半一致性读的情况下，若这两个更新操作都需要加锁且相互冲突，则可能导致一个事务等待另一个事务释放锁。而使用半一致性读时，如果事务1正在更新某些行，而事务2请求更新的不与之冲突，则可以顺利执行，减少了等待时间[1][2].

### 优势与应用场景
半一致性读的主要优势在于：
- **减少锁冲突**：通过判断是否真正需要加锁，可以降低因行锁引起的阻塞，从而提高并发性能。
- **优化全表扫描**：在全表扫描更新时，只有满足条件的行会被加锁，这样可以避免全表加锁带来的性能瓶颈[1][2][4].

### 适用场景
- 在高并发环境下，特别是涉及大量更新操作且数据访问模式较为复杂时，使用半一致性读可以显著提升系统响应速度和资源利用率。
- 对于低区分度字段的更新操作，可以利用这一特性来优化性能，避免不必要的等待和死锁[1][5].

### 总结
MySQL的半一致性读是一种有效提升数据库并发性能的技术，通过优化行锁机制和减少不必要的阻塞，为高并发场景提供了更好的支持。理解其工作原理及应用场景，有助于数据库管理员和开发者在设计和优化数据库系统时做出更明智的决策。

## 11. 介绍MVCC实现原理
>[!abstract] 摘要
>1. ①多事务读不阻塞；②数据一致；
>2. 版本链 + Read View

MVCC，多版本并发控制，允许多个事务读取同一行数据而不会彼此阻塞，并且每个事务看到的数据版本是该事务开始时的数据版本。MYSQL通过MVCC机制实现高并发。

#### 实现原理
通过**表的三个隐含字段 + undo log + Read View**实现的。

**三个隐含字段**：
- `row_id`：用于唯一标识一行记录，若存在主键，则该字段不存在。
- `trx_id`：最近事务ID，用于记录创建或最后一次修改该记录的事务ID。
- `roll_ptr`：回滚指针，指向该记录的上一个版本，用于配合undo log，指向上一个旧版本。

**undo log**：

1. 假设一个事务编号为10的事务向表中插入了一条记录，那么此时行数据为：
	![[Pasted image 20250304141828.png]]
2. 此时有另外一个事务编号为20的事务修改该记录的name字段。那么①首先数据库会加排它锁，避免其他事务对该记录进行修改；②然后会将该行老数据拷贝到undo log中；③最后才是真正对该行记录进行修改，并将`roll_ptr`指针指向`undo log`中的拷贝副本。
	![[Pasted image 20250304142148.png]]
3. 后续有修改，也是同样执行上述的操作，最终会在形成一个版本链。
	![[Pasted image 20250304142246.png]]

#### Read View
是一种快照机制，用于实现MVCC，帮助事务确定哪些版本的记录可见，以实现并发读写，提高并发性能。
![[Pasted image 20241204205441.png|650]]

通过判断要读取的记录的事务`trx_ID`与Read View中记录的ID的大小关系，来判断记录是否可见。
- `trx_id == creator_trx_id`，则当前事务在访问自己修改的数据，可见。
- `trx_id < min_trx_id`，则事务在Read View生成之前已经提交，说明可见。
- `trx_id > max_trx_id`，则事务在Read View生成之后才创建，说明不可见。
- `min_trx_id < trx_id < max_trx_id`，则此时会与`m_ids`进行比较：
	- 若在`m_ids`中，说明事务开启时，`trx_id`还是活跃的，因此不可见。
	- 若不在`m_ids`中，说明事务开启之前，其他事务对数据进行修改并提交，则应该可见。

总结，只能看到两种数据：1. 自身修改的数据；2. 在事务启动时**已提交**的其他事务的修改。

说明一下最后一种情况：
我认为，根本原因还是在于，事务开启时并不会阻塞写，所以103仍可以修改并提交。这样`min_trx_id`就是102了，并且`m_ids`中不会包含103。
![[Pasted image 20250304163933.png]]
## 12. 介绍下ReadView
ReadView主要用于解决可见性问题，**帮助事务确定哪些版本的行记录是可见的**。
- RC隔离级别，是在「每个select语句执行前」都会重新生成一个 Read View；
- RR隔离级别，会在第一个SELECT语句执行后生成一个Read View，然后整个事务期间都会用这个ReadView。


Read View有四个重要信息：
![[Pasted image 20241204205441.png|650]]


![[Pasted image 20241204205725.png|650]]
## 13. 当前读和快照读有什么区别？
>[!abstract] 摘要：
>1. **区别**：Read View 和 最新数据；
>2. **何时**：DML语句、IN SHARE MODE、FOR UPDATEA。

快照读读取的是快照中，即ReadView中的数据；当前读，读取的是最新的数据，主要用于修改操作，获取数据的最新状态以保持一致性。

快照读：
`SELECT * FROM xx_table WHERE ...;`

当前读：
- 增删改、加锁的select都会进行当前读
```sql
SELECT * FROM xx_table LOCK IN SHARE MODE;

SELECT * FROM xx_table FOR UPDATE;

INSERT INTO xx_table ...

DELETE FROM xx_table ...

UPDATE xx_table ...
```
## 14. 自适应哈希索引是什么？
##### 是什么？
是这样的。**InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引能提高速度，则会建立哈希索引，称为自适应哈希索引（Adaptive Hash Index）**。

AHI是**通过缓冲池的B+树页构造**而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。**InnoDB存储引擎会自动根据访问频率和模式来自动地为某些热点页建立哈希索引**。
##### 建立要求
1. 只适用于等值查询，范围查询不使用。
2. AHI要求对所建立的热点也的连续访问模式必须是一样的。例如对于联合索引`(a,b)`，符合条件的连续访问模式可以是：`WHERE a=xxx`或`WHERE a=xxx and b=xxx`，但不能是二者交替进行。
3. 需要以该连续访问模式访问100次；
4. 页通过该模式访问了N次，其中`N=页中记录/16`
##### 如何查看？
使用`SHOW ENGINE INNODB STATUS`可以查看当前AHI的使用情况。
##### 优缺点
**优点：**
1. 自动建立、优化，通过哈希的O(1)查询提升性能，避免了全表扫描。

**缺点：**
1. 高并发场景下可能会导致哈希锁的竞争。
2. 自适应哈希索引建立在缓冲页中，因此需要有足够的内存资源。

## 15. SavePoint保存点是什么？
用于在事务中打点，避免将本次事务的内容全部回滚了。

执行`ROLLBACK [SAVEPOINT]`会回滚到指定保存点的位置。

## 16. 为什么崩溃恢复不用bin log而是使用redo log？
1. bin log会记录所有的更改操作，保存更新删除数据、表结构的修改，主要用于人工恢复数据，可以通过`mysqlbinlog`工具恢复数据；redo log是InnoDB引擎特有的，用于保证`crash-safe`能力、持久性的，只会记录buffer pool中未刷盘的数据。
2. 当数据库崩溃时，虽然bin log和redo log中记录了已写入但未刷盘的数据，**但bin log中不存在某个标志可以判断哪些数据已经被持久化**。但redo log不同，只要已被刷入磁盘的数据，都会从redo log中抹掉。

---

# <font color="#245bdb">锁</font>
## 1. 介绍一下MySQL的锁
![[Pasted image 20241119215143.png]]
## 2. 什么是排他锁和共享锁?
>[!abstract] 摘要
>1. 读锁共享，写锁阻塞。
### 共享锁:
- 共享锁又称读锁、S锁，是读取操作创建的锁。其他用户可以并发读取数据，**但任何事务都不能对数据进行修改**（获取数据上的排他锁），直到已释放所有共享锁。
- 如果事务T对事务A加了共享锁，其他事务只能对A再加共享锁，不能加排他锁。

### 排他锁:
- 排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任何类型的锁。获得排他锁的事务既能读数据，又能修改数据。

## 3. 什么是意向锁?
>[!abstract] 摘要
>1. 解决不同锁粒度并发性问题的锁机制；
>2. **申请表锁时，通过意向锁快速判断是否有行锁**。

若事务A对某行记录加了行锁，而事务B申请整张表加表锁，那么就需要判断表中是否有行锁，若通过全表扫描来检测，那么效率很低，因此引入意向锁来快速判断。

所以，**意向锁是数据库管理系统中用于实现锁协议的一种锁机制，是用于处理不同锁粒度之间（主要是表锁与行锁） 的并发性问题。**
	行锁与行锁之间的并发问题通过行级互斥锁实现。

意向锁共有两种：1)意向共享锁；2)意向排他锁。共享+共享√，共享+排他×，排他+排他×.
## 4. redo log的作用是什么？


## 5. binlog, redolog和undolog的区别?
#### binlog
- binlog主要用于对数据库进行**数据备份、主从复制和崩溃恢复**等操作。binlog是MySQL用于记录所有**DDL语句和DML语句**的一种二进制文件，不会记录查询类操作(如SELECT、SHOW)。
- binlog是追加写形式，当写满一个文件后会创建新文件继续写，不会覆盖以前的日志。
#### redolog
- redolog是MySQL用于**实现崩溃恢复和数据持久性**的一种机制。在事务进行过程中，MySQL会**将事务做了什么改动**记录到Redo Log中。当系统崩溃或者发生异常情况时，MySQL会利用Redo Log中的记录信息来进行恢复操作，将事务所做的修改持久化到磁盘中。
#### undolog
- Undo Log则用于在**事务回滚或系统崩溃时撤销（回滚）事务所做的修改**。当一个事务执行过程中，MySQL会将**事务修改前的数据**记录到Undo Log中。如果事务需要回滚，则会从Undo Log中找到相应的记录来**撤销事务所做的修改**。
## 6. binlog, redolog和undolog的持久化时间？ TODO
## 7. MySQL中的binlog有几种格式?
共有三种格式：row、statement和mixed.
### statement:
数据库中的SQL语句会原封不动的被记录在binlog中。

使用较少，会导致主从复制不一致的问题。
- 比如说，当我们使用DELETE或者UPDATE的时候，指定了LIMIT，但是并没有使用order by，那么最终这条语句在主库和从库上的执行结果可能是不一样的（即使同一个库上面，你执行多次结果可能也不一样）。
### row:
binlog中会**记录每个数据更改的具体行的细节**，每条日志都会详细记录发生变更的行的内容和修改情况。

缺点是需要记录更多的内容，如批量修改，需要将每条记录的变更细节都记录。因此**数据恢复时需要更长时间**。
### mixed:
两者的结合，自动切换选择合适的格式进行记录。但是在RC级别下，只有row格式可以生效。


## 8. ==什么是事务的两阶段提交?==
![[Pasted image 20241120013145.png|450]]
将事务的更新分为Prepare准备阶段和Commit提交阶段。
- **准备阶段**：MySQL将事务的更新操作记录到redo log中，并将其标记为Prepare状态；紧接着，MySQL将更新操作写入binlog。
- **提交阶段**：MySQL将redo log记录标记为commit提交状态，并确保事务的修改持久化到数据库中。
两阶段提交确保了binlog和redolog的数据一致性，从而保证数据库在崩溃恢复等场景下的可靠性和稳定性。

假设第一阶段提交已完成，binlog已写入，但是第二阶段还未完成，redolog仍未被标记为commit状态，此时数据库宕机崩溃，那么**重启后，事务会回滚还是提交？**

判断回滚还是提交的基本原则：**保证binlog与redolog的一致性，保证binlog能完全恢复数据。**
- 因为binlog已落盘，所以此时会根据redolog中的记录将数据恢复，并提交事务。
	- 若此时将事务回滚，那么binlog中就会多出一条记录(已写入的binlog不能被修改！)，导致数据不一致。

![[Pasted image 20250107125613.png|500]]
![[Pasted image 20250123104540.png]]
## 9. 两阶段提交中，如何判断binlog和redolog是否达成了一致?
当MySQL写完redolog并将它标记为prepare状态时，并且会在redolog中记录一个**XID**，它**全局唯一的标识着这个事务**。而当你设置`sync_binlog=1`时，做完了上面第一阶段写redolog后，mysql就会对应binlog并且会直接将其刷新到磁盘中。

下图就是磁盘上的row格式的binlog记录。binlog结束的位置上也有一个XID。
![[Pasted image 20241120194528.png]]
只要这个XID和redolog中记录的XID是一致的，MySQL就会认为binlog和redolog逻辑上一致。就上面的场景来说就会commit，而如果仅仅是rodolog中记录了XID，binlog中没有，MySQL就会RollBack。

**总结**：通过redolog和binlog中的用于全局唯一标识事务的XID来判断。

>[!IMPORTANT]
>**注意：保持binlog和redolog的一致，需要开启参数innodb_support_xa = 1**


## 10. 死锁情况分析
![[Pasted image 20250217203021.png|400]]

**分析结果：**
![[Pasted image 20250217203253.png]]
- 由于TIME3和TIME4互相等待对方释放间隙锁，因此会导致死锁。


---
# <font color="#245bdb">分布式</font>
## 1. ~~分布式id方案^<sup>美团leaf分布式id</sup>~~ TODO


## 2. 读扩散问题是什么？ TODO
查找非分片字段发生的扫描所有分表的问题。
- 假设user表按照user_id分表，那么此时就会有user_0、user_1等多张表，那么此时若按照name字段进行查询，则无法具体定位到某张表，那么就会对所有分表执行！

**解决方案一：**
- 根据name字段建立新表。那么查询过程就会变成先查name表，获取对应主键id，再去查主键id对应的分表。
	- **缺点**：需要维护两套表，并且普通索引列更新，需要同时更新两张表。![[Pasted image 20241220111707.png]]

**解决方案二：**
>倒排索引，通过字段反向查找出含有该字段的数据记录。
- 利用ES的倒排索引功能，内部会以ID分片键进行分片，同时建立name到id，age到id的倒排索引。
- **具体实现**：利用开源工具canal监听MySQL的binlog日志变更，再将数据解析后写入ES。![[Pasted image 20241220112928.png]]

**解决方案三：**
- 使用分布式数据库TiDB。

## 3. MySQL的主从复制
基本思路就是基于Binlog进行主从复制。其中复制有三种方式：同步、异步、半同步。

1. 从服务开启主从复制后，会创建I/O线程、SQL线程；
2. 从服务器的I/O线程，会尝试和主服务器建立连接；主服务器有Binlog dump线程，用于和从服务器I/O线程做交互。
## 4. 分库分表会带来什么问题？
1. 跨库事务问题；
2. 跨多表的分页、排序；
3. 二次分表的数据迁移问题；
4. 一致性ID问题。
## 5. 分库分表后如何进行分页查询？

#### 非ShardingKey的关键查询
假设是基于买家ID进行分库分表，那么基于买家ID的查询自然就能路由到该库进行查询了。

而基于卖家ID的查询，就无法路由了。解决办法是：
同步一张基于卖家ID的分表。使用Canal基于Binlog做自动同步，将订单创建时，会在买家表中也插入一条记录，基于卖家ID做分表。这样之后基于卖家ID的查询就也能路由了。

并且，由于这张卖家表只处理读请求，因此无需像买家ID做的分表那样需要较高的配置。

#### 非ShardingKey的复杂查询
由于分库分表一般都是大型企业采用了！因为数据量、连接数已经很大了！因此，一般都是使用分布式数据仓库来实现，将数据同步到像TiDB、PolarDB、AnalyticDB等这些数据库，或同步到ES中，在这些数据库进行聚合查询。
## 6. 分库分表之后如何进行Join操作？
标准的Join操作是要在单库执行。并且有些分库是分布在不同的服务器上的，跨库join就需要与多个服务器交互，会有网络延迟。
#### 方案一：应用层JOIN
单独查询各个表，在应用层将结果合并，进行JOIN操作。

**优点**：
1. 灵活，可以跨多库进行。

**缺点**：
1. 对应用服务器处理要求高，数据量大的话网络开销也很大，性能有影响。
#### 方案二：数据冗余
反范式，做数据冗余，尽量避免执行JOIN操作。

**优点**：
1. 实际场景中常用。能显著减少复杂查询，提升系统性能。

**缺点**：
1. 存在一致性问题，同时也会增加存储空间。
#### 方案三：基于ES
使用Canal基于Binlog，将数据同步到ES中，使用ES进行查询。
## 7. 如何进行平滑的数据迁移？

