# <font color="#245bdb">数据结构</font>
## 1. 介绍一下Redis的底层数据结构:
共五种，分别是`String,List,Set,Hash,ZSet`. 后续版本更新又添加了`BitMap,HyperLogLog,GEO,Stream`.

**使用场景:**
- BitMap: 常用来做状态统计，例如用户签到记录.
- HyperLogLog: 海量数据基数统计，比如百万级用户UV
- GEO: 存储地理信息，查找附近的人
- Stream: 消息队列,相比于使用List实现的消息队列,优点是:1)可以自动生成全局唯一消息id; 2)支持以消费组形式消费数据.
## 2. ZSet用过吗?
用过. 用于实现排行榜功能. 数据结构为:`key:member:score`.
赋值可用`ZADD key score member`,为
增加点赞数量用: `ZINCRBY key increment member`,可在原有score基础上增量增加.
查询排行可以用`ZREVRANGE key start stop`来查询降序的排行.

## 3. ZSet的底层实现是什么?
- ZSet底层在5.0之前使用**压缩列表或跳表**实现的，5.0之后又引入了**紧凑列表listpack**，7.0之后彻底取消zipList。
![[Pasted image 20241218193129.png]]
当集合的元素个数小于128，且每个元素的值小于64字节，使用压缩列表。
当不满足上述条件，例如元素个数大于128个，或存在元素大于64字节，则采用跳表。

然后，在Redis7中废除了压缩列表，使用listpack数据结构替代。

## 4. ==跳表是怎么实现的?== ^
跳表是在链表的基础上改进过来的. 主要原因就是链表的查询需要逐一查找,时间复杂度是O(N),所以引入了跳表,实现了**多层的有序链表**,优点就是提高了查询效率(O(logN)),更快速定位数据.
![[Pasted image 20241009232226.png]]
**查询值为4的节点:**
- 链表查询：需要从头节点开始遍历，查询4次（1,2,3,4）才能查询到目标节点.
- 跳表查询：
	- 第一层L2，查询3，发现4在3~NULL之间，跳跃到下一层；
	- 第二层L1，查询4在3~5，继续下一层；
	- 第三层L0，查询到节点4.

**跳表的数据结构:->如何实现多层级的?**
```C
typedef struct zskiplistNode {
	//Zset 对象的元素值 
	sds ele; 
	//元素权重值 
	double score; 
	//后向指针 
	struct zskiplistNode *backward; 
	//节点的level数组，保存每层上的前向指针和跨度 
	struct zskiplistLevel { 
		struct zskiplistNode *forward; 
		unsigned long span; } level[]; 
	} zskiplistNode;
```
内部存在**ele和score变量**,对应了ZSet中的member(元素)和score(元素权重). 
然后还有个**后向指针**,指向前一个节点,便于倒序查找.

跳表是一个**带有层级关系**的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的**zskiplistLevel 结构体类型的 level 数组**。

**level 数组中的每一个元素代表跳表的一层**，也就是由zskiplistLevel结构体表示，比如`level[0]`就表示第一层,`level[1]`就表示第二层。zskiplistLevel结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。
![[Pasted image 20241012202231.png]]

Redis 跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。  

具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。  

这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。  

虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点。
## 5. 跳表是怎么设置层高的?
跳表在创建节点时候，会生成范围为\[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。 

## 6. ==Redis为什么使用跳表而不是用B+树?==
1. **内存占用**上，跳表更加灵活:
	平衡树每个节点包含2个指针，而跳表的每个节点包含的指针平均数目是`1/(1-p)`个，取决于p的大小。在Redis中，p的值为0.25，因此平均每个节点包含的指针就是`4/3`，比平衡树更有优势.
2. **范围查找**时，跳表操作更简单:
	B+树在查找到区间的左边界时(也就是较小的值)，还需要继续中序遍历查找右边界的节点,那么在实现上就略显困难. 而在跳表上进行范围查询，只需要查找到小值后，在第一层进行若干次遍历再查找到右边界即可。
3. **算法实现**上，跳表更简单:
	B+树的插入和删除操作可能会导致树的结构的改变，逻辑复杂；而跳表的插入和删除只需要修改相邻节点的指针即可。

## 7. 压缩列表是怎么实现的? ^
## 8. 介绍一下Redis中的listpack. ^
## 9. 为什么ZSet 既能支持高效的范围查询，还能以 O(1) 复杂度获取元素权重值？
```java
typedef struct zset 
{ 
    dict *dict; 
    zskiplist *zsl;
} zset;
```
内部含有dict字典与skiplist跳表：字典存储`member->score`的映射关系，跳表是有序链表+多层索引的结构，支持以`O(logN)`的复杂度进行查询。因此，既支持高效范围查询，也支持O(1)获取分数。
## 10. 哈希表是怎么扩容的？
首先,正常情况下数据都存储在`哈希表1`中. 当数据量逐渐增加时,此时需要就需要有`哈希表2`,分配的空间大小一般为表1的**2倍**. 然后**表1的数据会迁移到表2**中,然后**表2会被设置成表1**,最后表2中又会再次新建一个空白的哈希表,为下次扩容做准备.

这涉及到一个问题,就是如果数据量很大,并且由于**Redis是单线程**的,所以数据在由表1迁移至表2时,会**引起Redis的阻塞**,导致无法服务其他请求.

所以Redis采用了**渐进式rehash**,也就是将数据分多次迁移.具体而言,是 
1) **先给`哈希表2`分配空间**,
2) 然后在执行增删改查操作时,会**按顺序将数据迁移到`哈希表2`中**.

在渐进式更新过程中,新增操作会将数据保存到`哈希表2`中.
查询操作会先查询表1,再查询表2.

## 11. String是使用什么存储的?为什么不用C语言中的字符串? | 为什么要自己定义SDS？^
是使用SDS(Simple Dynamic String)数据结构存储的,使用SDS保证了Redis的"快".
![[Pasted image 20241012202850.png|450]]
**len:** 记录了字符串长度,保证了在查询字符串长度时的时间复杂度为O(1).

**alloc:** 分配给字符数组的空间长度. 在修改字符串时,会先判断`alloc-len`是否满足修改需求.
若不满足修改需求,则会自动将SDS的空间扩展至所需大小,然后再执行修改操作.
**用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出的问题。**


**flags:** 用来表示不同类型的SDS,共有SDSHDR5,SDSHDR8,SDSHDR16,SDSHDR32和SDSHDR65五种.

**buf[]:** 字符数组,用来保存实际数据.既可以保存字符串,也可以保存二进制数据.

### 相比于C语言中的字符串,SDS的优点:
1. **查询速度快**： 定义了len元数据，提高查询长度、追加写操作的时间复杂度；
	- C语言中字符串以`\0`表示字符串结束的标识，因此长度判断、追加操作都需要从头开始遍历。
2. **二进制安全：**
	- SDS使用len来记录字符串长度,而C语言使用`\0`作为字符串结束标志来记录字符串长度. C语言使用`\0`作为结束标志,使其无法正确处理包含`\0`的字符串.
	- SDS字符串仍旧存在`\0`字符,以更好的兼容部分C语言标准库函数.使得SDS既可以作为C语言字符串使用,也可保证二进制安全.
3. **不会发生缓冲区溢出**：
	- C语言的字符串标准库中的操作都是不安全的，因为"缓冲区大小是否满足修改需求"的操作交由开发者自己判断，而程序内部并不会自己判断是否足够用,故有可能发生缓冲区溢出导致程序异常结束!
	- 而**SDS结构的API会判断`alloc-len`是否满足修改需求**，保证缓冲区不会溢出.

## 12. Redis的渐进式Rehash是什么？
>

Redis底层使用了两张哈希表，并且会维护一个rehashindex，初始值为-1，用来记录当前rehash的下标位置。

1. 初始时，只使用哈希表1。当元素个数与哈希表1**长度相等**时，此时会触发rehash操作，将哈希表2的容量扩大一倍；
2. 当后续有增删改查时，就会将`rehashindex`索引所对应的链表上所有元素都rehash到哈希表2中，并将rehashindex+1，此时所添加的元素就会新增到哈希表2上；
3. 后续继续有增删改操作时，会不断执行rehash操作，直到全部完成；
4. rehash完成后，会将哈希表1和哈希表2的指针互换，并把哈希表2置为NULL，后续的增删改查继续在哈希表1进行。

>**在rehash过程中，查询操作会先在哈希表1查找对应的KEY，若找不到，则继续在哈希表2中查询。**

**优点：**
- 避免一次性迁移过多数据，导致增删改查操作性能受影响。
## 13. Redis的Pipeline是什么，和事务有什么区别？
Pipeline允许客户端一次性向服务器**发送多个命令**，而不必等待每个命令的响应，从而减少网络延迟。

没有Pipeline时，每个请求遵循以下流程：
1. 客户端发送命令到服务器；
2. 服务器执行命令并返回结果给客户端；
3. 客户端接收返回结果。
**每一个请求和响应之间存在一次网络通信的往返时间**（RTT，Round-Trip Time），如果大量请求依次发送，网络延迟会显著增加请求的总执行时间。

**优点：**
- 减少客户端与服务器的通信次数，提升性能。




---
# <font color="#245bdb">Redis线程模型</font>
## 1. Redis为什么快?
1. **基于内存**的数据库,数据存储在内存中,读写速度非常快.
2. Redis的**单线程模型**,所有操作都在一个线程内完成,**无需线程切换**,节省了线程切换带来的额外开销,并且也不会有死锁问题.
3. Redis在单线程的基础上,采用了**I/O多路复用技术**(epoll和select机制),实现了**单个线程同时处理多个用户端连接**的能力,从而提高了Redis的并发性能.
	- 在单线程时,允许内核中存在多个监听Socket和已连接的Socket,内核会一直监听这些Socket的连接请求或数据请求.
4. 采用了**高效的数据结构**,在设计上进行了性能优化,能实现O(1)复杂度的读写操作.
5. 引入了**多线程机制提高I/O性能**。采用多线程，可以使请求处理并发进行，大大提升性能。当线程在处理网络IO时，其他线程可以继续处理其他请求，减少了阻塞时间.
## 2. Redis为什么被设计成单线程？^
单线程指的是“**网络I/O和读写操作是由一个线程完成的**”，即只有**网络请求模块和数据操作模块**是单线程的。

## 3. 为什么Redis设计成单线程也能这么快？^

## 4. 为什么Redis 6.0引入了多线程? ^
>**Redis 6.0中的多线程,只是针对处理网络请求过程采用了多线程，而数据的读写命令，仍然是单线程处理的。**

为了处理更高的QPS.
![[Pasted image 20241220110355.png]]![[Pasted image 20241220110324.png]]
![[Pasted image 20241218173114.png|450]]
## 5. Redis哪些地方使用了多线程? ^

## 6. Redis怎么实现的IO多路复用? ^

## 7. Redis的网络模型是怎样的? ^

---
# <font color="#245bdb">Redis事务</font>
## 1. 如何实现Redis原子性?
>**原子性在并发编程中，和在数据库中两种不同的概念:**  
>	在数据库中，事务的ACID中原子性指的是"**要么都执行要么都回滚**.
>	在并发编程中，原子性指的是"**操作不可拆分、不被中断**"。

Redis是单线程的,所以执行一条命令时是原子性的； 当有多条命令时，可以**使用lua脚本保证原子性**。**Redis会把Lua脚本封装成单独的事务**，由Redi服务器自行处理并完成整个事务，当此时有其他请求时，会**暂存**，等Lua脚本处理完毕后再把暂存的请求恢复。

Lua脚本

>[!注意]
>**Redis保证以原子方式执行Lua脚本，但是不保证脚本中所有操作要么都执行或者都回滚。**

**lua脚本举例:** 
分布式锁的解锁操作: 1)先判断锁是不是自己的; 2)是自己的再解锁.
```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放 
if redis.call("get",KEYS[1]) == ARGV[1] then     
	return redis.call("del",KEYS[1]) 
else     
	return 0 
end
```
## 2. 为什么Lua脚本可以保证原子性？
- Lua脚本会被Redis封装成事务来执行，确保命令执行过程中不被打断。若此时有其它线程要执行命令，会阻塞等待Lua脚本执行结束。
## 3. 除了lua有没有什么也能保证redis的原子性?
Redis的事务也可以保证多个操作的原子性,即Redis的MULTI和EXEC操作. 

Redis的事务中,若前面的操作失败了,不影响后面操作的执行.
但是当事务中执行出错了,**无法回滚**.

## 4. Redis的事务和Lua之间有哪些区别？
Redis的事务和Lua脚本都是用来保证原子性的手段.

**区别1：后续命令是否受影响**
- 事务和Lua脚本都是原子性保证，但是**都无法回滚**!
- 但Redis的事务中，某个命令失败**不会影响**后续命令的执行；
- 而Lua脚本，若某个命令失败，后续命令**会受影响**.

**区别2：交互次数**
- Redis的事务由MULTI开始，EXEC结束.在期间的操作都会被Redis服务器暂存起来,不会立即执行,但是**每次命令的提交都会与Redis服务器进行一次交互**；
- Lua脚本只需要一次性将脚本提交给Redis服务器即可。（类似于Pipeline）

**区别3:前后依赖**
- Redis事务内的命令时独立执行的，并且在EXEC命令执行前，事务内的命令是没有被真正执行的，所以后续的命令不会也不能依赖于前面的命令的.(无`IF ELSE`等条件语句)
- Lua脚本中的命令是可以依赖于前面的命令的，并且可以利用前一个命令的执行结果进行后续处理。例如`IF ELSE THEN`.
## 5. SETNX为什么是原子性的？
因为Redis是单线程的，命令是在主线程顺序执行的，因此命令在执行时不会被其他命令打断。
## 6. Redis 的事务机制是怎样的？
Redis支持事务，保证多个命令执行原子性，不被打断。但是**不支持回滚**！发生错误了，会继续执行剩余命令，而不是回滚整个事务。
## 7. 为什么Redis不支持回滚？
1. **违背Redis设计初衷**。Redis的设计倾向于简单高效，回滚机制会提高系统复杂度并且降低系统性能；
2. **单线程**。Redis的执行过程是单线程的，无需担心并发造成的数据异常。

---
# <font color="#245bdb">Redis日志</font>
## 1. Redis的持久化方式有什么?各有什么优缺点?
共有**2种**持久化方式:
### AOF日志：
AOF，Append Only File，是**将Redis的所有写操作追加到AOF文件的末尾**,从而记录了Redis服务器运行期间所有修改操作的详细记录.Redis重启后,可通过执行写操作来恢复数据.（类似于MySQL的statement形式的binlog）

若写操作刚执行完,Redis服务器就宕机,此时写操作可能还未被写入AOF文件,会导致命令和相应的数据丢失.

**优点：** 可以实现**更高的数据可靠性(比RDB可靠)**、支持**更细粒度的数据恢复**，适合做数据存档和数据备份。
**缺点：** 文件大占用空间更多，**每次写操作都需要写磁盘导致负载较高**.
### RDB快照
RDB，Redis DataBase，是将Redis的内存中的数据**定期**保存到磁盘上，以防止数据在Redis进程异常退出或服务器断电等情况下丢失。

**优点:** 快照文件小，恢复速度快，适合做备份和灾难恢复.
**缺点:** 定期更新可能会丢数据。
### 混合持久化：RDB-AOF
Redis4.0推出了RDB-AOF混合持久化，同时保留了两种持久化的优点。

开启混合持久化，AOF重写时会将Redis的持久化数据，以RDB的格式写在AOF文件的开头，之后的数据再以AOF的格式追加到文件的末尾.

恢复数据时：
1. 会先加载RDB的快照部分；
2. 再执行快照之后的AOF格式保存的增量写操作，最终实现数据恢复。

**优点:** **结合了AOF的实时性以及RDB的快速恢复能力**,既能确保数据的安全性和完整性，又提升了数据恢复的速度.
**缺点:** AOF文件的可读性变差,并且混合AOF文件无法在旧版本中使用.

## 2. RDB和AOF的写回策略分别是什么？
写回策略是指将数据**从内存写入到持久化存储（如磁盘）** 的方式和时机。

**RDB写回策略：**
- **定期触发**：通过配置`save`参数定义自动保存条件。Redis定期检查条件是否满足，满足则触发RDB的保存操作。
	- `save 60 100`：每60秒至少发生100个变化，则保存快照。
- **手动触发**：通过命令手动生成RDB文件。
	- SAVE：由主线程完成生成RDB文件，会阻塞Redis服务器直至快照完成。
	- BGSAVE：创建子线程在后台异步生成RDB文件，不会阻塞Redis服务器。【BackGround Save】

**AOF写回策略：**
- **Always**：同步写回，每个写命令执行完毕后，立马同步将日志写回磁盘。【性能降低，类似于降级成磁盘数据库了】
- **Everysec**：每秒写回，每个写命令执行完毕后，先把日志写到AOF文件的内存缓冲区，每隔1秒把缓冲区的内容写回磁盘。【推荐】
- **No**：操作系统控制的写回，每个写命令执行完毕后，只把日志到内存缓冲区，由操作系统决定何时写回磁盘。【操作系统何时写回不确定，因此数据丢失风险大！】
## 3. Redis能完全保证数据不丢失吗？^
当然不能！

---
# <font color="#245bdb">Redis缓存淘汰与过期删除</font>
## 1. 介绍一下Redis的过期策略.
Redis 的过期策略采用的是**定期删除和惰性删除相结合**的方式。

### 定期删除:
每隔100ms就随机抽取一些设置了过期时间的key，并检查其是否过期，过期则删除. 
若$\frac{过期的key}{抽查的总数}$>25%，则会继续随机抽取20个key判断是否过期，直到比例小于25%.

同时,为了避免循环过度,导致线程卡死,**循环流程具有25ms的时间上限.**

**过期时间配置:**
> redis.conf中配置了10Hz,也就是1秒抽取10次
> 随机抽取的个数默认为20个,并且是固定值.

**定期删除的优缺点:**
- 定期删除是Redis的主动删除策略，能保证过期的key被**及时删除**；
- 会**占用CPU资源**来扫描key，可能会影响Redis的性能.

**内存处理:**
将过期键删除时,**不会立即释放**内存,而是**将过期的key标记为"已过期",并放入专门的链表中**.在Redis的内存使用率达到一定阈值时,Redis会对这些"已过期"的键进行一次内存回收操作,是否键占用的内存空空间.

### 惰性删除:
当key过期时，不会立即删除，而是在key被访问时才触发删除操作.

**惰性删除的优缺点:**
惰性删除是Redis的被动删除策略,可节省CPU资源,但会导致过期的key始终保存在内存中,**占用内存资源**.

**内存处理:**
访问时检查是否过期，过期了则删除键并释放内存。

>[!注意:]
>一般来说，这些**被删除的内存空间会被操作系统标记为“可重用的内存”，等待被重新分配**。因此，即使Redis进行了内存回收操作，也并不能保证Redis所占用的内存空间会立即释放给操作系统。

## 2. 介绍一下Redis的内存淘汰策略(也叫数据逐出策略).
Redis 的内存淘汰策略用于在内存满了之后，决定哪些key要被删除,以保存新的内容. Redis 支持多种内存淘汰策略，可以通过配置文件中的 **maxmemory-policy** 参数来指定。

Redis的内存淘汰策略共8种,分为"不进行数据淘汰"和"进行数据淘汰"两类.
![[Pasted image 20241013180555.png]]
**不进行数据淘汰的策略:**
	**noeviction:** 当运行内存超过最大设置内存时，**不淘汰任何数据**，这时如果有新的数据写入，会**报错通知禁止写入**. 但若只是单纯的查询或者删除操作的话,还是可以正常工作.


>lru:The Least Recently Used,最近**最少使用,最久未被访问**的数据会被最早淘汰.
 lfu:The Least Frequently Used,**使用频次最低**的数据会被最早淘汰.
- **进行数据淘汰的策略:** 组合`(allkeys,volatile)`和`(lru,lfu,random)`
	- **allkeys-lru:** 从**所有key中选择最近最少使用**的那个key并删除。  
	- **volatile-lru:** 从**设置了过期时间的key中选择最近最少使用**的那个key并删除。  
	- **allkeys-random:** 从所有 key 中**随机选择**一个 key 并删除。  
	- **volatile-random:** 从设置了过期时间的 key 中随机选择一个key并删除。  
	- **volatile-lfu:** 淘汰的对象是带有过期时间的键值对中，访问频率最低的那个。  
	- **allkeys-lfu:** 淘汰的对象则是所有键值对中，访问频率最低的那个。	
	- **volatile-ttl:** 从**设置了过期时间的key中选择剩余时间最短的key** 并删除。  

## 3. 如何选择内存淘汰策略?
腾讯针对Redis的淘汰策略设置给出的建议:
1. 当 **Redis 作为缓存使用**的时候，推荐使用 **allkeys-lru 淘汰策略**。该策略会将最近最少使用的 Key 淘汰。默认情况下，使用频率最低则后期命中的概率也最低，所以将其淘汰。
2. 当 Redis 作为**半缓存半持久化**使用时，可以使用 volatile-lru。但因为 Redis 本身不建议保存持久化数据，所以只作为备选方案。

阿里Redis的默认内存淘汰策略为**volatile-lru**.
## 4. 过期删除策略和内存淘汰策略有什么区别？ 
- 过期删除策略是**淘汰已过期的键值对**；
- 内存淘汰策略是当Redis的运行内存满了的时候，通过配置的策略来**删除键值对**，腾出内存空间以保存新的内容.
## 5. Redis中有一批key瞬间过期，为什么其它key的读写效率会降低？
因为Redis的过期删除策略：**主动删除**。

由于Redis是单线程模型，并且**主动删除定时任务是在主线程进行的**，所以若出现一批KEY同时过期，就可能需要主动删除大量的KEY，导致**后续业务请求只能等待主动删除结束才能执行**。

**解决：**（缓存雪崩？）
- 设置不同的过期时间，避免大规模KEY同时过期，分散删除过期键的压力。

---
# <font color="#245bdb">Redis集群</font>
## 1. 介绍一下Redis的集群模式？
Redis的集群模主要分为三种：1）主从复制；2）哨兵模式；3）Redis Cluster模式，用于在分布式环境中解决高可用性与数据复制。
### 主从复制
包含一个主节点和多个从节点。主节点用于处理所有的写操作与读操作，从节点会复制主节点的数据，并且只能处理读操作。主节点发生故障后，可以手动将从节点可以升级成主节点，实现故障转移。
![[Pasted image 20241204222013.png|650]]
**优点：**
1. 简单易用，适用于读多写少的场景；
2. 扩展性好，可通过增加从节点来提高读能力；

**缺点：**
1. 不具备故障自动转移的能力，无法做容错和恢复；
2. 主节点或从节点宕机，会导致部分读请求失败；
3. 主节点宕机容易导致数据不一致。
### 哨兵模式
在主从复制的基础上增加了哨兵节点，用于监控主节点与从节点的状态。当主节点故障时，从节点能自动进行故障恢复。

**原理：**
- 哨兵节点（多个）会向主从节点发送PING命令，若未收到PONG命令，则会标记为**主观下线**。若被多数标记为下线，则会被标记为客观下线，此时会触发故障转移过程。
	- 客观下线由`quorum`参数配置，默认是50%以上的节点标记主观下线，就会被标记为客观下线。

**优点：**
1. 为整个集群提供了自动故障恢复和转移的能力。

### Cluster模式
将数据自动分片到多个节点上，每个节点负责一部分数据，每个节点都包含一个主节点和多个从节点，并且可单独提供读写服务。

Redis Cluster能够自动检测节点的故障。当一个主节点失去连接或不可达时，Redis Cluster会尝试将该节点标记为不可用，并从可用的从节点中提升一个新的主节点。

**优点：**
1. 提供了更好的横向扩展和容错能力；
2. 可以自动管理数据分片和故障转移；
3. 数据分片存储在不同节点，每个节点都可单独提供读写服务，不存在单点故障问题。
![[Pasted image 20241204223025.png|650]]

## 2. 什么是Redis的数据分片？
- Redis的数据分片是**将Redis数据集分割成多个部分，分别存储在不同的Redis节点**。可用于将单独的Redis数据库扩展到多个物理机器上，从而提高Redis集群的性能和可扩展性。
- **实现方式**：将数据按照某种规则（例如，key的hash值）分配到不同的节点上。当客户端想要访问某个key时，它会先计算出这个key应该存储在哪个节点上，然后直接连接到该节点进行操作。
- Redis的Cluster集群模式中，使用**哈希槽**（hash slot）的方式进行数据分片，将整个数据集划分为多个槽，每个槽分配一个节点。客户端访问key时，先计算出对应的槽，然后直接连接到该槽所对应的节点进行操作。

划分为16384个槽，每个节点负责多个槽。访问数据时，先计算出槽编号，然后根据槽编号找到负责该槽的节点，向该节点发送请求进行连接。
![[Pasted image 20241218221139.png]]
**优点：**
1. **提高性能与吞吐量**：多个节点并行处理更多请求，可以降低单个节点的压力，同时提高整体性能和吞吐量。
2. **提高可扩展性**：分片使得Redis可以水平扩展，通过添加更多节点来扩展数据库的容量与处理能力。
3. **避免单点故障**：一个节点出问题，其他节点仍可继续运行；
4. **数据冗余和高可用**：分片数据可以在集群内其它节点进行冗余复制，保证节点宕机数据也不会丢失。
## 3. Redis主从同步中的增量和完全同步怎么实现？^
## 4. 介绍下Redis集群的脑裂问题？
一个分布式系统有两个子集，每个子集都有自己的Master节点，并且每个子集都认为子集是正常的，从而导致数据不一致或重复写入的问题。
![[Pasted image 20241218213019.png]]
**发生的原因：**
1. 

---
# <font color="#245bdb">Redis场景题</font>
## 1. 什么是热Key问题?
### 介绍:
当我们使用Redis作为存储时，如果发生一些特殊情况，比如明星官宣的突发事件，世界杯等重大活动，双十一的活动秒杀等等，就会**出现特别大的流量，并且会导致某些热词、商品等被频繁的查询和访问**。

如果在**同一个时间点上，Redis中的同一个key被大量访问**，就会导致流量过于集中，使得很多物理资源无法支撑，如网络带宽、物理存储空间、数据库连接等。

热key的定义，通常以其接收到的Key被请求频率来判定，例如：  
- QPS集中在特定的Key：Redis实例的总QPS为10,000，而其中一个Key的每秒访问量达到了7,000。那么这个key就算热key了。  
- 带宽使用率集中在特定的Key：对一个拥有1000个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。  
- CPU使用时间占比集中在特定的Key：对一个拥有10000个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求。
## 2. 如何解决热key问题?
>**热点key拆分,多级缓存,热key备份,限流等方案**

### 多级缓存:
加缓存是解决热key的最主要方式!通过缓存可以尽量减少与系统的交互,使得用户请求能提前返回.

缓存的方式有很多，有些数据可以**缓存在客户的客户端浏览器中**，有些数据可以**缓存在距离用户就近的CDN中**，有些数据可以**通过Redis等这类缓存框架进行缓存**，还有些数据可以**通过服务器本地缓存**进行。

**通过缓存的方式尽量减少用户的访问链路的长度。**

### 热key备份:
加了缓存之后， 还可能同时**部署多个缓存服务器**，如Redis同时部署多个服务器集群。并且实时的**将热点数据同步分发到多个缓存服务器集群中**，一旦有的集群扛不住了，立刻做切换。

### 热Key拆分:
将一个热key拆分成多个key，在每一个Key后面加一个后缀名，然后把这些**key分散到多个实例**中。这样在客户端请求的时候，可以**根据一定的规则计算得出一个固定的Key，这样多次请求就会被分散到不同的节点上了。**

**热点拆分会会导致用户只能拿到部分数据,但是有时并不需要返回所有数据.**

例如:将"淄博烧烤"拆分为"淄博烧烤_001","淄博烧烤_002""淄博烧烤_003"等,并将他们存储在集群中的不同节点上. 此时,用户只能访问到部分数据,但是并不影响,只推送部分内容给用户即可. 

在热key不那么热后,再把数据汇总,重新推送给没推送到用户.

## 3. 什么是大Key问题,如何解决大Key问题?
Big Key是Redis中存储了大量数据的Key，通常是Key对应的Value值很大，或者包含的元素过多。
![[Pasted image 20241218213338.png]]
### BigKey造成的危害：
1. **影响性能**：由于big key的values占用的内存会很大，所以读取它们的速度会很慢，会影响系统的性能.
2. **占用内存** ：大量的big key也会占满Redis的内存，让Redis无法继续存储新的数据，而且也会导致Redis卡住.
3. **内存空间不均匀**：在 Redis 集群中,可能会因为某个节点上存储了Big Key，导致**多个节点之间内存使用不均匀**。
4. **影响Redis备份和恢复**：如果从RDB文件中恢复全量数据时，可能需要大量的时间，甚至无法正常恢复。
5. **搜索困难**：搜索key内容时非常困难，并且可能需要花费较长的时间完成搜索任务。
6. **迁移困难：** ：大对象的迁移和复制压力较大，极易破坏缓存的一致性
7. **过期执行耗时**： 如果 Bigkey 设置了过期时间，当过期后，这个 key 会被删除，而大key的删除过程也比较耗时。
### 识别办法：
可通过`redis-cli-bigkeys`来获取Redis中的BigKey:：搜索**所有Redis数据库中包含大量内存数据的key**，并且会将其**保存在本地标准输出文件**中.
### 解决办法：(拆分+删除+迁移)
1. **拆分大Key：**
	- 将大Key拆分为多个数据在合理范围的key，比如根据日期或用户尾号等字段进行拆分. 
	- 或者在集群模式下，将BigKey分散到不同服务器上，加快响应速度.
2. **清理过期数据**：合理设置缓存的过期时间，避免因不及时清理而增大Key大小.
3. **合理删除低频数据**：合理删除访问频率低的BigKey，优化内存占用.
4. **部分迁移**：将大Key迁移至单独的数据库存储，并异步删除Redis中的大Key.

## 4. 什么是缓存击穿、缓存穿透和缓存雪崩?
### **缓存击穿:**
某一个key缓存过期,当有高并发量的请求同时访问该key时,瞬间**击穿缓存服务器,直接访问数据库**,使数据库处于高负载情况.
### 缓存穿透:
>**与击穿的区别就在于，穿透的情况中，数据库也不存在查询的数据.**

服务器中不存在缓存数据，**数据库中也不存在符合条件的数据**，因此也无法构建缓存数据来服务后续的请求，导致大量请求到达数据库,使数据库处于高负载。

>[!击穿与穿透的区别]
>**共同点:**缓存服务器中都没有要访问的数据.
>**区别:**
>	击穿时,数据库存在要访问的数据,所以**访问后可以构建缓存数据**;
>	穿透时,数据库也不存在要访问的数据,**后续所有请求都会直接访问数据库**.
### 缓存雪崩:
大量缓存在同一时间到期,获取缓存服务器宕机,此时所有请求都直接访问数据库,造成数据库高负载,影响性能,甚至数据库宕机.
## 5. 讲讲三种缓存失效的处理方式。
### 缓存击穿
1. **异步定时更新**：通过定时任务去更新这个热点key，并重新设置其过期时间。
2. **互斥锁**：若查询缓存发现是空值，则加锁并从数据库加载数据更新缓存，然后再释放锁，此时其他线程再请求时，就可以从缓存中获取数据了。

### 缓冲穿透
1. **缓存空值**：客户端请求某个 ID 的数据，首先检查缓存是否命中。如果缓存未命中，查询数据库。**如果数据库查询结果为空，将该空结果（如 null 或 {}）缓存起来，并设置一个合理的过期时间**。当后续请求再访问相同 ID 时，缓存直接返回空结果，避免每次都打到数据库。
2. **布隆过滤器**：在缓存前添加布隆过滤器，通过布隆过滤器存储所有可能存在的合法数据的键。当请求到达时，通过布隆过滤器判断是否存在，不存在则会直接返回；可能存在的话会进行查询。
![[Pasted image 20241205002548.png|300]]
### 缓存雪崩
1. **集群部署**：部署多集群，即使某个节点故障，其他节点仍可以提供服务，避免单点故障。
2. **设置不同的过期时间**：通过设置不同的过期时间，避免大量缓存在同一时间过期。（可通过在原有缓存添加一个随机值实现）
3. **限流**：设置合理的系统限流策略，如令牌桶或漏斗算法，控制访问流量。
## 6. ==介绍一下布隆过滤器.==
>主要用于判断**数据是否不存在**,数据存在的情况可能会误判!

### **介绍:**
布隆过滤器是一种数据结构，用于**快速检索一个元素是否可能存在于一个集合(bit数组)中**。

布隆过滤器由 **"N个哈希函数"和"初始值为0的位图数组"** 构成.写入数据库时,会在位图上做标记, 而下次查询时,只需要查询布隆过滤器,若不存在标记,则代表数据不存在!

**优点:** 空间效率和查询时间都远远超过一般的算法
**缺点:** 有一定的误判率和删除困难。

### **工作过程:**
1. **初始化布隆过滤器:**
在初始化布隆过滤器时，需要**指定集合的大小和误判率**。布隆过滤器内部包含一个bit数组和多个哈希函数，每个哈希函数都会生成一个索引值。
2. **添加元素到布隆过滤器:**
元素通过多个哈希函数生成多个索引,将位图中对应索引的位置赋1.
	(经哈希函数后还需要`%BitMap.size()`,将哈希值限制在位图数组范围内)
3. **查询元素是否在布隆过滤器中:**
元素经由多个哈希函数生成多个索引,若索引对应的值都为1,则元素**可能存在**,若存在对应值不为1,则肯定不存在!

### 使用场景
1. **缓存系统:** 缓存系统可以使用布隆过滤器来判断一个查询是否可能存在于缓存中，从而减少查询缓存的次数，提高查询效率。布隆过滤器也经常用来解决缓存穿透的问题.
2. **分布式系统:** 在分布式系统中，可以使用布隆过滤器来判断一个元素是否存在于分布式缓存中，避免在所有节点上进行查询，减少网络负载。

### 使用方法:
基于Guava实现的布隆过滤器:
```java
// 创建布隆过滤器，预计插入100个元素，误判率为0.01
        BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(), 100, 0.01);

        // 插入元素
        bloomFilter.put("Hollis");
        bloomFilter.put("666");
        bloomFilter.put("八股文");

        // 判断元素是否存在
        System.out.println(bloomFilter.mightContain("Hollis")); // true
        System.out.println(bloomFilter.mightContain("王星星"));  // false
```

注意,实现布隆过滤器时,需要传入 **"容量"和"误判率"** 两个参数,内部会**根据参数计算出所需的BitMap数组大小和哈希函数的数量**,使得在当前容量下存入的元素能满足误判率要求.
	注意,实际存放的元素数量可以超过容量,但此时误判率会增加.

## 7. 什么情况下会出现数据库和缓存不一致的问题 
### 非并发情况:
写缓存和写数据库具有时间差,当一个操作失败,一个操作成功时,会出现不一致.

### 并发情况:
1. **两个线程同时进行更新操作**:
![[Pasted image 20241016162551.png]]

2. **读写并行操作:**(可能性较小,因为读操作的耗时很短)
![[Pasted image 20241016163228.png]]
## 8. ==如何解决(保证)Redis和数据库的一致性问题?== ^
三种常见方案：
1. **先更新数据库，再删除缓存**。(而不是更新数据库,然后更新缓存)
2. **延迟双删**：先删除缓存，再更新数据库，再删除一次缓存。
3. **cache-aside**：更新数据库，基于 binlog 监听进行缓存删除。

## 9. 为什么删除缓存代替更新缓存？

## 10. 为什么需要延迟双删,两次删除的原因是什么? ^


## 11. 库存扣减如何避免超卖和少卖?
### 超卖问题:

**出现原因:** 
![[Pasted image 20241016213556.png|300]]
### 解决办法1:数据层面进行库存限制

借助数据库自己执行引擎的顺序执行机制，只要保证库存不要扣减成负数:
```sql
update inventory
set quantity = quantity - #{count}
where sku_id='123' and quantity >= #{count}
```

**缺点:**
- 完全依赖数据库,在高并发情况下,多个线程同时更新会发生阻塞.
### 解决办法2:Redis扣减

利用Redis的单线程执行特性,以及Lua脚本的原子性保障:
```lua
local key = KEYS[1] -- 商品的键名
local amount = tonumber(ARGV[1]) -- 扣减的数量

-- 获取商品当前的库存量
local stock = tonumber(redis.call('get', key))

-- 如果库存足够，则减少库存并返回新的库存量
if stock >= amount then
    redis.call('decrby', key, amount)
    return redis.call('get', key)
else
    return "INSUFFICIENT STOCK"
end

```

### 解决办法3:方案融合(实际应用)

先在Redis中做扣减,利用Redis来抗高并发,然后再同步到数据库扣减进行持久化存储,避免Redis挂了导致数据丢失.

一般的做法是: 先在Redis中做扣减，然后发送一个MQ消息，消费者在接到消息之后做数据库中库存的真正扣减及业务逻辑操作。
![[Pasted image 20241021000228.png]]

但是,若Redis中扣减成功,但是MQ消息发送失败或者消息丢了,则可能导致少卖问题.

#### 少卖问题解决办法:
引入一些**对账机制**，做一些**准实时的核对**，针对这类情况及时发现，如果少卖很多的话，那么就需要再把这些库存加回去。（比如用zset在redis中添加流水记录，然后定时拉一段时间内的所有记录，和数据库比对，发现不一致，则进行补偿处理）

### 解决办法4:分布式锁?

利用分布式锁,保证同一时间只能有一个客户端拿到锁,其他客户端会循环等待来尝试获取锁.
#### 不使用分布式锁的原因:
- 分布式锁,在不使用Lua脚本的情况下,**每次库存扣减操作都需要与Redis服务器进行多次通信**(如加锁,读取库存,扣减库存,释放锁).**既增加了网络延时,还增加了系统的复杂性.**
- Lua脚本在Redis服务器内部执行,可以直接操作内存数据,执行效率很高.并且使用 Lua 脚本实现的话，我们可以**将库存扣减的逻辑集中处理,不需要在应用层做额外的同步处理**。
- 分布式锁需要细致的管理，包括锁的设置、维护锁的存活时间、处理死锁问题等。如果锁没有正确管理，可能会导致死锁或者锁失效，进而影响系统的稳定性和数据一致性。

## 12. 除了做缓存，Redis还能用来干什么
1. **排行榜功能**：利用ZSet的排序功能；
2. **计数器**：实现网站的访问量、点赞功能，通过INCR的原子性自增操作；
3. **分布式锁**：Redis 的单线程特性可以保证多个客户端之间对同一把锁的操作是原子性的，可以轻松实现分布式锁，用于控制多个进程对共享资源的访问。

## 13. 如何用SETNX实现分布式锁？
- 利用Redis的单线程特性，在多个Redis客户端同时通过SETNX命令尝试获取锁，如果返回1表示获取锁成功，否则表示获取锁失败。
- 获取锁成功，还需设置一个过期时间，避免客户端宕机导致一直持有锁。
- DEL锁时，需要判断锁是否属于当前客户端。

**优点：**
1. 实现简单；
2. 性能高：利用SETNX的原子性与Redis的单线程特性，保证了单线程。

**缺点：**
1. **锁无法续期**：如果业务执行较长，且超时时间设置较短，会导致锁被提前释放；
2. **无法避免死锁**：如果未设置超时时间，且客户端崩溃，则会导致锁被一直持有；
3. **不支持重入**：SETNX不支持可重入锁。（String型为KEY-VALUE结构）

### 示例：
- 加锁为`trylock()`，其中Key为lockKey，value为requestID；
- 解锁为`unlock()`，只有当锁的value与当前requestID相同，才释放锁返回true，否则返回false。
	- 解锁通过Lua脚本进行；eval代表执行lua脚本。
```java
public class RedisDistributedLock {
    private final JedisPool jedisPool;

    public RedisDistributedLock(JedisPool jedisPool) {
        this.jedisPool = jedisPool;
    }

    public boolean tryLock(String lockKey, String requestId, int expireTime) {
        try (Jedis jedis = jedisPool.getResource()) {
            String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
            return "OK".equals(result);
        }
    }

    public boolean unlock(String lockKey, String requestId) {
        try (Jedis jedis = jedisPool.getResource()) {
            String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
            Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));
            return Long.parseLong(result.toString()) == 1L;
        }
    }
}
```

**进阶可使用Redisson实现。**

## 14. 如何使用Redisson实现分布式锁？
Redisson的优点：
1. **WatchDog机制**，可以自动延长锁的有效期；（默认30秒）
2. 支持**可重入锁**；
3. 支持**公平锁**；
4. 支持**联锁**：多个锁都上锁成功才算加锁成功；
5. **读写锁**：允许同时有多个读锁，和一个写锁；

## 15. 什么是RedLock？解决了什么问题？^
RedLock通过使用多个Redis节点，提供了一个更健壮的分布式锁解决方案。

## 16. Redisson的watchdog机制是怎么样的？
- 获取锁成功后，会基于后台定时任务，定期向Redis发送命令，重新设置锁的定期时间。
- 若未主动设置过期时间，则会自动设置过期时间为30s，并每隔10s续期一次。
- `unlock()`释放锁后，即使`unlock()`失败，WatchDog也会取消续期；
- 如果加锁时指定了超时时间，那么WatchDog不会进行续期。

## 17. 如何基于Redisson实现延时队列？^
Redisson中定义了基于ZSet实现的分布式延时队列RDelayedQueue，允许以指定的延时时长将元素放入队列中。

## 18. 如何基于Redis实现滑动窗口限流？^
